{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LD_LIBRARY_PATH=/ home / zach / anaconda3 / envs / research / lib /\n",
      "env: TF_GPU_ALLOCATOR=cuda_malloc_async\n"
     ]
    }
   ],
   "source": [
    "%env LD_LIBRARY_PATH= / home / zach / anaconda3 / envs / research / lib /\n",
    "%env TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n",
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 13:45:24.893585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 13:45:24.897049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 13:45:24.897357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 13:45:24.897823: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-29 13:45:24.898829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 13:45:24.899130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 13:45:24.899411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 13:45:25.199594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 13:45:25.199923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 13:45:25.200213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-29 13:45:25.200468: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-05-29 13:45:25.200677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6292 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "f1 = tfa.metrics.F1Score(num_classes=1, average=None)\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11376/3597924913.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  train = train.drop(['TR', 'AG'], 1)\n",
      "/tmp/ipykernel_11376/3597924913.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  test = test.drop(['TR', 'AG'], 1)\n",
      "/tmp/ipykernel_11376/3597924913.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  val = val.drop(['TR', 'AG'], 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       hurray saving us in so many ways lockthemup bu...\n",
      "1       why would young fighting age men be the vast m...\n",
      "2       illegals dump their kids at the border like ro...\n",
      "3       ny times nearly all white states pose an array...\n",
      "4       orban in brussels european leaders are ignorin...\n",
      "                              ...                        \n",
      "8995                  i am proud to be a hysterical woman\n",
      "8996    hollywood is complicit in the rape and sexual ...\n",
      "8997    what a fucking cunt i hate seeing kids getting...\n",
      "8998                                hysterical woman like\n",
      "8999    nearly every woman i know has metoo in their f...\n",
      "Name: text, Length: 9000, dtype: object\n",
      "0       oh i could have gone on about taxes since the ...\n",
      "1       several of the wild fires in california and co...\n",
      "2       my question is how do you resettle a refugee a...\n",
      "3       europe youve got a problem we must hurry and b...\n",
      "4       this is outrageous stopillegalimmigration meri...\n",
      "                              ...                        \n",
      "2995    you can never take a l off a real bitch im hot...\n",
      "2996    likes to call me a cunt a bitch but i tell him...\n",
      "2997    1 never said you were taught 2 you called me b...\n",
      "2998    if i see and know you a hoe why would i hit yo...\n",
      "2999     you be chasing them hoes fuck what a bitch think\n",
      "Name: text, Length: 3000, dtype: object\n",
      "0      i swear im getting to places just in the nick ...\n",
      "1      im an immigrant and trump is right on immigrat...\n",
      "2      illegalimmigrants illegalaliens electoralsyste...\n",
      "3      we have our own invasion issues with mexicans ...\n",
      "4      worker charged with sexually molesting eight c...\n",
      "                             ...                        \n",
      "995                     you unfollowed me fuck you pussy\n",
      "996    stfu bitch and you go make some satanic music ...\n",
      "997    honey as a fellow white chick let me tell you ...\n",
      "998    i hate bitches who talk about niggaz with kids...\n",
      "999    you won the life time recipient for hysterical...\n",
      "Name: text, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "## Data Import and Cleaning\n",
    "train = pd.read_csv('data/hateval2019_en_train.csv')\n",
    "test = pd.read_csv('data/hateval2019_en_test.csv')\n",
    "val = pd.read_csv('data/hateval2019_en_dev.csv')\n",
    "\n",
    "train = train.drop(['TR', 'AG'], 1)\n",
    "test = test.drop(['TR', 'AG'], 1)\n",
    "val = val.drop(['TR', 'AG'], 1)\n",
    "train.head()\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding, Flatten, concatenate, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.regularizers import L1, L2, l1_l2\n",
    "import io\n",
    "\n",
    "\n",
    "def normalize_tweet(text):\n",
    "    \"\"\"\n",
    "    Removes hashtags, @s, links, and punctuation\n",
    "    :param text:Text to be cleaned\n",
    "    :return: text with mentions, hashtages, and urls removes\n",
    "    \"\"\"\n",
    "    processed_text = text.lower()\n",
    "    processed_text = re.sub(r\"(?:\\@|http?\\://|https?\\://|www|t\\.)\\S+\", \"\", processed_text)\n",
    "    processed_text = re.sub(r\"(?:\\.|,|\\?|-)\", \" \", processed_text)\n",
    "    processed_text = re.sub(r\"(?:\\@|http?\\://|https?\\://|www|\\.com)\", \"\", processed_text)\n",
    "    processed_text = re.sub(r'[^\\w\\s]', '', processed_text)\n",
    "    processed_text = \" \".join(processed_text.split())\n",
    "    return processed_text\n",
    "\n",
    "\n",
    "def x_y_split(data):\n",
    "    \"\"\"splits and X and y from dataframe\n",
    "\n",
    "    Args:\n",
    "        data:dataframe to split from\n",
    "\n",
    "    Returns:\n",
    "        tuple:X data, y data\n",
    "    \"\"\"\n",
    "    X = data['text']\n",
    "    X = X.apply(normalize_tweet)\n",
    "    y = data['HS']\n",
    "    return X, y\n",
    "\n",
    "\n",
    "## Split sequences into train, validation, and test sets\n",
    "#Split x and ys\n",
    "x_train, y_train = x_y_split(train)\n",
    "print(x_train)\n",
    "#x_train.to_csv('data/x_train.csv')\n",
    "#y_train.to_csv('data/y_train.csv')\n",
    "#Split x and ys\n",
    "x_test, y_test = x_y_split(test)\n",
    "print(x_test)\n",
    "#x_test.to_csv('data/x_test.csv')\n",
    "#y_test.to_csv('data/y_test.csv')\n",
    "#Split x and ys\n",
    "x_val, y_val = x_y_split(val)\n",
    "print(x_val)\n",
    "#x_val.to_csv('data/x_val.csv')\n",
    "#y_val.to_csv('data/y_val.csv')\n",
    "\n",
    "x_graph_train = pd.read_csv('data/extracted_annotations_train.csv')\n",
    "x_graph_val = pd.read_csv('data/extracted_annotations_val.csv')\n",
    "x_graph_test = pd.read_csv('data/extracted_annotations_test.csv')\n",
    "\n",
    "x_graph_train = x_graph_train['annotations']\n",
    "x_graph_val = x_graph_val['annotations']\n",
    "x_graph_test = x_graph_test['annotations']\n",
    "\n",
    "x_graph_train = x_graph_train.apply(str)\n",
    "x_graph_val = x_graph_val.apply(str)\n",
    "x_graph_test = x_graph_test.apply(str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "0       hurray saving us in so many ways lockthemup bu...\n1       why would young fighting age men be the vast m...\n2       illegals dump their kids at the border like ro...\n3       ny times nearly all white states pose an array...\n4       orban in brussels european leaders are ignorin...\n                              ...                        \n8995                  i am proud to be a hysterical woman\n8996    hollywood is complicit in the rape and sexual ...\n8997    what a fucking cunt i hate seeing kids getting...\n8998                                hysterical woman like\n8999    nearly every woman i know has metoo in their f...\nName: text, Length: 9000, dtype: object"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text  # A dependency of the preprocessing model\n",
    "\n",
    "tfhub_handle_encoder = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n",
    "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "\n",
    "\n",
    "def build_classifier_model(do, trainable=False):\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=trainable, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    text_input2 = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text_graph')\n",
    "    preprocessing_layer2 = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing_graph')\n",
    "    encoder_inputs2 = preprocessing_layer2(text_input2)\n",
    "    encoder2 = hub.KerasLayer(tfhub_handle_encoder, trainable=trainable, name='BERT_encoder_graph')\n",
    "    outputs2 = encoder2(encoder_inputs2)\n",
    "    net2 = outputs2['pooled_output']\n",
    "    combined = concatenate([net,net2])\n",
    "    x = Dropout(do)(combined)\n",
    "    x = Reshape((1,1536))(x)\n",
    "    x = LSTM(512,dropout=do)(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(do)(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "    return tf.keras.Model([text_input,text_input2], x)\n",
    "\n",
    "\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-29 13:45:52.510128: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 396/1125 [=========>....................] - ETA: 3:46 - loss: 0.6868 - f1_score: 0.5992 - accuracy: 0.5619"
     ]
    }
   ],
   "source": [
    "learning_rates = [5e-5, 1e-4, 3e-5, 3e-5]\n",
    "#learning_rates = [5e-5]\n",
    "learning_rates_text = ['5e-5', '1e-4', '3e-5', '3e-5']\n",
    "batch_sizes = [8]\n",
    "dropout = [.5,.75,.25,0.0,.1]\n",
    "#dropout = [.1]\n",
    "results = {}\n",
    "results_acc = {}\n",
    "best_epochs = {}\n",
    "for do in dropout:\n",
    "    for bs in batch_sizes:\n",
    "        for lr in range(len(learning_rates)):\n",
    "            np.random.seed(42)\n",
    "            tf.random.set_seed(42)\n",
    "            string = 'lr{lr}_bs{bs}_do{do}'.format(lr=learning_rates_text[lr], bs=bs, do=do)\n",
    "\n",
    "            bert = build_classifier_model(do, trainable=True)\n",
    "            bert.compile(loss=loss, optimizer=Adam(learning_rate=learning_rates[lr]), metrics=[f1, 'accuracy'])\n",
    "            history = bert.fit(x=[x_train,x_graph_train],\n",
    "                               y=y_train, batch_size=8,\n",
    "                               validation_data=([x_val,x_graph_val], y_val),\n",
    "                               epochs=4)\n",
    "\n",
    "            max_f1 = max(history.history['val_f1_score'])\n",
    "            max_acc = max(history.history['val_accuracy'])\n",
    "            val_acc_per_epoch = history.history['val_accuracy']\n",
    "            best_epoch = val_acc_per_epoch.index(max_acc) + 1\n",
    "            results[string] = max_f1\n",
    "            results_acc[string] = max_acc\n",
    "            best_epochs[string] = best_epoch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bert.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}