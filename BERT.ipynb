{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LD_LIBRARY_PATH=/home/zach/anaconda3/envs/research/lib/\n",
      "env: TF_GPU_ALLOCATOR=cuda_malloc_async\n"
     ]
    }
   ],
   "source": [
    "#Need to remove hardcoding but needed for now\n",
    "%env LD_LIBRARY_PATH=/home/zach/anaconda3/envs/research/lib/\n",
    "%env TF_GPU_ALLOCATOR=cuda_malloc_async"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0433822-9d89-4b16-bb3c-faf4becb2f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "import tensorflow_addons as tfa\n",
    "f1 = tfa.metrics.F1Score(num_classes=1,average=None)\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/zach/anaconda3/envs/research/lib/'"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['LD_LIBRARY_PATH']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Import and Cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bc2ed28-b317-4e93-879b-174809fe1592",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64834/675437588.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  train = train.drop(['TR','AG'],1)\n",
      "/tmp/ipykernel_64834/675437588.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  test = test.drop(['TR','AG'],1)\n",
      "/tmp/ipykernel_64834/675437588.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  val = val.drop(['TR','AG'],1)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/hateval2019_en_train.csv')\n",
    "test = pd.read_csv('data/hateval2019_en_test.csv')\n",
    "val = pd.read_csv('data/hateval2019_en_dev.csv')\n",
    "\n",
    "train = train.drop(['TR','AG'],1)\n",
    "test = test.drop(['TR','AG'],1)\n",
    "val = val.drop(['TR','AG'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38ad4e4f-bb0a-4320-abb5-70975afcf27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "    id                                               text  HS\n0  201  Hurray, saving us $$$ in so many ways @potus @...   1\n1  202  Why would young fighting age men be the vast m...   1\n2  203  @KamalaHarris Illegals Dump their Kids at the ...   1\n3  204  NY Times: 'Nearly All White' States Pose 'an A...   0\n4  205  Orban in Brussels: European leaders are ignori...   0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>HS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>201</td>\n      <td>Hurray, saving us $$$ in so many ways @potus @...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>202</td>\n      <td>Why would young fighting age men be the vast m...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>203</td>\n      <td>@KamalaHarris Illegals Dump their Kids at the ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>204</td>\n      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>205</td>\n      <td>Orban in Brussels: European leaders are ignori...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19c65889-3f31-48d8-9b24-4761dead01fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.regularizers import L1,L2, l1_l2\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a577312-e144-4c17-8f0d-3c01dfb99194",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_tweet(text):\n",
    "    \"\"\"\n",
    "    Removes hashtags, @s, links, and punctuation\n",
    "    :param text:Text to be cleaned\n",
    "    :return: text with mentions, hashtages, and urls removes\n",
    "    \"\"\"\n",
    "    processed_text = text.lower()\n",
    "    processed_text = re.sub(r\"(?:\\@|http?\\://|https?\\://|www|t\\.)\\S+\", \"\", processed_text)\n",
    "    processed_text = re.sub(r\"(?:\\.|,|\\?|-)\", \" \", processed_text)\n",
    "    processed_text = re.sub(r\"(?:\\@|http?\\://|https?\\://|www|\\.com)\", \"\", processed_text)\n",
    "    processed_text = re.sub(r'[^\\w\\s]', '', processed_text)\n",
    "    processed_text = \" \".join(processed_text.split())\n",
    "    return processed_text\n",
    "\n",
    "def x_y_split(data):\n",
    "    \"\"\"splits and X and y from dataframe\n",
    "\n",
    "    Args:\n",
    "        data:dataframe to split from\n",
    "\n",
    "    Returns:\n",
    "        tuple:X data, y data\n",
    "    \"\"\"\n",
    "    X = data['text']\n",
    "    X = X.apply(normalize_tweet)\n",
    "    y = data['HS']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486671d4-0ebf-4dca-b222-f9874edcffd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split sequences into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "892e5b37-65e1-4490-8f21-4c86f55a3252",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       hurray saving us in so many ways lockthemup bu...\n",
      "1       why would young fighting age men be the vast m...\n",
      "2       illegals dump their kids at the border like ro...\n",
      "3       ny times nearly all white states pose an array...\n",
      "4       orban in brussels european leaders are ignorin...\n",
      "                              ...                        \n",
      "8995                  i am proud to be a hysterical woman\n",
      "8996    hollywood is complicit in the rape and sexual ...\n",
      "8997    what a fucking cunt i hate seeing kids getting...\n",
      "8998                                hysterical woman like\n",
      "8999    nearly every woman i know has metoo in their f...\n",
      "Name: text, Length: 9000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Split x and ys\n",
    "x_train, y_train = x_y_split(train)\n",
    "print(x_train)\n",
    "#x_train.to_csv('data/x_train.csv')\n",
    "#y_train.to_csv('data/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d051068c-d8f7-4ae2-953f-cab47e9d6aa6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       oh i could have gone on about taxes since the ...\n",
      "1       several of the wild fires in california and co...\n",
      "2       my question is how do you resettle a refugee a...\n",
      "3       europe youve got a problem we must hurry and b...\n",
      "4       this is outrageous stopillegalimmigration meri...\n",
      "                              ...                        \n",
      "2995    you can never take a l off a real bitch im hot...\n",
      "2996    likes to call me a cunt a bitch but i tell him...\n",
      "2997    1 never said you were taught 2 you called me b...\n",
      "2998    if i see and know you a hoe why would i hit yo...\n",
      "2999     you be chasing them hoes fuck what a bitch think\n",
      "Name: text, Length: 3000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Split x and ys\n",
    "x_test, y_test = x_y_split(test)\n",
    "print(x_test)\n",
    "#x_test.to_csv('data/x_test.csv')\n",
    "#y_test.to_csv('data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01de8fa7-03ed-4d50-9ca6-296865282e6f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      i swear im getting to places just in the nick ...\n",
      "1      im an immigrant and trump is right on immigrat...\n",
      "2      illegalimmigrants illegalaliens electoralsyste...\n",
      "3      we have our own invasion issues with mexicans ...\n",
      "4      worker charged with sexually molesting eight c...\n",
      "                             ...                        \n",
      "995                     you unfollowed me fuck you pussy\n",
      "996    stfu bitch and you go make some satanic music ...\n",
      "997    honey as a fellow white chick let me tell you ...\n",
      "998    i hate bitches who talk about niggaz with kids...\n",
      "999    you won the life time recipient for hysterical...\n",
      "Name: text, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Split x and ys\n",
    "x_val, y_val = x_y_split(val)\n",
    "print(x_val)\n",
    "#x_val.to_csv('data/x_val.csv')\n",
    "#y_val.to_csv('data/y_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text  # A dependency of the preprocessing model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "tfhub_handle_encoder = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n",
    "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def build_classifier_model(do,trainable=False):\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=trainable, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(do)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 184s 158ms/step - loss: 0.5035 - f1_score: 0.5919 - accuracy: 0.7560 - val_loss: 0.4812 - val_f1_score: 0.5985 - val_accuracy: 0.7770\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 182s 162ms/step - loss: 0.3713 - f1_score: 0.5919 - accuracy: 0.8406 - val_loss: 0.5690 - val_f1_score: 0.5985 - val_accuracy: 0.7760\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 190s 169ms/step - loss: 0.2101 - f1_score: 0.5919 - accuracy: 0.9211 - val_loss: 0.6628 - val_f1_score: 0.5985 - val_accuracy: 0.7710\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 189s 168ms/step - loss: 0.1205 - f1_score: 0.5919 - accuracy: 0.9571 - val_loss: 0.8040 - val_f1_score: 0.5985 - val_accuracy: 0.7410\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 193s 166ms/step - loss: 0.6995 - f1_score: 0.5925 - accuracy: 0.6261 - val_loss: 0.7360 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 187s 166ms/step - loss: 0.7669 - f1_score: 0.5919 - accuracy: 0.5240 - val_loss: 0.6961 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 179s 159ms/step - loss: 0.7121 - f1_score: 0.5919 - accuracy: 0.5429 - val_loss: 0.6838 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.6995 - f1_score: 0.5919 - accuracy: 0.5518 - val_loss: 0.6825 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 187s 160ms/step - loss: 0.4961 - f1_score: 0.5925 - accuracy: 0.7599 - val_loss: 0.4630 - val_f1_score: 0.5985 - val_accuracy: 0.7760\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.3185 - f1_score: 0.5919 - accuracy: 0.8656 - val_loss: 0.5060 - val_f1_score: 0.5985 - val_accuracy: 0.7800\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.1622 - f1_score: 0.5919 - accuracy: 0.9402 - val_loss: 0.7284 - val_f1_score: 0.5985 - val_accuracy: 0.7530\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.0798 - f1_score: 0.5919 - accuracy: 0.9730 - val_loss: 0.8571 - val_f1_score: 0.5985 - val_accuracy: 0.7740\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 187s 159ms/step - loss: 0.4913 - f1_score: 0.5925 - accuracy: 0.7641 - val_loss: 0.4763 - val_f1_score: 0.5985 - val_accuracy: 0.7690\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.3148 - f1_score: 0.5919 - accuracy: 0.8702 - val_loss: 0.5086 - val_f1_score: 0.5985 - val_accuracy: 0.7810\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.1594 - f1_score: 0.5919 - accuracy: 0.9420 - val_loss: 0.6798 - val_f1_score: 0.5985 - val_accuracy: 0.7750\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.0717 - f1_score: 0.5919 - accuracy: 0.9749 - val_loss: 0.9370 - val_f1_score: 0.5985 - val_accuracy: 0.7770\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 173s 297ms/step - loss: 0.5212 - f1_score: 0.5925 - accuracy: 0.7317 - val_loss: 0.5030 - val_f1_score: 0.5985 - val_accuracy: 0.7340\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 167s 297ms/step - loss: 0.3396 - f1_score: 0.5919 - accuracy: 0.8510 - val_loss: 0.5220 - val_f1_score: 0.5985 - val_accuracy: 0.7590\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 167s 297ms/step - loss: 0.1957 - f1_score: 0.5919 - accuracy: 0.9239 - val_loss: 0.8993 - val_f1_score: 0.5985 - val_accuracy: 0.7430\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 168s 298ms/step - loss: 0.1025 - f1_score: 0.5919 - accuracy: 0.9636 - val_loss: 0.7957 - val_f1_score: 0.5985 - val_accuracy: 0.7630\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 174s 298ms/step - loss: 0.5237 - f1_score: 0.5925 - accuracy: 0.7449 - val_loss: 0.4971 - val_f1_score: 0.5985 - val_accuracy: 0.7620\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 167s 297ms/step - loss: 0.3723 - f1_score: 0.5919 - accuracy: 0.8382 - val_loss: 0.4961 - val_f1_score: 0.5985 - val_accuracy: 0.7560\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 168s 298ms/step - loss: 0.2539 - f1_score: 0.5919 - accuracy: 0.9023 - val_loss: 0.8053 - val_f1_score: 0.5985 - val_accuracy: 0.7390\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 168s 299ms/step - loss: 0.1714 - f1_score: 0.5919 - accuracy: 0.9399 - val_loss: 0.8245 - val_f1_score: 0.5985 - val_accuracy: 0.7230\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 174s 298ms/step - loss: 0.4934 - f1_score: 0.5925 - accuracy: 0.7560 - val_loss: 0.4926 - val_f1_score: 0.5985 - val_accuracy: 0.7550\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 168s 299ms/step - loss: 0.3149 - f1_score: 0.5919 - accuracy: 0.8670 - val_loss: 0.5189 - val_f1_score: 0.5985 - val_accuracy: 0.7720\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 168s 299ms/step - loss: 0.1614 - f1_score: 0.5919 - accuracy: 0.9413 - val_loss: 0.6188 - val_f1_score: 0.5985 - val_accuracy: 0.7850\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 168s 299ms/step - loss: 0.0845 - f1_score: 0.5919 - accuracy: 0.9699 - val_loss: 0.7612 - val_f1_score: 0.5985 - val_accuracy: 0.7710\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 175s 299ms/step - loss: 0.5362 - f1_score: 0.5925 - accuracy: 0.7278 - val_loss: 0.5074 - val_f1_score: 0.5985 - val_accuracy: 0.7360\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 168s 299ms/step - loss: 0.3587 - f1_score: 0.5919 - accuracy: 0.8424 - val_loss: 0.5039 - val_f1_score: 0.5985 - val_accuracy: 0.7640\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 168s 299ms/step - loss: 0.2263 - f1_score: 0.5919 - accuracy: 0.9071 - val_loss: 0.7054 - val_f1_score: 0.5985 - val_accuracy: 0.7600\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 169s 300ms/step - loss: 0.1137 - f1_score: 0.5919 - accuracy: 0.9592 - val_loss: 0.8968 - val_f1_score: 0.5985 - val_accuracy: 0.7580\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 188s 160ms/step - loss: 0.5416 - f1_score: 0.5925 - accuracy: 0.7329 - val_loss: 0.4775 - val_f1_score: 0.5985 - val_accuracy: 0.7690\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.3654 - f1_score: 0.5919 - accuracy: 0.8463 - val_loss: 0.5384 - val_f1_score: 0.5985 - val_accuracy: 0.7890\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.2349 - f1_score: 0.5919 - accuracy: 0.9117 - val_loss: 0.7005 - val_f1_score: 0.5985 - val_accuracy: 0.7760\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.1253 - f1_score: 0.5919 - accuracy: 0.9568 - val_loss: 1.0275 - val_f1_score: 0.5985 - val_accuracy: 0.7480\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 188s 160ms/step - loss: 0.7857 - f1_score: 0.5925 - accuracy: 0.5201 - val_loss: 0.6859 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.7158 - f1_score: 0.5919 - accuracy: 0.5360 - val_loss: 0.6921 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.7079 - f1_score: 0.5919 - accuracy: 0.5440 - val_loss: 0.6834 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.7075 - f1_score: 0.5919 - accuracy: 0.5392 - val_loss: 0.6829 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 188s 160ms/step - loss: 0.5478 - f1_score: 0.5925 - accuracy: 0.7232 - val_loss: 0.4814 - val_f1_score: 0.5985 - val_accuracy: 0.7740\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.3599 - f1_score: 0.5919 - accuracy: 0.8409 - val_loss: 0.5051 - val_f1_score: 0.5985 - val_accuracy: 0.7710\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.2062 - f1_score: 0.5919 - accuracy: 0.9238 - val_loss: 0.6509 - val_f1_score: 0.5985 - val_accuracy: 0.7610\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 181s 161ms/step - loss: 0.0967 - f1_score: 0.5919 - accuracy: 0.9686 - val_loss: 0.8594 - val_f1_score: 0.5985 - val_accuracy: 0.7520\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 186s 160ms/step - loss: 0.5267 - f1_score: 0.5925 - accuracy: 0.7397 - val_loss: 0.4905 - val_f1_score: 0.5985 - val_accuracy: 0.7600\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 181s 161ms/step - loss: 0.3522 - f1_score: 0.5919 - accuracy: 0.8458 - val_loss: 0.4918 - val_f1_score: 0.5985 - val_accuracy: 0.7750\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 181s 161ms/step - loss: 0.1889 - f1_score: 0.5919 - accuracy: 0.9279 - val_loss: 0.6634 - val_f1_score: 0.5985 - val_accuracy: 0.7680\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 181s 161ms/step - loss: 0.0833 - f1_score: 0.5919 - accuracy: 0.9710 - val_loss: 0.7965 - val_f1_score: 0.5985 - val_accuracy: 0.7430\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 175s 299ms/step - loss: 0.5501 - f1_score: 0.5925 - accuracy: 0.7296 - val_loss: 0.5285 - val_f1_score: 0.5985 - val_accuracy: 0.7250\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 169s 300ms/step - loss: 0.3704 - f1_score: 0.5919 - accuracy: 0.8434 - val_loss: 0.5715 - val_f1_score: 0.5985 - val_accuracy: 0.7410\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 168s 299ms/step - loss: 0.2509 - f1_score: 0.5919 - accuracy: 0.9027 - val_loss: 0.6779 - val_f1_score: 0.5985 - val_accuracy: 0.7560\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 169s 299ms/step - loss: 0.1103 - f1_score: 0.5919 - accuracy: 0.9606 - val_loss: 0.9231 - val_f1_score: 0.5985 - val_accuracy: 0.7350\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 174s 299ms/step - loss: 0.7433 - f1_score: 0.5925 - accuracy: 0.5379 - val_loss: 0.6825 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 169s 300ms/step - loss: 0.7039 - f1_score: 0.5919 - accuracy: 0.5469 - val_loss: 0.6848 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 169s 299ms/step - loss: 0.6996 - f1_score: 0.5919 - accuracy: 0.5483 - val_loss: 0.6850 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 169s 299ms/step - loss: 0.6977 - f1_score: 0.5919 - accuracy: 0.5522 - val_loss: 0.6828 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 175s 298ms/step - loss: 0.5568 - f1_score: 0.5925 - accuracy: 0.7217 - val_loss: 0.5084 - val_f1_score: 0.5985 - val_accuracy: 0.7370\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 169s 300ms/step - loss: 0.3656 - f1_score: 0.5919 - accuracy: 0.8348 - val_loss: 0.5076 - val_f1_score: 0.5985 - val_accuracy: 0.7650\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 168s 299ms/step - loss: 0.2335 - f1_score: 0.5919 - accuracy: 0.9064 - val_loss: 0.6162 - val_f1_score: 0.5985 - val_accuracy: 0.7710\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 169s 299ms/step - loss: 0.1170 - f1_score: 0.5919 - accuracy: 0.9572 - val_loss: 0.8055 - val_f1_score: 0.5985 - val_accuracy: 0.7670\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 177s 299ms/step - loss: 0.5657 - f1_score: 0.5925 - accuracy: 0.7171 - val_loss: 0.4805 - val_f1_score: 0.5985 - val_accuracy: 0.7640\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 169s 301ms/step - loss: 0.3731 - f1_score: 0.5919 - accuracy: 0.8312 - val_loss: 0.5108 - val_f1_score: 0.5985 - val_accuracy: 0.7530\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 169s 300ms/step - loss: 0.2330 - f1_score: 0.5919 - accuracy: 0.9060 - val_loss: 0.5894 - val_f1_score: 0.5985 - val_accuracy: 0.7700\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 169s 300ms/step - loss: 0.1117 - f1_score: 0.5919 - accuracy: 0.9613 - val_loss: 0.7899 - val_f1_score: 0.5985 - val_accuracy: 0.7450\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 189s 161ms/step - loss: 0.5083 - f1_score: 0.5925 - accuracy: 0.7447 - val_loss: 0.4707 - val_f1_score: 0.5985 - val_accuracy: 0.7780\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 181s 161ms/step - loss: 0.3503 - f1_score: 0.5919 - accuracy: 0.8497 - val_loss: 0.5057 - val_f1_score: 0.5985 - val_accuracy: 0.7690\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 181s 161ms/step - loss: 0.2025 - f1_score: 0.5919 - accuracy: 0.9244 - val_loss: 0.6455 - val_f1_score: 0.5985 - val_accuracy: 0.7500\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 181s 161ms/step - loss: 0.1081 - f1_score: 0.5919 - accuracy: 0.9637 - val_loss: 0.7887 - val_f1_score: 0.5985 - val_accuracy: 0.7430\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 186s 160ms/step - loss: 0.6281 - f1_score: 0.5925 - accuracy: 0.6530 - val_loss: 0.6839 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 181s 161ms/step - loss: 0.6900 - f1_score: 0.5919 - accuracy: 0.5599 - val_loss: 0.6935 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 181s 161ms/step - loss: 0.6906 - f1_score: 0.5919 - accuracy: 0.5649 - val_loss: 0.6825 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 181s 161ms/step - loss: 0.6888 - f1_score: 0.5919 - accuracy: 0.5659 - val_loss: 0.6825 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 187s 160ms/step - loss: 0.4719 - f1_score: 0.5925 - accuracy: 0.7749 - val_loss: 0.4817 - val_f1_score: 0.5985 - val_accuracy: 0.7670\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 181s 161ms/step - loss: 0.3187 - f1_score: 0.5919 - accuracy: 0.8638 - val_loss: 0.5405 - val_f1_score: 0.5985 - val_accuracy: 0.7730\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 181s 161ms/step - loss: 0.1807 - f1_score: 0.5919 - accuracy: 0.9319 - val_loss: 0.6422 - val_f1_score: 0.5985 - val_accuracy: 0.7720\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 181s 161ms/step - loss: 0.0829 - f1_score: 0.5919 - accuracy: 0.9714 - val_loss: 0.9532 - val_f1_score: 0.5985 - val_accuracy: 0.7470\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 186s 160ms/step - loss: 0.4748 - f1_score: 0.5925 - accuracy: 0.7734 - val_loss: 0.4801 - val_f1_score: 0.5985 - val_accuracy: 0.7660\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 181s 161ms/step - loss: 0.2960 - f1_score: 0.5919 - accuracy: 0.8762 - val_loss: 0.5635 - val_f1_score: 0.5985 - val_accuracy: 0.7880\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 181s 161ms/step - loss: 0.1524 - f1_score: 0.5919 - accuracy: 0.9463 - val_loss: 0.7706 - val_f1_score: 0.5985 - val_accuracy: 0.7430\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.0735 - f1_score: 0.5919 - accuracy: 0.9753 - val_loss: 0.9062 - val_f1_score: 0.5985 - val_accuracy: 0.7660\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 174s 299ms/step - loss: 0.4966 - f1_score: 0.5925 - accuracy: 0.7600 - val_loss: 0.4718 - val_f1_score: 0.5985 - val_accuracy: 0.7540\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 169s 299ms/step - loss: 0.3263 - f1_score: 0.5919 - accuracy: 0.8598 - val_loss: 0.5416 - val_f1_score: 0.5985 - val_accuracy: 0.7830\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 168s 299ms/step - loss: 0.1806 - f1_score: 0.5919 - accuracy: 0.9307 - val_loss: 0.8071 - val_f1_score: 0.5985 - val_accuracy: 0.7400\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 168s 299ms/step - loss: 0.0936 - f1_score: 0.5919 - accuracy: 0.9668 - val_loss: 0.8693 - val_f1_score: 0.5985 - val_accuracy: 0.7390\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 175s 298ms/step - loss: 0.5127 - f1_score: 0.5925 - accuracy: 0.7549 - val_loss: 0.5281 - val_f1_score: 0.5985 - val_accuracy: 0.7270\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 168s 299ms/step - loss: 0.3742 - f1_score: 0.5919 - accuracy: 0.8431 - val_loss: 0.5338 - val_f1_score: 0.5985 - val_accuracy: 0.7550\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 168s 299ms/step - loss: 0.2613 - f1_score: 0.5919 - accuracy: 0.8986 - val_loss: 0.6892 - val_f1_score: 0.5985 - val_accuracy: 0.7530\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 168s 298ms/step - loss: 0.1679 - f1_score: 0.5919 - accuracy: 0.9420 - val_loss: 0.7043 - val_f1_score: 0.5985 - val_accuracy: 0.7210\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 176s 298ms/step - loss: 0.4793 - f1_score: 0.5925 - accuracy: 0.7667 - val_loss: 0.4755 - val_f1_score: 0.5985 - val_accuracy: 0.7670\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 168s 299ms/step - loss: 0.3052 - f1_score: 0.5919 - accuracy: 0.8691 - val_loss: 0.5302 - val_f1_score: 0.5985 - val_accuracy: 0.7800\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 168s 299ms/step - loss: 0.1568 - f1_score: 0.5919 - accuracy: 0.9400 - val_loss: 0.6843 - val_f1_score: 0.5985 - val_accuracy: 0.7780\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 168s 298ms/step - loss: 0.0717 - f1_score: 0.5919 - accuracy: 0.9760 - val_loss: 0.8592 - val_f1_score: 0.5985 - val_accuracy: 0.7640\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 174s 298ms/step - loss: 0.4803 - f1_score: 0.5925 - accuracy: 0.7667 - val_loss: 0.4903 - val_f1_score: 0.5985 - val_accuracy: 0.7630\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 168s 298ms/step - loss: 0.3079 - f1_score: 0.5919 - accuracy: 0.8692 - val_loss: 0.4962 - val_f1_score: 0.5985 - val_accuracy: 0.7870\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 168s 298ms/step - loss: 0.1558 - f1_score: 0.5919 - accuracy: 0.9421 - val_loss: 0.6823 - val_f1_score: 0.5985 - val_accuracy: 0.7780\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 167s 297ms/step - loss: 0.0771 - f1_score: 0.5919 - accuracy: 0.9736 - val_loss: 0.7940 - val_f1_score: 0.5985 - val_accuracy: 0.7570\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 185s 159ms/step - loss: 0.4753 - f1_score: 0.5925 - accuracy: 0.7771 - val_loss: 0.4768 - val_f1_score: 0.5985 - val_accuracy: 0.7730\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.3304 - f1_score: 0.5919 - accuracy: 0.8583 - val_loss: 0.4808 - val_f1_score: 0.5985 - val_accuracy: 0.7680\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.1983 - f1_score: 0.5919 - accuracy: 0.9248 - val_loss: 0.7184 - val_f1_score: 0.5985 - val_accuracy: 0.7440\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.1056 - f1_score: 0.5919 - accuracy: 0.9642 - val_loss: 0.8503 - val_f1_score: 0.5985 - val_accuracy: 0.7480\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 186s 159ms/step - loss: 0.6628 - f1_score: 0.5925 - accuracy: 0.6057 - val_loss: 0.6708 - val_f1_score: 0.5985 - val_accuracy: 0.6090\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.6879 - f1_score: 0.5919 - accuracy: 0.5613 - val_loss: 0.6910 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.6851 - f1_score: 0.5919 - accuracy: 0.5742 - val_loss: 0.6831 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.6842 - f1_score: 0.5919 - accuracy: 0.5746 - val_loss: 0.6825 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 186s 160ms/step - loss: 0.4689 - f1_score: 0.5925 - accuracy: 0.7779 - val_loss: 0.4721 - val_f1_score: 0.5985 - val_accuracy: 0.7620\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.3145 - f1_score: 0.5919 - accuracy: 0.8657 - val_loss: 0.5014 - val_f1_score: 0.5985 - val_accuracy: 0.7830\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.1631 - f1_score: 0.5919 - accuracy: 0.9412 - val_loss: 0.8486 - val_f1_score: 0.5985 - val_accuracy: 0.7460\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.0913 - f1_score: 0.5919 - accuracy: 0.9691 - val_loss: 1.0231 - val_f1_score: 0.5985 - val_accuracy: 0.7410\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 186s 159ms/step - loss: 0.4686 - f1_score: 0.5925 - accuracy: 0.7793 - val_loss: 0.4674 - val_f1_score: 0.5985 - val_accuracy: 0.7780\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.3095 - f1_score: 0.5919 - accuracy: 0.8703 - val_loss: 0.5255 - val_f1_score: 0.5985 - val_accuracy: 0.7890\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.1657 - f1_score: 0.5919 - accuracy: 0.9416 - val_loss: 0.8163 - val_f1_score: 0.5985 - val_accuracy: 0.7540\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 179s 160ms/step - loss: 0.0853 - f1_score: 0.5919 - accuracy: 0.9718 - val_loss: 0.7687 - val_f1_score: 0.5985 - val_accuracy: 0.7620\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 176s 298ms/step - loss: 0.4683 - f1_score: 0.5925 - accuracy: 0.7764 - val_loss: 0.4833 - val_f1_score: 0.5985 - val_accuracy: 0.7700\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 168s 298ms/step - loss: 0.3007 - f1_score: 0.5919 - accuracy: 0.8717 - val_loss: 0.4821 - val_f1_score: 0.5985 - val_accuracy: 0.7700\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 168s 299ms/step - loss: 0.1746 - f1_score: 0.5919 - accuracy: 0.9341 - val_loss: 0.6865 - val_f1_score: 0.5985 - val_accuracy: 0.7560\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 168s 298ms/step - loss: 0.0883 - f1_score: 0.5919 - accuracy: 0.9700 - val_loss: 0.8079 - val_f1_score: 0.5985 - val_accuracy: 0.7620\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 174s 298ms/step - loss: 0.5063 - f1_score: 0.5925 - accuracy: 0.7552 - val_loss: 0.6123 - val_f1_score: 0.5985 - val_accuracy: 0.6500\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 168s 298ms/step - loss: 0.3970 - f1_score: 0.5919 - accuracy: 0.8210 - val_loss: 0.5004 - val_f1_score: 0.5985 - val_accuracy: 0.7580\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 168s 298ms/step - loss: 0.6032 - f1_score: 0.5919 - accuracy: 0.6327 - val_loss: 0.6842 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 168s 299ms/step - loss: 0.6825 - f1_score: 0.5919 - accuracy: 0.5744 - val_loss: 0.6826 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 174s 298ms/step - loss: 0.4625 - f1_score: 0.5925 - accuracy: 0.7794 - val_loss: 0.4696 - val_f1_score: 0.5985 - val_accuracy: 0.7660\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 168s 299ms/step - loss: 0.2985 - f1_score: 0.5919 - accuracy: 0.8713 - val_loss: 0.5579 - val_f1_score: 0.5985 - val_accuracy: 0.7710\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 168s 298ms/step - loss: 0.1528 - f1_score: 0.5919 - accuracy: 0.9419 - val_loss: 0.6297 - val_f1_score: 0.5985 - val_accuracy: 0.7610\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 168s 299ms/step - loss: 0.0734 - f1_score: 0.5919 - accuracy: 0.9753 - val_loss: 0.7975 - val_f1_score: 0.5985 - val_accuracy: 0.7560\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 174s 297ms/step - loss: 0.5017 - f1_score: 0.5925 - accuracy: 0.7518 - val_loss: 0.4811 - val_f1_score: 0.5985 - val_accuracy: 0.7750\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 168s 298ms/step - loss: 0.3372 - f1_score: 0.5919 - accuracy: 0.8566 - val_loss: 0.4851 - val_f1_score: 0.5985 - val_accuracy: 0.7730\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 168s 298ms/step - loss: 0.1911 - f1_score: 0.5919 - accuracy: 0.9222 - val_loss: 0.6307 - val_f1_score: 0.5985 - val_accuracy: 0.7810\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 167s 297ms/step - loss: 0.0886 - f1_score: 0.5919 - accuracy: 0.9697 - val_loss: 0.7645 - val_f1_score: 0.5985 - val_accuracy: 0.7620\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 186s 160ms/step - loss: 0.4829 - f1_score: 0.5925 - accuracy: 0.7690 - val_loss: 0.4722 - val_f1_score: 0.5985 - val_accuracy: 0.7720\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.3282 - f1_score: 0.5919 - accuracy: 0.8608 - val_loss: 0.5134 - val_f1_score: 0.5985 - val_accuracy: 0.7660\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.1869 - f1_score: 0.5919 - accuracy: 0.9296 - val_loss: 0.9104 - val_f1_score: 0.5985 - val_accuracy: 0.7370\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.1056 - f1_score: 0.5919 - accuracy: 0.9629 - val_loss: 0.8409 - val_f1_score: 0.5985 - val_accuracy: 0.7580\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 186s 159ms/step - loss: 0.6802 - f1_score: 0.5925 - accuracy: 0.5828 - val_loss: 0.6896 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.6888 - f1_score: 0.5919 - accuracy: 0.5589 - val_loss: 0.6919 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.6880 - f1_score: 0.5919 - accuracy: 0.5658 - val_loss: 0.6825 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.6887 - f1_score: 0.5919 - accuracy: 0.5717 - val_loss: 0.6825 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 189s 160ms/step - loss: 0.4671 - f1_score: 0.5925 - accuracy: 0.7806 - val_loss: 0.4529 - val_f1_score: 0.5985 - val_accuracy: 0.7950\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.2960 - f1_score: 0.5919 - accuracy: 0.8773 - val_loss: 0.5254 - val_f1_score: 0.5985 - val_accuracy: 0.7770\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.1484 - f1_score: 0.5919 - accuracy: 0.9451 - val_loss: 0.7493 - val_f1_score: 0.5985 - val_accuracy: 0.7690\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.0787 - f1_score: 0.5919 - accuracy: 0.9743 - val_loss: 0.8533 - val_f1_score: 0.5985 - val_accuracy: 0.7570\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 189s 160ms/step - loss: 0.4714 - f1_score: 0.5925 - accuracy: 0.7753 - val_loss: 0.4617 - val_f1_score: 0.5985 - val_accuracy: 0.7790\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.2968 - f1_score: 0.5919 - accuracy: 0.8788 - val_loss: 0.4971 - val_f1_score: 0.5985 - val_accuracy: 0.7830\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 181s 160ms/step - loss: 0.1516 - f1_score: 0.5919 - accuracy: 0.9477 - val_loss: 0.6990 - val_f1_score: 0.5985 - val_accuracy: 0.7800\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.0725 - f1_score: 0.5919 - accuracy: 0.9763 - val_loss: 0.6886 - val_f1_score: 0.5985 - val_accuracy: 0.7810\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 174s 298ms/step - loss: 0.4743 - f1_score: 0.5925 - accuracy: 0.7704 - val_loss: 0.4803 - val_f1_score: 0.5985 - val_accuracy: 0.7650\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 168s 298ms/step - loss: 0.3088 - f1_score: 0.5919 - accuracy: 0.8686 - val_loss: 0.5066 - val_f1_score: 0.5985 - val_accuracy: 0.7810\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 168s 298ms/step - loss: 0.1857 - f1_score: 0.5919 - accuracy: 0.9291 - val_loss: 0.7572 - val_f1_score: 0.5985 - val_accuracy: 0.7700\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 168s 298ms/step - loss: 0.0999 - f1_score: 0.5919 - accuracy: 0.9670 - val_loss: 0.8182 - val_f1_score: 0.5985 - val_accuracy: 0.7660\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 174s 297ms/step - loss: 0.6046 - f1_score: 0.5925 - accuracy: 0.6639 - val_loss: 0.6831 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 167s 297ms/step - loss: 0.6947 - f1_score: 0.5919 - accuracy: 0.5614 - val_loss: 0.6831 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 167s 297ms/step - loss: 0.7070 - f1_score: 0.5919 - accuracy: 0.5431 - val_loss: 0.6844 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 168s 298ms/step - loss: 0.7053 - f1_score: 0.5919 - accuracy: 0.5357 - val_loss: 0.6830 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 174s 297ms/step - loss: 0.4668 - f1_score: 0.5925 - accuracy: 0.7727 - val_loss: 0.4688 - val_f1_score: 0.5985 - val_accuracy: 0.7700\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 167s 298ms/step - loss: 0.3077 - f1_score: 0.5919 - accuracy: 0.8716 - val_loss: 0.4921 - val_f1_score: 0.5985 - val_accuracy: 0.7950\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 167s 297ms/step - loss: 0.1720 - f1_score: 0.5919 - accuracy: 0.9364 - val_loss: 0.6574 - val_f1_score: 0.5985 - val_accuracy: 0.7680\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 167s 298ms/step - loss: 0.0799 - f1_score: 0.5919 - accuracy: 0.9718 - val_loss: 0.8322 - val_f1_score: 0.5985 - val_accuracy: 0.7720\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 174s 296ms/step - loss: 0.4726 - f1_score: 0.5925 - accuracy: 0.7718 - val_loss: 0.4779 - val_f1_score: 0.5985 - val_accuracy: 0.7660\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 167s 297ms/step - loss: 0.2966 - f1_score: 0.5919 - accuracy: 0.8742 - val_loss: 0.4861 - val_f1_score: 0.5985 - val_accuracy: 0.7940\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 167s 296ms/step - loss: 0.1488 - f1_score: 0.5919 - accuracy: 0.9456 - val_loss: 0.6322 - val_f1_score: 0.5985 - val_accuracy: 0.7620\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 167s 297ms/step - loss: 0.0712 - f1_score: 0.5919 - accuracy: 0.9754 - val_loss: 0.9535 - val_f1_score: 0.5985 - val_accuracy: 0.7430\n"
     ]
    }
   ],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "learning_rates = [5e-5, 1e-4, 3e-5, 3e-5]\n",
    "learning_rates_text = ['5e-5', '1e-4', '3e-5', '3e-5']\n",
    "batch_sizes = [8, 16]\n",
    "dropout = [.5,.75,.25,0.0,.1]\n",
    "results = {}\n",
    "results_acc = {}\n",
    "best_epochs = {}\n",
    "for do in dropout:\n",
    "    for bs in batch_sizes:\n",
    "        for lr in range(len(learning_rates)):\n",
    "            np.random.seed(42)\n",
    "            tf.random.set_seed(42)\n",
    "            string = 'lr{lr}_bs{bs}_do{do}'.format(lr=learning_rates_text[lr], bs=bs, do=do)\n",
    "\n",
    "            bert = build_classifier_model(do, trainable=True)\n",
    "            bert.compile(loss=loss, optimizer=Adam(learning_rate=learning_rates[lr]), metrics=[f1, 'accuracy'])\n",
    "            history = bert.fit(x=x_train,\n",
    "                               y=y_train, batch_size=bs,\n",
    "                               validation_data=(x_val, y_val),\n",
    "                               epochs=4)\n",
    "\n",
    "            max_f1 = max(history.history['val_f1_score'])\n",
    "            max_acc = max(history.history['val_accuracy'])\n",
    "            val_acc_per_epoch = history.history['val_accuracy']\n",
    "            best_epoch = val_acc_per_epoch.index(max_acc) + 1\n",
    "            results[string] = max_f1\n",
    "            results_acc[string] = max_acc\n",
    "            best_epochs[string] = best_epoch\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "{'lr5e-5_bs8_do0.5': array([0.5984583], dtype=float32),\n 'lr1e-4_bs8_do0.5': array([0.5984583], dtype=float32),\n 'lr3e-5_bs8_do0.5': array([0.5984583], dtype=float32),\n 'lr5e-5_bs16_do0.5': array([0.5984583], dtype=float32),\n 'lr1e-4_bs16_do0.5': array([0.5984583], dtype=float32),\n 'lr3e-5_bs16_do0.5': array([0.5984583], dtype=float32),\n 'lr5e-5_bs8_do0.75': array([0.5984583], dtype=float32),\n 'lr1e-4_bs8_do0.75': array([0.5984583], dtype=float32),\n 'lr3e-5_bs8_do0.75': array([0.5984583], dtype=float32),\n 'lr5e-5_bs16_do0.75': array([0.5984583], dtype=float32),\n 'lr1e-4_bs16_do0.75': array([0.5984583], dtype=float32),\n 'lr3e-5_bs16_do0.75': array([0.5984583], dtype=float32),\n 'lr5e-5_bs8_do0.25': array([0.5984583], dtype=float32),\n 'lr1e-4_bs8_do0.25': array([0.5984583], dtype=float32),\n 'lr3e-5_bs8_do0.25': array([0.5984583], dtype=float32),\n 'lr5e-5_bs16_do0.25': array([0.5984583], dtype=float32),\n 'lr1e-4_bs16_do0.25': array([0.5984583], dtype=float32),\n 'lr3e-5_bs16_do0.25': array([0.5984583], dtype=float32),\n 'lr5e-5_bs8_do0.0': array([0.5984583], dtype=float32),\n 'lr1e-4_bs8_do0.0': array([0.5984583], dtype=float32),\n 'lr3e-5_bs8_do0.0': array([0.5984583], dtype=float32),\n 'lr5e-5_bs16_do0.0': array([0.5984583], dtype=float32),\n 'lr1e-4_bs16_do0.0': array([0.5984583], dtype=float32),\n 'lr3e-5_bs16_do0.0': array([0.5984583], dtype=float32),\n 'lr5e-5_bs8_do0.1': array([0.5984583], dtype=float32),\n 'lr1e-4_bs8_do0.1': array([0.5984583], dtype=float32),\n 'lr3e-5_bs8_do0.1': array([0.5984583], dtype=float32),\n 'lr5e-5_bs16_do0.1': array([0.5984583], dtype=float32),\n 'lr1e-4_bs16_do0.1': array([0.5984583], dtype=float32),\n 'lr3e-5_bs16_do0.1': array([0.5984583], dtype=float32)}"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "results2 = {}\n",
    "results2_acc = {}\n",
    "best_epochs2 = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 63s 53ms/step - loss: 0.7632 - f1_score: 0.5925 - accuracy: 0.5301 - val_loss: 0.6809 - val_f1_score: 0.5985 - val_accuracy: 0.5660\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.7418 - f1_score: 0.5919 - accuracy: 0.5403 - val_loss: 0.6722 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.7353 - f1_score: 0.5919 - accuracy: 0.5449 - val_loss: 0.6652 - val_f1_score: 0.5985 - val_accuracy: 0.5820\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.7267 - f1_score: 0.5919 - accuracy: 0.5452 - val_loss: 0.6605 - val_f1_score: 0.5985 - val_accuracy: 0.5870\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 64s 53ms/step - loss: 0.7556 - f1_score: 0.5925 - accuracy: 0.5333 - val_loss: 0.6717 - val_f1_score: 0.5985 - val_accuracy: 0.5740\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 60s 54ms/step - loss: 0.7268 - f1_score: 0.5919 - accuracy: 0.5500 - val_loss: 0.6615 - val_f1_score: 0.5985 - val_accuracy: 0.5830\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 60s 54ms/step - loss: 0.7149 - f1_score: 0.5919 - accuracy: 0.5587 - val_loss: 0.6528 - val_f1_score: 0.5985 - val_accuracy: 0.5950\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 60s 54ms/step - loss: 0.7014 - f1_score: 0.5919 - accuracy: 0.5634 - val_loss: 0.6478 - val_f1_score: 0.5985 - val_accuracy: 0.6020\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 63s 53ms/step - loss: 0.7679 - f1_score: 0.5925 - accuracy: 0.5299 - val_loss: 0.6863 - val_f1_score: 0.5985 - val_accuracy: 0.5680\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.7491 - f1_score: 0.5919 - accuracy: 0.5374 - val_loss: 0.6789 - val_f1_score: 0.5985 - val_accuracy: 0.5680\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.7457 - f1_score: 0.5919 - accuracy: 0.5368 - val_loss: 0.6735 - val_f1_score: 0.5985 - val_accuracy: 0.5750\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.7402 - f1_score: 0.5919 - accuracy: 0.5367 - val_loss: 0.6690 - val_f1_score: 0.5985 - val_accuracy: 0.5780\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 63s 53ms/step - loss: 0.7679 - f1_score: 0.5925 - accuracy: 0.5299 - val_loss: 0.6863 - val_f1_score: 0.5985 - val_accuracy: 0.5680\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.7491 - f1_score: 0.5919 - accuracy: 0.5374 - val_loss: 0.6789 - val_f1_score: 0.5985 - val_accuracy: 0.5680\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.7457 - f1_score: 0.5919 - accuracy: 0.5368 - val_loss: 0.6735 - val_f1_score: 0.5985 - val_accuracy: 0.5750\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 60s 54ms/step - loss: 0.7402 - f1_score: 0.5919 - accuracy: 0.5367 - val_loss: 0.6690 - val_f1_score: 0.5985 - val_accuracy: 0.5780\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 62s 104ms/step - loss: 0.7605 - f1_score: 0.5925 - accuracy: 0.5316 - val_loss: 0.6845 - val_f1_score: 0.5985 - val_accuracy: 0.5670\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.7396 - f1_score: 0.5919 - accuracy: 0.5417 - val_loss: 0.6770 - val_f1_score: 0.5985 - val_accuracy: 0.5710\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.7399 - f1_score: 0.5919 - accuracy: 0.5420 - val_loss: 0.6720 - val_f1_score: 0.5985 - val_accuracy: 0.5720\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.7364 - f1_score: 0.5919 - accuracy: 0.5426 - val_loss: 0.6667 - val_f1_score: 0.5985 - val_accuracy: 0.5800\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 62s 104ms/step - loss: 0.7537 - f1_score: 0.5925 - accuracy: 0.5339 - val_loss: 0.6765 - val_f1_score: 0.5985 - val_accuracy: 0.5710\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.7287 - f1_score: 0.5919 - accuracy: 0.5488 - val_loss: 0.6670 - val_f1_score: 0.5985 - val_accuracy: 0.5760\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.7243 - f1_score: 0.5919 - accuracy: 0.5539 - val_loss: 0.6598 - val_f1_score: 0.5985 - val_accuracy: 0.5860\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.7158 - f1_score: 0.5919 - accuracy: 0.5570 - val_loss: 0.6546 - val_f1_score: 0.5985 - val_accuracy: 0.5890\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 62s 104ms/step - loss: 0.7654 - f1_score: 0.5925 - accuracy: 0.5346 - val_loss: 0.6891 - val_f1_score: 0.5985 - val_accuracy: 0.5690\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.7448 - f1_score: 0.5919 - accuracy: 0.5419 - val_loss: 0.6829 - val_f1_score: 0.5985 - val_accuracy: 0.5660\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.7477 - f1_score: 0.5919 - accuracy: 0.5378 - val_loss: 0.6791 - val_f1_score: 0.5985 - val_accuracy: 0.5660\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.7469 - f1_score: 0.5919 - accuracy: 0.5367 - val_loss: 0.6745 - val_f1_score: 0.5985 - val_accuracy: 0.5720\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 63s 104ms/step - loss: 0.7654 - f1_score: 0.5925 - accuracy: 0.5346 - val_loss: 0.6891 - val_f1_score: 0.5985 - val_accuracy: 0.5690\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.7448 - f1_score: 0.5919 - accuracy: 0.5419 - val_loss: 0.6829 - val_f1_score: 0.5985 - val_accuracy: 0.5660\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.7477 - f1_score: 0.5919 - accuracy: 0.5378 - val_loss: 0.6791 - val_f1_score: 0.5985 - val_accuracy: 0.5660\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.7469 - f1_score: 0.5919 - accuracy: 0.5367 - val_loss: 0.6745 - val_f1_score: 0.5985 - val_accuracy: 0.5720\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 65s 53ms/step - loss: 0.8916 - f1_score: 0.5925 - accuracy: 0.5192 - val_loss: 0.6873 - val_f1_score: 0.5985 - val_accuracy: 0.5710\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 59s 53ms/step - loss: 0.8536 - f1_score: 0.5919 - accuracy: 0.5252 - val_loss: 0.6787 - val_f1_score: 0.5985 - val_accuracy: 0.5680\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.8271 - f1_score: 0.5919 - accuracy: 0.5349 - val_loss: 0.6728 - val_f1_score: 0.5985 - val_accuracy: 0.5760\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.8229 - f1_score: 0.5919 - accuracy: 0.5274 - val_loss: 0.6676 - val_f1_score: 0.5985 - val_accuracy: 0.5810\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 65s 53ms/step - loss: 0.8775 - f1_score: 0.5925 - accuracy: 0.5194 - val_loss: 0.6791 - val_f1_score: 0.5985 - val_accuracy: 0.5700\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.8226 - f1_score: 0.5919 - accuracy: 0.5324 - val_loss: 0.6685 - val_f1_score: 0.5985 - val_accuracy: 0.5760\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 60s 54ms/step - loss: 0.7846 - f1_score: 0.5919 - accuracy: 0.5418 - val_loss: 0.6603 - val_f1_score: 0.5985 - val_accuracy: 0.5880\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 60s 54ms/step - loss: 0.7663 - f1_score: 0.5919 - accuracy: 0.5402 - val_loss: 0.6554 - val_f1_score: 0.5985 - val_accuracy: 0.5900\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 65s 53ms/step - loss: 0.8992 - f1_score: 0.5925 - accuracy: 0.5204 - val_loss: 0.6919 - val_f1_score: 0.5985 - val_accuracy: 0.5710\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.8678 - f1_score: 0.5919 - accuracy: 0.5227 - val_loss: 0.6849 - val_f1_score: 0.5985 - val_accuracy: 0.5710\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 60s 54ms/step - loss: 0.8478 - f1_score: 0.5919 - accuracy: 0.5321 - val_loss: 0.6802 - val_f1_score: 0.5985 - val_accuracy: 0.5700\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 60s 54ms/step - loss: 0.8521 - f1_score: 0.5919 - accuracy: 0.5236 - val_loss: 0.6763 - val_f1_score: 0.5985 - val_accuracy: 0.5720\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 66s 53ms/step - loss: 0.8992 - f1_score: 0.5925 - accuracy: 0.5204 - val_loss: 0.6919 - val_f1_score: 0.5985 - val_accuracy: 0.5710\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.8678 - f1_score: 0.5919 - accuracy: 0.5227 - val_loss: 0.6849 - val_f1_score: 0.5985 - val_accuracy: 0.5710\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.8478 - f1_score: 0.5919 - accuracy: 0.5321 - val_loss: 0.6802 - val_f1_score: 0.5985 - val_accuracy: 0.5700\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.8521 - f1_score: 0.5919 - accuracy: 0.5236 - val_loss: 0.6763 - val_f1_score: 0.5985 - val_accuracy: 0.5720\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 65s 105ms/step - loss: 0.8963 - f1_score: 0.5925 - accuracy: 0.5261 - val_loss: 0.6894 - val_f1_score: 0.5985 - val_accuracy: 0.5720\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.8436 - f1_score: 0.5919 - accuracy: 0.5404 - val_loss: 0.6823 - val_f1_score: 0.5985 - val_accuracy: 0.5670\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.8518 - f1_score: 0.5919 - accuracy: 0.5300 - val_loss: 0.6782 - val_f1_score: 0.5985 - val_accuracy: 0.5710\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.8429 - f1_score: 0.5919 - accuracy: 0.5250 - val_loss: 0.6733 - val_f1_score: 0.5985 - val_accuracy: 0.5770\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 64s 104ms/step - loss: 0.8846 - f1_score: 0.5925 - accuracy: 0.5241 - val_loss: 0.6823 - val_f1_score: 0.5985 - val_accuracy: 0.5690\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.8219 - f1_score: 0.5919 - accuracy: 0.5449 - val_loss: 0.6732 - val_f1_score: 0.5985 - val_accuracy: 0.5720\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.8166 - f1_score: 0.5919 - accuracy: 0.5374 - val_loss: 0.6669 - val_f1_score: 0.5985 - val_accuracy: 0.5820\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.7970 - f1_score: 0.5919 - accuracy: 0.5330 - val_loss: 0.6612 - val_f1_score: 0.5985 - val_accuracy: 0.5870\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 65s 104ms/step - loss: 0.9033 - f1_score: 0.5925 - accuracy: 0.5270 - val_loss: 0.6935 - val_f1_score: 0.5985 - val_accuracy: 0.5700\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.8533 - f1_score: 0.5919 - accuracy: 0.5392 - val_loss: 0.6873 - val_f1_score: 0.5985 - val_accuracy: 0.5700\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.8681 - f1_score: 0.5919 - accuracy: 0.5263 - val_loss: 0.6844 - val_f1_score: 0.5985 - val_accuracy: 0.5700\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.8651 - f1_score: 0.5919 - accuracy: 0.5224 - val_loss: 0.6812 - val_f1_score: 0.5985 - val_accuracy: 0.5700\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 63s 104ms/step - loss: 0.9033 - f1_score: 0.5925 - accuracy: 0.5270 - val_loss: 0.6935 - val_f1_score: 0.5985 - val_accuracy: 0.5700\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.8533 - f1_score: 0.5919 - accuracy: 0.5392 - val_loss: 0.6873 - val_f1_score: 0.5985 - val_accuracy: 0.5700\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.8681 - f1_score: 0.5919 - accuracy: 0.5263 - val_loss: 0.6844 - val_f1_score: 0.5985 - val_accuracy: 0.5700\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.8651 - f1_score: 0.5919 - accuracy: 0.5224 - val_loss: 0.6812 - val_f1_score: 0.5985 - val_accuracy: 0.5700\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 63s 53ms/step - loss: 0.7100 - f1_score: 0.5925 - accuracy: 0.5422 - val_loss: 0.6780 - val_f1_score: 0.5985 - val_accuracy: 0.5700\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.6965 - f1_score: 0.5919 - accuracy: 0.5571 - val_loss: 0.6684 - val_f1_score: 0.5985 - val_accuracy: 0.5760\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.6924 - f1_score: 0.5919 - accuracy: 0.5580 - val_loss: 0.6616 - val_f1_score: 0.5985 - val_accuracy: 0.5850\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 60s 54ms/step - loss: 0.6845 - f1_score: 0.5919 - accuracy: 0.5708 - val_loss: 0.6564 - val_f1_score: 0.5985 - val_accuracy: 0.5880\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 63s 53ms/step - loss: 0.7040 - f1_score: 0.5925 - accuracy: 0.5450 - val_loss: 0.6682 - val_f1_score: 0.5985 - val_accuracy: 0.5780\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.6858 - f1_score: 0.5919 - accuracy: 0.5712 - val_loss: 0.6565 - val_f1_score: 0.5985 - val_accuracy: 0.5850\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.6780 - f1_score: 0.5919 - accuracy: 0.5781 - val_loss: 0.6492 - val_f1_score: 0.5985 - val_accuracy: 0.6120\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 60s 54ms/step - loss: 0.6676 - f1_score: 0.5919 - accuracy: 0.5903 - val_loss: 0.6424 - val_f1_score: 0.5985 - val_accuracy: 0.6010\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 63s 53ms/step - loss: 0.7140 - f1_score: 0.5925 - accuracy: 0.5448 - val_loss: 0.6837 - val_f1_score: 0.5985 - val_accuracy: 0.5650\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.7021 - f1_score: 0.5919 - accuracy: 0.5518 - val_loss: 0.6758 - val_f1_score: 0.5985 - val_accuracy: 0.5680\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.7002 - f1_score: 0.5919 - accuracy: 0.5464 - val_loss: 0.6700 - val_f1_score: 0.5985 - val_accuracy: 0.5780\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.6940 - f1_score: 0.5919 - accuracy: 0.5597 - val_loss: 0.6655 - val_f1_score: 0.5985 - val_accuracy: 0.5770\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 63s 53ms/step - loss: 0.7140 - f1_score: 0.5925 - accuracy: 0.5448 - val_loss: 0.6837 - val_f1_score: 0.5985 - val_accuracy: 0.5650\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.7021 - f1_score: 0.5919 - accuracy: 0.5518 - val_loss: 0.6758 - val_f1_score: 0.5985 - val_accuracy: 0.5680\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.7002 - f1_score: 0.5919 - accuracy: 0.5464 - val_loss: 0.6700 - val_f1_score: 0.5985 - val_accuracy: 0.5780\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.6940 - f1_score: 0.5919 - accuracy: 0.5597 - val_loss: 0.6655 - val_f1_score: 0.5985 - val_accuracy: 0.5770\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 63s 105ms/step - loss: 0.7136 - f1_score: 0.5925 - accuracy: 0.5432 - val_loss: 0.6822 - val_f1_score: 0.5985 - val_accuracy: 0.5670\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.7012 - f1_score: 0.5919 - accuracy: 0.5527 - val_loss: 0.6739 - val_f1_score: 0.5985 - val_accuracy: 0.5680\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 59s 106ms/step - loss: 0.6962 - f1_score: 0.5919 - accuracy: 0.5569 - val_loss: 0.6679 - val_f1_score: 0.5985 - val_accuracy: 0.5810\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.6923 - f1_score: 0.5919 - accuracy: 0.5621 - val_loss: 0.6631 - val_f1_score: 0.5985 - val_accuracy: 0.5820\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 63s 104ms/step - loss: 0.7078 - f1_score: 0.5925 - accuracy: 0.5447 - val_loss: 0.6736 - val_f1_score: 0.5985 - val_accuracy: 0.5670\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.6924 - f1_score: 0.5919 - accuracy: 0.5647 - val_loss: 0.6630 - val_f1_score: 0.5985 - val_accuracy: 0.5800\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.6844 - f1_score: 0.5919 - accuracy: 0.5734 - val_loss: 0.6562 - val_f1_score: 0.5985 - val_accuracy: 0.5870\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 59s 105ms/step - loss: 0.6777 - f1_score: 0.5919 - accuracy: 0.5782 - val_loss: 0.6501 - val_f1_score: 0.5985 - val_accuracy: 0.5890\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 65s 106ms/step - loss: 0.7181 - f1_score: 0.5925 - accuracy: 0.5437 - val_loss: 0.6872 - val_f1_score: 0.5985 - val_accuracy: 0.5590\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 60s 106ms/step - loss: 0.7057 - f1_score: 0.5919 - accuracy: 0.5473 - val_loss: 0.6805 - val_f1_score: 0.5985 - val_accuracy: 0.5660\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 66s 118ms/step - loss: 0.7023 - f1_score: 0.5919 - accuracy: 0.5484 - val_loss: 0.6756 - val_f1_score: 0.5985 - val_accuracy: 0.5670\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 66s 118ms/step - loss: 0.7003 - f1_score: 0.5919 - accuracy: 0.5507 - val_loss: 0.6714 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 72s 117ms/step - loss: 0.7181 - f1_score: 0.5925 - accuracy: 0.5437 - val_loss: 0.6872 - val_f1_score: 0.5985 - val_accuracy: 0.5590\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 66s 117ms/step - loss: 0.7057 - f1_score: 0.5919 - accuracy: 0.5473 - val_loss: 0.6805 - val_f1_score: 0.5985 - val_accuracy: 0.5660\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 66s 118ms/step - loss: 0.7023 - f1_score: 0.5919 - accuracy: 0.5484 - val_loss: 0.6756 - val_f1_score: 0.5985 - val_accuracy: 0.5670\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 66s 117ms/step - loss: 0.7003 - f1_score: 0.5919 - accuracy: 0.5507 - val_loss: 0.6714 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 71s 60ms/step - loss: 0.6845 - f1_score: 0.5925 - accuracy: 0.5710 - val_loss: 0.6763 - val_f1_score: 0.5985 - val_accuracy: 0.5660\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 65s 58ms/step - loss: 0.6708 - f1_score: 0.5919 - accuracy: 0.5768 - val_loss: 0.6658 - val_f1_score: 0.5985 - val_accuracy: 0.5800\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 67s 59ms/step - loss: 0.6629 - f1_score: 0.5919 - accuracy: 0.5856 - val_loss: 0.6596 - val_f1_score: 0.5985 - val_accuracy: 0.5860\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 66s 58ms/step - loss: 0.6559 - f1_score: 0.5919 - accuracy: 0.5969 - val_loss: 0.6530 - val_f1_score: 0.5985 - val_accuracy: 0.5930\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 71s 58ms/step - loss: 0.6789 - f1_score: 0.5925 - accuracy: 0.5714 - val_loss: 0.6661 - val_f1_score: 0.5985 - val_accuracy: 0.5790\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 66s 58ms/step - loss: 0.6601 - f1_score: 0.5919 - accuracy: 0.5907 - val_loss: 0.6532 - val_f1_score: 0.5985 - val_accuracy: 0.5890\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 66s 59ms/step - loss: 0.6492 - f1_score: 0.5919 - accuracy: 0.6073 - val_loss: 0.6476 - val_f1_score: 0.5985 - val_accuracy: 0.6240\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 66s 59ms/step - loss: 0.6397 - f1_score: 0.5919 - accuracy: 0.6252 - val_loss: 0.6384 - val_f1_score: 0.5985 - val_accuracy: 0.6110\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 72s 58ms/step - loss: 0.6884 - f1_score: 0.5925 - accuracy: 0.5718 - val_loss: 0.6822 - val_f1_score: 0.5985 - val_accuracy: 0.5640\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 66s 59ms/step - loss: 0.6767 - f1_score: 0.5919 - accuracy: 0.5701 - val_loss: 0.6737 - val_f1_score: 0.5985 - val_accuracy: 0.5670\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 66s 59ms/step - loss: 0.6707 - f1_score: 0.5919 - accuracy: 0.5768 - val_loss: 0.6677 - val_f1_score: 0.5985 - val_accuracy: 0.5860\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 66s 59ms/step - loss: 0.6651 - f1_score: 0.5919 - accuracy: 0.5816 - val_loss: 0.6627 - val_f1_score: 0.5985 - val_accuracy: 0.5840\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 72s 59ms/step - loss: 0.6884 - f1_score: 0.5925 - accuracy: 0.5718 - val_loss: 0.6822 - val_f1_score: 0.5985 - val_accuracy: 0.5640\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 66s 59ms/step - loss: 0.6767 - f1_score: 0.5919 - accuracy: 0.5701 - val_loss: 0.6737 - val_f1_score: 0.5985 - val_accuracy: 0.5670\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 67s 59ms/step - loss: 0.6707 - f1_score: 0.5919 - accuracy: 0.5768 - val_loss: 0.6677 - val_f1_score: 0.5985 - val_accuracy: 0.5860\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 66s 59ms/step - loss: 0.6651 - f1_score: 0.5919 - accuracy: 0.5816 - val_loss: 0.6627 - val_f1_score: 0.5985 - val_accuracy: 0.5840\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 71s 120ms/step - loss: 0.6878 - f1_score: 0.5925 - accuracy: 0.5720 - val_loss: 0.6809 - val_f1_score: 0.5985 - val_accuracy: 0.5640\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 65s 115ms/step - loss: 0.6754 - f1_score: 0.5919 - accuracy: 0.5717 - val_loss: 0.6718 - val_f1_score: 0.5985 - val_accuracy: 0.5760\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 65s 115ms/step - loss: 0.6689 - f1_score: 0.5919 - accuracy: 0.5784 - val_loss: 0.6655 - val_f1_score: 0.5985 - val_accuracy: 0.5870\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 65s 115ms/step - loss: 0.6629 - f1_score: 0.5919 - accuracy: 0.5846 - val_loss: 0.6602 - val_f1_score: 0.5985 - val_accuracy: 0.5880\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 68s 114ms/step - loss: 0.6820 - f1_score: 0.5925 - accuracy: 0.5700 - val_loss: 0.6718 - val_f1_score: 0.5985 - val_accuracy: 0.5710\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 65s 115ms/step - loss: 0.6662 - f1_score: 0.5919 - accuracy: 0.5814 - val_loss: 0.6600 - val_f1_score: 0.5985 - val_accuracy: 0.5850\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 65s 115ms/step - loss: 0.6570 - f1_score: 0.5919 - accuracy: 0.5952 - val_loss: 0.6544 - val_f1_score: 0.5985 - val_accuracy: 0.6010\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 65s 115ms/step - loss: 0.6488 - f1_score: 0.5919 - accuracy: 0.6068 - val_loss: 0.6463 - val_f1_score: 0.5985 - val_accuracy: 0.5950\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 69s 115ms/step - loss: 0.6923 - f1_score: 0.5925 - accuracy: 0.5719 - val_loss: 0.6861 - val_f1_score: 0.5985 - val_accuracy: 0.5590\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 66s 118ms/step - loss: 0.6802 - f1_score: 0.5919 - accuracy: 0.5696 - val_loss: 0.6789 - val_f1_score: 0.5985 - val_accuracy: 0.5660\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 65s 115ms/step - loss: 0.6754 - f1_score: 0.5919 - accuracy: 0.5726 - val_loss: 0.6734 - val_f1_score: 0.5985 - val_accuracy: 0.5740\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 61s 109ms/step - loss: 0.6708 - f1_score: 0.5919 - accuracy: 0.5780 - val_loss: 0.6691 - val_f1_score: 0.5985 - val_accuracy: 0.5750\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 65s 108ms/step - loss: 0.6923 - f1_score: 0.5925 - accuracy: 0.5719 - val_loss: 0.6861 - val_f1_score: 0.5985 - val_accuracy: 0.5590\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 61s 109ms/step - loss: 0.6802 - f1_score: 0.5919 - accuracy: 0.5696 - val_loss: 0.6789 - val_f1_score: 0.5985 - val_accuracy: 0.5660\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 61s 109ms/step - loss: 0.6754 - f1_score: 0.5919 - accuracy: 0.5726 - val_loss: 0.6734 - val_f1_score: 0.5985 - val_accuracy: 0.5740\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6708 - f1_score: 0.5919 - accuracy: 0.5780 - val_loss: 0.6691 - val_f1_score: 0.5985 - val_accuracy: 0.5750\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 64s 53ms/step - loss: 0.6918 - f1_score: 0.5925 - accuracy: 0.5588 - val_loss: 0.6766 - val_f1_score: 0.5985 - val_accuracy: 0.5680\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.6775 - f1_score: 0.5919 - accuracy: 0.5717 - val_loss: 0.6669 - val_f1_score: 0.5985 - val_accuracy: 0.5770\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 60s 54ms/step - loss: 0.6723 - f1_score: 0.5919 - accuracy: 0.5787 - val_loss: 0.6602 - val_f1_score: 0.5985 - val_accuracy: 0.5910\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 60s 54ms/step - loss: 0.6663 - f1_score: 0.5919 - accuracy: 0.5856 - val_loss: 0.6542 - val_f1_score: 0.5985 - val_accuracy: 0.5920\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 64s 53ms/step - loss: 0.6862 - f1_score: 0.5925 - accuracy: 0.5601 - val_loss: 0.6664 - val_f1_score: 0.5985 - val_accuracy: 0.5810\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 60s 54ms/step - loss: 0.6671 - f1_score: 0.5919 - accuracy: 0.5838 - val_loss: 0.6548 - val_f1_score: 0.5985 - val_accuracy: 0.5850\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 61s 54ms/step - loss: 0.6589 - f1_score: 0.5919 - accuracy: 0.5983 - val_loss: 0.6479 - val_f1_score: 0.5985 - val_accuracy: 0.6190\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 61s 54ms/step - loss: 0.6505 - f1_score: 0.5919 - accuracy: 0.6098 - val_loss: 0.6397 - val_f1_score: 0.5985 - val_accuracy: 0.6100\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 64s 53ms/step - loss: 0.6958 - f1_score: 0.5925 - accuracy: 0.5589 - val_loss: 0.6825 - val_f1_score: 0.5985 - val_accuracy: 0.5640\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.6831 - f1_score: 0.5919 - accuracy: 0.5649 - val_loss: 0.6744 - val_f1_score: 0.5985 - val_accuracy: 0.5690\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.6799 - f1_score: 0.5919 - accuracy: 0.5701 - val_loss: 0.6684 - val_f1_score: 0.5985 - val_accuracy: 0.5850\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 61s 54ms/step - loss: 0.6754 - f1_score: 0.5919 - accuracy: 0.5734 - val_loss: 0.6637 - val_f1_score: 0.5985 - val_accuracy: 0.5820\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 64s 54ms/step - loss: 0.6958 - f1_score: 0.5925 - accuracy: 0.5589 - val_loss: 0.6825 - val_f1_score: 0.5985 - val_accuracy: 0.5640\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 60s 54ms/step - loss: 0.6831 - f1_score: 0.5919 - accuracy: 0.5649 - val_loss: 0.6744 - val_f1_score: 0.5985 - val_accuracy: 0.5690\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 62s 55ms/step - loss: 0.6799 - f1_score: 0.5919 - accuracy: 0.5701 - val_loss: 0.6684 - val_f1_score: 0.5985 - val_accuracy: 0.5850\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 68s 60ms/step - loss: 0.6754 - f1_score: 0.5919 - accuracy: 0.5734 - val_loss: 0.6637 - val_f1_score: 0.5985 - val_accuracy: 0.5820\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 71s 119ms/step - loss: 0.6952 - f1_score: 0.5925 - accuracy: 0.5543 - val_loss: 0.6813 - val_f1_score: 0.5985 - val_accuracy: 0.5670\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 67s 119ms/step - loss: 0.6826 - f1_score: 0.5919 - accuracy: 0.5654 - val_loss: 0.6725 - val_f1_score: 0.5985 - val_accuracy: 0.5680\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 67s 119ms/step - loss: 0.6802 - f1_score: 0.5919 - accuracy: 0.5689 - val_loss: 0.6662 - val_f1_score: 0.5985 - val_accuracy: 0.5840\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 67s 120ms/step - loss: 0.6732 - f1_score: 0.5919 - accuracy: 0.5788 - val_loss: 0.6611 - val_f1_score: 0.5985 - val_accuracy: 0.5870\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 67s 113ms/step - loss: 0.6895 - f1_score: 0.5925 - accuracy: 0.5588 - val_loss: 0.6723 - val_f1_score: 0.5985 - val_accuracy: 0.5710\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 64s 114ms/step - loss: 0.6736 - f1_score: 0.5919 - accuracy: 0.5792 - val_loss: 0.6611 - val_f1_score: 0.5985 - val_accuracy: 0.5800\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 64s 114ms/step - loss: 0.6685 - f1_score: 0.5919 - accuracy: 0.5848 - val_loss: 0.6545 - val_f1_score: 0.5985 - val_accuracy: 0.6010\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 64s 114ms/step - loss: 0.6591 - f1_score: 0.5919 - accuracy: 0.5966 - val_loss: 0.6474 - val_f1_score: 0.5985 - val_accuracy: 0.5970\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 68s 113ms/step - loss: 0.6997 - f1_score: 0.5925 - accuracy: 0.5579 - val_loss: 0.6865 - val_f1_score: 0.5985 - val_accuracy: 0.5590\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 64s 114ms/step - loss: 0.6873 - f1_score: 0.5919 - accuracy: 0.5611 - val_loss: 0.6794 - val_f1_score: 0.5985 - val_accuracy: 0.5650\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 64s 114ms/step - loss: 0.6865 - f1_score: 0.5919 - accuracy: 0.5626 - val_loss: 0.6741 - val_f1_score: 0.5985 - val_accuracy: 0.5710\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 64s 114ms/step - loss: 0.6810 - f1_score: 0.5919 - accuracy: 0.5689 - val_loss: 0.6698 - val_f1_score: 0.5985 - val_accuracy: 0.5740\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 69s 113ms/step - loss: 0.6997 - f1_score: 0.5925 - accuracy: 0.5579 - val_loss: 0.6865 - val_f1_score: 0.5985 - val_accuracy: 0.5590\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 64s 114ms/step - loss: 0.6873 - f1_score: 0.5919 - accuracy: 0.5611 - val_loss: 0.6794 - val_f1_score: 0.5985 - val_accuracy: 0.5650\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 64s 115ms/step - loss: 0.6865 - f1_score: 0.5919 - accuracy: 0.5626 - val_loss: 0.6741 - val_f1_score: 0.5985 - val_accuracy: 0.5710\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 64s 114ms/step - loss: 0.6810 - f1_score: 0.5919 - accuracy: 0.5689 - val_loss: 0.6698 - val_f1_score: 0.5985 - val_accuracy: 0.5740\n"
     ]
    }
   ],
   "source": [
    "for do in dropout:\n",
    "    for bs in batch_sizes:\n",
    "        for lr in range(len(learning_rates)):\n",
    "            np.random.seed(42)\n",
    "            tf.random.set_seed(42)\n",
    "            string = 'lr{lr}_bs{bs}_do{do}'.format(lr=learning_rates_text[lr],bs=bs,do=do)\n",
    "            #filepath = 'checkpoints/bert_finetuned/lr{lr}_bs{bs}.hdf5'.format(lr=learning_rates_text[lr],bs=bs)\n",
    "            #checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
    "                                                 #    monitor='val_f1_score',\n",
    "                                                  #  save_best_only=True,\n",
    "                                                   #  verbose=1,)\n",
    "            #callbacks = [checkpoint]\n",
    "\n",
    "            bert = build_classifier_model(do,trainable=False)\n",
    "            bert.compile(loss = loss, optimizer = Adam(learning_rate=learning_rates[lr]), metrics = [f1,'accuracy'])\n",
    "            history = bert.fit(x=x_train,\n",
    "                                y=y_train,batch_size=bs,\n",
    "                                validation_data=(x_val,y_val),\n",
    "                                epochs=4)\n",
    "\n",
    "            max_f1 = max(history.history['val_f1_score'])\n",
    "            max_acc = max(history.history['val_accuracy'])\n",
    "            results2[string] = max_f1\n",
    "            results2_acc[string] = max_acc\n",
    "            val_acc_per_epoch = history.history['val_accuracy']\n",
    "            best_epoch = val_acc_per_epoch.index(max_acc) + 1\n",
    "            best_epochs2[string] = best_epoch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "{'lr5e-5_bs8_do0.5': array([0.5984583], dtype=float32),\n 'lr1e-4_bs8_do0.5': array([0.5984583], dtype=float32),\n 'lr3e-5_bs8_do0.5': array([0.5984583], dtype=float32),\n 'lr5e-5_bs16_do0.5': array([0.5984583], dtype=float32),\n 'lr1e-4_bs16_do0.5': array([0.5984583], dtype=float32),\n 'lr3e-5_bs16_do0.5': array([0.5984583], dtype=float32),\n 'lr5e-5_bs8_do0.75': array([0.5984583], dtype=float32),\n 'lr1e-4_bs8_do0.75': array([0.5984583], dtype=float32),\n 'lr3e-5_bs8_do0.75': array([0.5984583], dtype=float32),\n 'lr5e-5_bs16_do0.75': array([0.5984583], dtype=float32),\n 'lr1e-4_bs16_do0.75': array([0.5984583], dtype=float32),\n 'lr3e-5_bs16_do0.75': array([0.5984583], dtype=float32),\n 'lr5e-5_bs8_do0.25': array([0.5984583], dtype=float32),\n 'lr1e-4_bs8_do0.25': array([0.5984583], dtype=float32),\n 'lr3e-5_bs8_do0.25': array([0.5984583], dtype=float32),\n 'lr5e-5_bs16_do0.25': array([0.5984583], dtype=float32),\n 'lr1e-4_bs16_do0.25': array([0.5984583], dtype=float32),\n 'lr3e-5_bs16_do0.25': array([0.5984583], dtype=float32),\n 'lr5e-5_bs8_do0.0': array([0.5984583], dtype=float32),\n 'lr1e-4_bs8_do0.0': array([0.5984583], dtype=float32),\n 'lr3e-5_bs8_do0.0': array([0.5984583], dtype=float32),\n 'lr5e-5_bs16_do0.0': array([0.5984583], dtype=float32),\n 'lr1e-4_bs16_do0.0': array([0.5984583], dtype=float32),\n 'lr3e-5_bs16_do0.0': array([0.5984583], dtype=float32),\n 'lr5e-5_bs8_do0.1': array([0.5984583], dtype=float32),\n 'lr1e-4_bs8_do0.1': array([0.5984583], dtype=float32),\n 'lr3e-5_bs8_do0.1': array([0.5984583], dtype=float32),\n 'lr5e-5_bs16_do0.1': array([0.5984583], dtype=float32),\n 'lr1e-4_bs16_do0.1': array([0.5984583], dtype=float32),\n 'lr3e-5_bs16_do0.1': array([0.5984583], dtype=float32)}"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "{'lr5e-5_bs8_do0.5': 0.7770000100135803,\n 'lr1e-4_bs8_do0.5': 0.5730000138282776,\n 'lr3e-5_bs8_do0.5': 0.781000018119812,\n 'lr5e-5_bs16_do0.5': 0.7630000114440918,\n 'lr1e-4_bs16_do0.5': 0.7620000243186951,\n 'lr3e-5_bs16_do0.5': 0.7639999985694885,\n 'lr5e-5_bs8_do0.75': 0.7889999747276306,\n 'lr1e-4_bs8_do0.75': 0.5730000138282776,\n 'lr3e-5_bs8_do0.75': 0.7749999761581421,\n 'lr5e-5_bs16_do0.75': 0.7559999823570251,\n 'lr1e-4_bs16_do0.75': 0.5730000138282776,\n 'lr3e-5_bs16_do0.75': 0.7699999809265137,\n 'lr5e-5_bs8_do0.25': 0.777999997138977,\n 'lr1e-4_bs8_do0.25': 0.5730000138282776,\n 'lr3e-5_bs8_do0.25': 0.7879999876022339,\n 'lr5e-5_bs16_do0.25': 0.7829999923706055,\n 'lr1e-4_bs16_do0.25': 0.7549999952316284,\n 'lr3e-5_bs16_do0.25': 0.7870000004768372,\n 'lr5e-5_bs8_do0.0': 0.7730000019073486,\n 'lr1e-4_bs8_do0.0': 0.609000027179718,\n 'lr3e-5_bs8_do0.0': 0.7889999747276306,\n 'lr5e-5_bs16_do0.0': 0.7699999809265137,\n 'lr1e-4_bs16_do0.0': 0.7580000162124634,\n 'lr3e-5_bs16_do0.0': 0.781000018119812,\n 'lr5e-5_bs8_do0.1': 0.7720000147819519,\n 'lr1e-4_bs8_do0.1': 0.5730000138282776,\n 'lr3e-5_bs8_do0.1': 0.7829999923706055,\n 'lr5e-5_bs16_do0.1': 0.781000018119812,\n 'lr1e-4_bs16_do0.1': 0.5730000138282776,\n 'lr3e-5_bs16_do0.1': 0.7940000295639038}"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_acc\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "{'lr5e-5_bs8_do0.5': 0.5870000123977661,\n 'lr1e-4_bs8_do0.5': 0.6019999980926514,\n 'lr3e-5_bs8_do0.5': 0.578000009059906,\n 'lr5e-5_bs16_do0.5': 0.5799999833106995,\n 'lr1e-4_bs16_do0.5': 0.5889999866485596,\n 'lr3e-5_bs16_do0.5': 0.5720000267028809,\n 'lr5e-5_bs8_do0.75': 0.5809999704360962,\n 'lr1e-4_bs8_do0.75': 0.5899999737739563,\n 'lr3e-5_bs8_do0.75': 0.5720000267028809,\n 'lr5e-5_bs16_do0.75': 0.5770000219345093,\n 'lr1e-4_bs16_do0.75': 0.5870000123977661,\n 'lr3e-5_bs16_do0.75': 0.5699999928474426,\n 'lr5e-5_bs8_do0.25': 0.5879999995231628,\n 'lr1e-4_bs8_do0.25': 0.6119999885559082,\n 'lr3e-5_bs8_do0.25': 0.578000009059906,\n 'lr5e-5_bs16_do0.25': 0.5820000171661377,\n 'lr1e-4_bs16_do0.25': 0.5889999866485596,\n 'lr3e-5_bs16_do0.25': 0.5730000138282776,\n 'lr5e-5_bs8_do0.0': 0.5929999947547913,\n 'lr1e-4_bs8_do0.0': 0.6240000128746033,\n 'lr3e-5_bs8_do0.0': 0.5860000252723694,\n 'lr5e-5_bs16_do0.0': 0.5879999995231628,\n 'lr1e-4_bs16_do0.0': 0.6010000109672546,\n 'lr3e-5_bs16_do0.0': 0.574999988079071,\n 'lr5e-5_bs8_do0.1': 0.5920000076293945,\n 'lr1e-4_bs8_do0.1': 0.6190000176429749,\n 'lr3e-5_bs8_do0.1': 0.5849999785423279,\n 'lr5e-5_bs16_do0.1': 0.5870000123977661,\n 'lr1e-4_bs16_do0.1': 0.6010000109672546,\n 'lr3e-5_bs16_do0.1': 0.5740000009536743}"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "'lr5e-5_bs8_do0.75'"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(results_acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7889999747276306"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_acc['lr5e-5_bs8_do0.75']\n",
    "#best_epochs['lr5e-5_bs8_do0.75']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1125/1125 [==============================] - 183s 157ms/step - loss: 0.5403 - f1_score: 0.5910 - accuracy: 0.7311 - val_loss: 0.5143 - val_f1_score: 0.5985 - val_accuracy: 0.7460\n",
      "Epoch 2/2\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.3698 - f1_score: 0.5919 - accuracy: 0.8391 - val_loss: 0.4940 - val_f1_score: 0.5985 - val_accuracy: 0.7790\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#model = tf.keras.models.load_model('checkpoints/fast_text_model.hdf5')\n",
    "#print(val)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "bert = build_classifier_model(.75,True)\n",
    "bert.compile(loss = loss, optimizer = Adam(learning_rate=5e-5), metrics = [f1,'accuracy'])\n",
    "history = bert.fit(x=x_train,\n",
    "                        y=y_train,batch_size=8,\n",
    "                        validation_data=(x_val,y_val),\n",
    "                        epochs=2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 18s 195ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.22      0.35      1740\n",
      "           1       0.47      0.96      0.63      1260\n",
      "\n",
      "    accuracy                           0.53      3000\n",
      "   macro avg       0.67      0.59      0.49      3000\n",
      "weighted avg       0.71      0.53      0.47      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = bert.predict(x_test)\n",
    "pred = np.round(pred)\n",
    "#print(pred)\n",
    "print(classification_report(y_test,pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "'lr5e-5_bs8_do0.75'"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(results2_acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2_acc['lr5e-5_bs8_do0.75']\n",
    "best_epochs2['lr5e-5_bs8_do0.75']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 70s 59ms/step - loss: 0.8916 - f1_score: 0.5920 - accuracy: 0.5192 - val_loss: 0.6873 - val_f1_score: 0.5985 - val_accuracy: 0.5710\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 63s 56ms/step - loss: 0.8536 - f1_score: 0.5919 - accuracy: 0.5252 - val_loss: 0.6787 - val_f1_score: 0.5985 - val_accuracy: 0.5680\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 63s 56ms/step - loss: 0.8271 - f1_score: 0.5919 - accuracy: 0.5349 - val_loss: 0.6728 - val_f1_score: 0.5985 - val_accuracy: 0.5760\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 63s 56ms/step - loss: 0.8229 - f1_score: 0.5919 - accuracy: 0.5274 - val_loss: 0.6676 - val_f1_score: 0.5985 - val_accuracy: 0.5810\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "bert = build_classifier_model(.75,False)\n",
    "bert.compile(loss = loss, optimizer = Adam(learning_rate=5e-5), metrics = [f1,'accuracy'])\n",
    "history = bert.fit(x=x_train,\n",
    "                        y=y_train,batch_size=8,\n",
    "                        validation_data=(x_val,y_val),\n",
    "                        epochs=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 18s 189ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.94      0.73      1740\n",
      "           1       0.55      0.10      0.17      1260\n",
      "\n",
      "    accuracy                           0.59      3000\n",
      "   macro avg       0.57      0.52      0.45      3000\n",
      "weighted avg       0.57      0.59      0.49      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = bert.predict(x_test)\n",
    "pred = np.round(pred)\n",
    "print(classification_report(y_test,pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.],\n       [1.],\n       [0.],\n       ...,\n       [0.],\n       [0.],\n       [0.]], dtype=float32)"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "0       0\n1       0\n2       0\n3       1\n4       1\n       ..\n2995    1\n2996    1\n2997    1\n2998    1\n2999    1\nName: HS, Length: 3000, dtype: int64"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}