{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LD_LIBRARY_PATH=/home/zach/anaconda3/envs/research/lib/\n",
      "env: TF_GPU_ALLOCATOR=cuda_malloc_async\n"
     ]
    }
   ],
   "source": [
    "#Need to remove hardcoding but needed for now\n",
    "%env LD_LIBRARY_PATH=/home/zach/anaconda3/envs/research/lib/\n",
    "%env TF_GPU_ALLOCATOR=cuda_malloc_async"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0433822-9d89-4b16-bb3c-faf4becb2f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 23:05:53.884511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-24 23:05:53.888053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-24 23:05:53.888373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-24 23:05:53.888861: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-24 23:05:53.890069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-24 23:05:53.890389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-24 23:05:53.890697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-24 23:05:54.245773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-24 23:05:54.246101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-24 23:05:54.246387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-24 23:05:54.246643: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-05-24 23:05:54.246855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6170 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "import tensorflow_addons as tfa\n",
    "f1 = tfa.metrics.F1Score(num_classes=1, average='macro')\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/zach/anaconda3/envs/research/lib/'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['LD_LIBRARY_PATH']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Import and Cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bc2ed28-b317-4e93-879b-174809fe1592",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_244221/675437588.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  train = train.drop(['TR','AG'],1)\n",
      "/tmp/ipykernel_244221/675437588.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  test = test.drop(['TR','AG'],1)\n",
      "/tmp/ipykernel_244221/675437588.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  val = val.drop(['TR','AG'],1)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/hateval2019_en_train.csv')\n",
    "test = pd.read_csv('data/hateval2019_en_test.csv')\n",
    "val = pd.read_csv('data/hateval2019_en_dev.csv')\n",
    "\n",
    "train = train.drop(['TR','AG'],1)\n",
    "test = test.drop(['TR','AG'],1)\n",
    "val = val.drop(['TR','AG'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38ad4e4f-bb0a-4320-abb5-70975afcf27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "    id                                               text  HS\n0  201  Hurray, saving us $$$ in so many ways @potus @...   1\n1  202  Why would young fighting age men be the vast m...   1\n2  203  @KamalaHarris Illegals Dump their Kids at the ...   1\n3  204  NY Times: 'Nearly All White' States Pose 'an A...   0\n4  205  Orban in Brussels: European leaders are ignori...   0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>HS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>201</td>\n      <td>Hurray, saving us $$$ in so many ways @potus @...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>202</td>\n      <td>Why would young fighting age men be the vast m...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>203</td>\n      <td>@KamalaHarris Illegals Dump their Kids at the ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>204</td>\n      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>205</td>\n      <td>Orban in Brussels: European leaders are ignori...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19c65889-3f31-48d8-9b24-4761dead01fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.regularizers import L1,L2, l1_l2\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a577312-e144-4c17-8f0d-3c01dfb99194",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_tweet(text):\n",
    "    \"\"\"\n",
    "    Removes hashtags, @s, links, and punctuation\n",
    "    :param text:Text to be cleaned\n",
    "    :return: text with mentions, hashtages, and urls removes\n",
    "    \"\"\"\n",
    "    processed_text = text.lower()\n",
    "    processed_text = re.sub(r\"(?:\\@|http?\\://|https?\\://|www|t\\.)\\S+\", \"\", processed_text)\n",
    "    processed_text = re.sub(r\"(?:\\.|,|\\?|-)\", \" \", processed_text)\n",
    "    processed_text = re.sub(r\"(?:\\@|http?\\://|https?\\://|www|\\.com)\", \"\", processed_text)\n",
    "    processed_text = re.sub(r'[^\\w\\s]', '', processed_text)\n",
    "    processed_text = \" \".join(processed_text.split())\n",
    "    return processed_text\n",
    "\n",
    "def x_y_split(data):\n",
    "    \"\"\"splits and X and y from dataframe\n",
    "\n",
    "    Args:\n",
    "        data:dataframe to split from\n",
    "\n",
    "    Returns:\n",
    "        tuple:X data, y data\n",
    "    \"\"\"\n",
    "    X = data['text']\n",
    "    X = X.apply(normalize_tweet)\n",
    "    y = data['HS']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486671d4-0ebf-4dca-b222-f9874edcffd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split sequences into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "892e5b37-65e1-4490-8f21-4c86f55a3252",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       hurray saving us in so many ways lockthemup bu...\n",
      "1       why would young fighting age men be the vast m...\n",
      "2       illegals dump their kids at the border like ro...\n",
      "3       ny times nearly all white states pose an array...\n",
      "4       orban in brussels european leaders are ignorin...\n",
      "                              ...                        \n",
      "8995                  i am proud to be a hysterical woman\n",
      "8996    hollywood is complicit in the rape and sexual ...\n",
      "8997    what a fucking cunt i hate seeing kids getting...\n",
      "8998                                hysterical woman like\n",
      "8999    nearly every woman i know has metoo in their f...\n",
      "Name: text, Length: 9000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Split x and ys\n",
    "x_train, y_train = x_y_split(train)\n",
    "print(x_train)\n",
    "#x_train.to_csv('data/x_train.csv')\n",
    "#y_train.to_csv('data/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d051068c-d8f7-4ae2-953f-cab47e9d6aa6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       oh i could have gone on about taxes since the ...\n",
      "1       several of the wild fires in california and co...\n",
      "2       my question is how do you resettle a refugee a...\n",
      "3       europe youve got a problem we must hurry and b...\n",
      "4       this is outrageous stopillegalimmigration meri...\n",
      "                              ...                        \n",
      "2995    you can never take a l off a real bitch im hot...\n",
      "2996    likes to call me a cunt a bitch but i tell him...\n",
      "2997    1 never said you were taught 2 you called me b...\n",
      "2998    if i see and know you a hoe why would i hit yo...\n",
      "2999     you be chasing them hoes fuck what a bitch think\n",
      "Name: text, Length: 3000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Split x and ys\n",
    "x_test, y_test = x_y_split(test)\n",
    "print(x_test)\n",
    "#x_test.to_csv('data/x_test.csv')\n",
    "#y_test.to_csv('data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01de8fa7-03ed-4d50-9ca6-296865282e6f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      i swear im getting to places just in the nick ...\n",
      "1      im an immigrant and trump is right on immigrat...\n",
      "2      illegalimmigrants illegalaliens electoralsyste...\n",
      "3      we have our own invasion issues with mexicans ...\n",
      "4      worker charged with sexually molesting eight c...\n",
      "                             ...                        \n",
      "995                     you unfollowed me fuck you pussy\n",
      "996    stfu bitch and you go make some satanic music ...\n",
      "997    honey as a fellow white chick let me tell you ...\n",
      "998    i hate bitches who talk about niggaz with kids...\n",
      "999    you won the life time recipient for hysterical...\n",
      "Name: text, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Split x and ys\n",
    "x_val, y_val = x_y_split(val)\n",
    "print(x_val)\n",
    "#x_val.to_csv('data/x_val.csv')\n",
    "#y_val.to_csv('data/y_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text  # A dependency of the preprocessing model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "tfhub_handle_encoder = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n",
    "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def build_classifier_model(do,trainable=False):\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=trainable, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(do)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 192s 164ms/step - loss: 0.5050 - f1_score: 0.5919 - accuracy: 0.7496 - val_loss: 0.5464 - val_f1_score: 0.5985 - val_accuracy: 0.7280\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 187s 166ms/step - loss: 0.3462 - f1_score: 0.5919 - accuracy: 0.8514 - val_loss: 0.5355 - val_f1_score: 0.5985 - val_accuracy: 0.7480\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 189s 168ms/step - loss: 0.1949 - f1_score: 0.5919 - accuracy: 0.9267 - val_loss: 0.7836 - val_f1_score: 0.5985 - val_accuracy: 0.7690\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 187s 166ms/step - loss: 0.0988 - f1_score: 0.5919 - accuracy: 0.9651 - val_loss: 0.9103 - val_f1_score: 0.5985 - val_accuracy: 0.7410\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 192s 165ms/step - loss: 0.6505 - f1_score: 0.5925 - accuracy: 0.6423 - val_loss: 0.6838 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 186s 165ms/step - loss: 0.7792 - f1_score: 0.5919 - accuracy: 0.5348 - val_loss: 0.7486 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 186s 165ms/step - loss: 0.7147 - f1_score: 0.5919 - accuracy: 0.5287 - val_loss: 0.6825 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 183s 163ms/step - loss: 0.7014 - f1_score: 0.5919 - accuracy: 0.5392 - val_loss: 0.6878 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 187s 161ms/step - loss: 0.4839 - f1_score: 0.5925 - accuracy: 0.7638 - val_loss: 0.4646 - val_f1_score: 0.5985 - val_accuracy: 0.7660\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 185s 164ms/step - loss: 0.3084 - f1_score: 0.5919 - accuracy: 0.8710 - val_loss: 0.5790 - val_f1_score: 0.5985 - val_accuracy: 0.7490\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 185s 165ms/step - loss: 0.1541 - f1_score: 0.5919 - accuracy: 0.9422 - val_loss: 0.8192 - val_f1_score: 0.5985 - val_accuracy: 0.7740\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 187s 166ms/step - loss: 0.0721 - f1_score: 0.5919 - accuracy: 0.9753 - val_loss: 0.9467 - val_f1_score: 0.5985 - val_accuracy: 0.7550\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 189s 162ms/step - loss: 0.4865 - f1_score: 0.5925 - accuracy: 0.7601 - val_loss: 0.4699 - val_f1_score: 0.5985 - val_accuracy: 0.7710\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 182s 162ms/step - loss: 0.3172 - f1_score: 0.5919 - accuracy: 0.8664 - val_loss: 0.4816 - val_f1_score: 0.5985 - val_accuracy: 0.7910\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 181s 161ms/step - loss: 0.1708 - f1_score: 0.5919 - accuracy: 0.9344 - val_loss: 0.6571 - val_f1_score: 0.5985 - val_accuracy: 0.7670\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 182s 162ms/step - loss: 0.0821 - f1_score: 0.5919 - accuracy: 0.9703 - val_loss: 0.7936 - val_f1_score: 0.5985 - val_accuracy: 0.7830\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 169s 289ms/step - loss: 0.5138 - f1_score: 0.5925 - accuracy: 0.7353 - val_loss: 0.4991 - val_f1_score: 0.5985 - val_accuracy: 0.7430\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 161s 287ms/step - loss: 0.3312 - f1_score: 0.5919 - accuracy: 0.8561 - val_loss: 0.5543 - val_f1_score: 0.5985 - val_accuracy: 0.7150\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 160s 283ms/step - loss: 0.1787 - f1_score: 0.5919 - accuracy: 0.9312 - val_loss: 0.6558 - val_f1_score: 0.5985 - val_accuracy: 0.7590\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 156s 277ms/step - loss: 0.0920 - f1_score: 0.5919 - accuracy: 0.9690 - val_loss: 0.9781 - val_f1_score: 0.5985 - val_accuracy: 0.7350\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 161s 275ms/step - loss: 0.5246 - f1_score: 0.5925 - accuracy: 0.7368 - val_loss: 0.5750 - val_f1_score: 0.5985 - val_accuracy: 0.6830\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 155s 275ms/step - loss: 0.3751 - f1_score: 0.5919 - accuracy: 0.8323 - val_loss: 0.6332 - val_f1_score: 0.5985 - val_accuracy: 0.7430\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 155s 275ms/step - loss: 0.2531 - f1_score: 0.5919 - accuracy: 0.8993 - val_loss: 0.8399 - val_f1_score: 0.5985 - val_accuracy: 0.7330\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 155s 275ms/step - loss: 0.1737 - f1_score: 0.5919 - accuracy: 0.9377 - val_loss: 0.7183 - val_f1_score: 0.5985 - val_accuracy: 0.7470\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 160s 274ms/step - loss: 0.5028 - f1_score: 0.5925 - accuracy: 0.7544 - val_loss: 0.4650 - val_f1_score: 0.5985 - val_accuracy: 0.7510\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 154s 274ms/step - loss: 0.3173 - f1_score: 0.5919 - accuracy: 0.8606 - val_loss: 0.4871 - val_f1_score: 0.5985 - val_accuracy: 0.7700\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 154s 274ms/step - loss: 0.1677 - f1_score: 0.5919 - accuracy: 0.9343 - val_loss: 0.6172 - val_f1_score: 0.5985 - val_accuracy: 0.7560\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 154s 274ms/step - loss: 0.0824 - f1_score: 0.5919 - accuracy: 0.9707 - val_loss: 0.7109 - val_f1_score: 0.5985 - val_accuracy: 0.7660\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 169s 290ms/step - loss: 0.4971 - f1_score: 0.5925 - accuracy: 0.7468 - val_loss: 0.4815 - val_f1_score: 0.5985 - val_accuracy: 0.7680\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 163s 290ms/step - loss: 0.3202 - f1_score: 0.5919 - accuracy: 0.8637 - val_loss: 0.4968 - val_f1_score: 0.5985 - val_accuracy: 0.7650\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 164s 291ms/step - loss: 0.1601 - f1_score: 0.5919 - accuracy: 0.9409 - val_loss: 0.6379 - val_f1_score: 0.5985 - val_accuracy: 0.7440\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 164s 291ms/step - loss: 0.0932 - f1_score: 0.5919 - accuracy: 0.9666 - val_loss: 0.8538 - val_f1_score: 0.5985 - val_accuracy: 0.7570\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 191s 164ms/step - loss: 0.5270 - f1_score: 0.5925 - accuracy: 0.7388 - val_loss: 0.4697 - val_f1_score: 0.5985 - val_accuracy: 0.7730\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 186s 166ms/step - loss: 0.3525 - f1_score: 0.5919 - accuracy: 0.8433 - val_loss: 0.5311 - val_f1_score: 0.5985 - val_accuracy: 0.7480\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 185s 165ms/step - loss: 0.2054 - f1_score: 0.5919 - accuracy: 0.9240 - val_loss: 0.8105 - val_f1_score: 0.5985 - val_accuracy: 0.7500\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.1058 - f1_score: 0.5919 - accuracy: 0.9653 - val_loss: 0.8217 - val_f1_score: 0.5985 - val_accuracy: 0.7670\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 196s 168ms/step - loss: 0.8193 - f1_score: 0.5925 - accuracy: 0.5388 - val_loss: 0.6841 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 189s 168ms/step - loss: 0.7076 - f1_score: 0.5919 - accuracy: 0.5400 - val_loss: 0.6825 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 182s 162ms/step - loss: 0.7004 - f1_score: 0.5919 - accuracy: 0.5509 - val_loss: 0.6825 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 186s 165ms/step - loss: 0.7008 - f1_score: 0.5919 - accuracy: 0.5440 - val_loss: 0.6840 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 1/4\n",
      " 550/1125 [=============>................] - ETA: 1:31 - loss: 0.6034 - f1_score: 0.5914 - accuracy: 0.6782"
     ]
    }
   ],
   "source": [
    "\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "learning_rates = [5e-5, 1e-4, 3e-5, 3e-5]\n",
    "learning_rates_text = ['5e-5', '1e-4', '3e-5', '3e-5']\n",
    "batch_sizes = [8, 16]\n",
    "dropout = [.5,.75,.25,0.0,.1]\n",
    "results = {}\n",
    "results_acc = {}\n",
    "for do in dropout:\n",
    "    for bs in batch_sizes:\n",
    "        for lr in range(len(learning_rates)):\n",
    "            string = 'lr{lr}_bs{bs}_do{do}'.format(lr=learning_rates_text[lr],bs=bs,do=do)\n",
    "            #filepath = 'checkpoints/bert_finetuned/lr{lr}_bs{bs}.hdf5'.format(lr=learning_rates_text[lr],bs=bs)\n",
    "            #checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
    "                                                 #    monitor='val_f1_score',\n",
    "                                                  #  save_best_only=True,\n",
    "                                                   #  verbose=1,)\n",
    "            #callbacks = [checkpoint]\n",
    "\n",
    "            bert = build_classifier_model(do,trainable=True)\n",
    "            bert.compile(loss = loss, optimizer = Adam(learning_rate=learning_rates[lr]), metrics = [f1,'accuracy'])\n",
    "            history = bert.fit(x=x_train,\n",
    "                                y=y_train,batch_size=bs,\n",
    "                                validation_data=(x_val,y_val),\n",
    "                                epochs=4)\n",
    "\n",
    "            max_f1 = max(history.history['val_f1_score'])\n",
    "            max_acc = max(history.history['val_accuracy'])\n",
    "            results[string] = max_f1\n",
    "            results_acc[string] = max_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results2 = {}\n",
    "results2_acc = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for do in dropout:\n",
    "    for bs in batch_sizes:\n",
    "        for lr in range(len(learning_rates)):\n",
    "            string = 'lr{lr}_bs{bs}_do{do}'.format(lr=learning_rates_text[lr],bs=bs,do=do)\n",
    "            #filepath = 'checkpoints/bert_finetuned/lr{lr}_bs{bs}.hdf5'.format(lr=learning_rates_text[lr],bs=bs)\n",
    "            #checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
    "                                                 #    monitor='val_f1_score',\n",
    "                                                  #  save_best_only=True,\n",
    "                                                   #  verbose=1,)\n",
    "            #callbacks = [checkpoint]\n",
    "\n",
    "            bert = build_classifier_model(do,trainable=False)\n",
    "            bert.compile(loss = loss, optimizer = Adam(learning_rate=learning_rates[lr]), metrics = [f1,'accuracy'])\n",
    "            history = bert.fit(x=x_train,\n",
    "                                y=y_train,batch_size=bs,\n",
    "                                validation_data=(x_val,y_val),\n",
    "                                epochs=4)\n",
    "\n",
    "            max_f1 = max(history.history['val_f1_score'])\n",
    "            max_acc = max(history.history['val_accuracy'])\n",
    "            results2[string] = max_f1\n",
    "            results2_acc[string] = max_f1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}