{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LD_LIBRARY_PATH=/home/zach/anaconda3/envs/research/lib/\n",
      "env: TF_GPU_ALLOCATOR=cuda_malloc_async\n"
     ]
    }
   ],
   "source": [
    "#Need to remove hardcoding but needed for now\n",
    "%env LD_LIBRARY_PATH=/home/zach/anaconda3/envs/research/lib/\n",
    "%env TF_GPU_ALLOCATOR=cuda_malloc_async"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0433822-9d89-4b16-bb3c-faf4becb2f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 23:05:53.884511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-24 23:05:53.888053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-24 23:05:53.888373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-24 23:05:53.888861: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-24 23:05:53.890069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-24 23:05:53.890389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-24 23:05:53.890697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-24 23:05:54.245773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-24 23:05:54.246101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-24 23:05:54.246387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-24 23:05:54.246643: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-05-24 23:05:54.246855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6170 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "import tensorflow_addons as tfa\n",
    "f1 = tfa.metrics.F1Score(num_classes=1, average='macro')\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/zach/anaconda3/envs/research/lib/'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['LD_LIBRARY_PATH']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Import and Cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bc2ed28-b317-4e93-879b-174809fe1592",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_244221/675437588.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  train = train.drop(['TR','AG'],1)\n",
      "/tmp/ipykernel_244221/675437588.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  test = test.drop(['TR','AG'],1)\n",
      "/tmp/ipykernel_244221/675437588.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  val = val.drop(['TR','AG'],1)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/hateval2019_en_train.csv')\n",
    "test = pd.read_csv('data/hateval2019_en_test.csv')\n",
    "val = pd.read_csv('data/hateval2019_en_dev.csv')\n",
    "\n",
    "train = train.drop(['TR','AG'],1)\n",
    "test = test.drop(['TR','AG'],1)\n",
    "val = val.drop(['TR','AG'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38ad4e4f-bb0a-4320-abb5-70975afcf27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "    id                                               text  HS\n0  201  Hurray, saving us $$$ in so many ways @potus @...   1\n1  202  Why would young fighting age men be the vast m...   1\n2  203  @KamalaHarris Illegals Dump their Kids at the ...   1\n3  204  NY Times: 'Nearly All White' States Pose 'an A...   0\n4  205  Orban in Brussels: European leaders are ignori...   0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>HS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>201</td>\n      <td>Hurray, saving us $$$ in so many ways @potus @...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>202</td>\n      <td>Why would young fighting age men be the vast m...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>203</td>\n      <td>@KamalaHarris Illegals Dump their Kids at the ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>204</td>\n      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>205</td>\n      <td>Orban in Brussels: European leaders are ignori...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19c65889-3f31-48d8-9b24-4761dead01fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.regularizers import L1,L2, l1_l2\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a577312-e144-4c17-8f0d-3c01dfb99194",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_tweet(text):\n",
    "    \"\"\"\n",
    "    Removes hashtags, @s, links, and punctuation\n",
    "    :param text:Text to be cleaned\n",
    "    :return: text with mentions, hashtages, and urls removes\n",
    "    \"\"\"\n",
    "    processed_text = text.lower()\n",
    "    processed_text = re.sub(r\"(?:\\@|http?\\://|https?\\://|www|t\\.)\\S+\", \"\", processed_text)\n",
    "    processed_text = re.sub(r\"(?:\\.|,|\\?|-)\", \" \", processed_text)\n",
    "    processed_text = re.sub(r\"(?:\\@|http?\\://|https?\\://|www|\\.com)\", \"\", processed_text)\n",
    "    processed_text = re.sub(r'[^\\w\\s]', '', processed_text)\n",
    "    processed_text = \" \".join(processed_text.split())\n",
    "    return processed_text\n",
    "\n",
    "def x_y_split(data):\n",
    "    \"\"\"splits and X and y from dataframe\n",
    "\n",
    "    Args:\n",
    "        data:dataframe to split from\n",
    "\n",
    "    Returns:\n",
    "        tuple:X data, y data\n",
    "    \"\"\"\n",
    "    X = data['text']\n",
    "    X = X.apply(normalize_tweet)\n",
    "    y = data['HS']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486671d4-0ebf-4dca-b222-f9874edcffd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split sequences into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "892e5b37-65e1-4490-8f21-4c86f55a3252",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       hurray saving us in so many ways lockthemup bu...\n",
      "1       why would young fighting age men be the vast m...\n",
      "2       illegals dump their kids at the border like ro...\n",
      "3       ny times nearly all white states pose an array...\n",
      "4       orban in brussels european leaders are ignorin...\n",
      "                              ...                        \n",
      "8995                  i am proud to be a hysterical woman\n",
      "8996    hollywood is complicit in the rape and sexual ...\n",
      "8997    what a fucking cunt i hate seeing kids getting...\n",
      "8998                                hysterical woman like\n",
      "8999    nearly every woman i know has metoo in their f...\n",
      "Name: text, Length: 9000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Split x and ys\n",
    "x_train, y_train = x_y_split(train)\n",
    "print(x_train)\n",
    "#x_train.to_csv('data/x_train.csv')\n",
    "#y_train.to_csv('data/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d051068c-d8f7-4ae2-953f-cab47e9d6aa6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       oh i could have gone on about taxes since the ...\n",
      "1       several of the wild fires in california and co...\n",
      "2       my question is how do you resettle a refugee a...\n",
      "3       europe youve got a problem we must hurry and b...\n",
      "4       this is outrageous stopillegalimmigration meri...\n",
      "                              ...                        \n",
      "2995    you can never take a l off a real bitch im hot...\n",
      "2996    likes to call me a cunt a bitch but i tell him...\n",
      "2997    1 never said you were taught 2 you called me b...\n",
      "2998    if i see and know you a hoe why would i hit yo...\n",
      "2999     you be chasing them hoes fuck what a bitch think\n",
      "Name: text, Length: 3000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Split x and ys\n",
    "x_test, y_test = x_y_split(test)\n",
    "print(x_test)\n",
    "#x_test.to_csv('data/x_test.csv')\n",
    "#y_test.to_csv('data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01de8fa7-03ed-4d50-9ca6-296865282e6f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      i swear im getting to places just in the nick ...\n",
      "1      im an immigrant and trump is right on immigrat...\n",
      "2      illegalimmigrants illegalaliens electoralsyste...\n",
      "3      we have our own invasion issues with mexicans ...\n",
      "4      worker charged with sexually molesting eight c...\n",
      "                             ...                        \n",
      "995                     you unfollowed me fuck you pussy\n",
      "996    stfu bitch and you go make some satanic music ...\n",
      "997    honey as a fellow white chick let me tell you ...\n",
      "998    i hate bitches who talk about niggaz with kids...\n",
      "999    you won the life time recipient for hysterical...\n",
      "Name: text, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Split x and ys\n",
    "x_val, y_val = x_y_split(val)\n",
    "print(x_val)\n",
    "#x_val.to_csv('data/x_val.csv')\n",
    "#y_val.to_csv('data/y_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text  # A dependency of the preprocessing model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "tfhub_handle_encoder = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n",
    "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def build_classifier_model(do,trainable=False):\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=trainable, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(do)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 192s 164ms/step - loss: 0.5050 - f1_score: 0.5919 - accuracy: 0.7496 - val_loss: 0.5464 - val_f1_score: 0.5985 - val_accuracy: 0.7280\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 187s 166ms/step - loss: 0.3462 - f1_score: 0.5919 - accuracy: 0.8514 - val_loss: 0.5355 - val_f1_score: 0.5985 - val_accuracy: 0.7480\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 189s 168ms/step - loss: 0.1949 - f1_score: 0.5919 - accuracy: 0.9267 - val_loss: 0.7836 - val_f1_score: 0.5985 - val_accuracy: 0.7690\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 187s 166ms/step - loss: 0.0988 - f1_score: 0.5919 - accuracy: 0.9651 - val_loss: 0.9103 - val_f1_score: 0.5985 - val_accuracy: 0.7410\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 192s 165ms/step - loss: 0.6505 - f1_score: 0.5925 - accuracy: 0.6423 - val_loss: 0.6838 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 186s 165ms/step - loss: 0.7792 - f1_score: 0.5919 - accuracy: 0.5348 - val_loss: 0.7486 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 186s 165ms/step - loss: 0.7147 - f1_score: 0.5919 - accuracy: 0.5287 - val_loss: 0.6825 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 183s 163ms/step - loss: 0.7014 - f1_score: 0.5919 - accuracy: 0.5392 - val_loss: 0.6878 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 187s 161ms/step - loss: 0.4839 - f1_score: 0.5925 - accuracy: 0.7638 - val_loss: 0.4646 - val_f1_score: 0.5985 - val_accuracy: 0.7660\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 185s 164ms/step - loss: 0.3084 - f1_score: 0.5919 - accuracy: 0.8710 - val_loss: 0.5790 - val_f1_score: 0.5985 - val_accuracy: 0.7490\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 185s 165ms/step - loss: 0.1541 - f1_score: 0.5919 - accuracy: 0.9422 - val_loss: 0.8192 - val_f1_score: 0.5985 - val_accuracy: 0.7740\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 187s 166ms/step - loss: 0.0721 - f1_score: 0.5919 - accuracy: 0.9753 - val_loss: 0.9467 - val_f1_score: 0.5985 - val_accuracy: 0.7550\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 189s 162ms/step - loss: 0.4865 - f1_score: 0.5925 - accuracy: 0.7601 - val_loss: 0.4699 - val_f1_score: 0.5985 - val_accuracy: 0.7710\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 182s 162ms/step - loss: 0.3172 - f1_score: 0.5919 - accuracy: 0.8664 - val_loss: 0.4816 - val_f1_score: 0.5985 - val_accuracy: 0.7910\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 181s 161ms/step - loss: 0.1708 - f1_score: 0.5919 - accuracy: 0.9344 - val_loss: 0.6571 - val_f1_score: 0.5985 - val_accuracy: 0.7670\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 182s 162ms/step - loss: 0.0821 - f1_score: 0.5919 - accuracy: 0.9703 - val_loss: 0.7936 - val_f1_score: 0.5985 - val_accuracy: 0.7830\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 169s 289ms/step - loss: 0.5138 - f1_score: 0.5925 - accuracy: 0.7353 - val_loss: 0.4991 - val_f1_score: 0.5985 - val_accuracy: 0.7430\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 161s 287ms/step - loss: 0.3312 - f1_score: 0.5919 - accuracy: 0.8561 - val_loss: 0.5543 - val_f1_score: 0.5985 - val_accuracy: 0.7150\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 160s 283ms/step - loss: 0.1787 - f1_score: 0.5919 - accuracy: 0.9312 - val_loss: 0.6558 - val_f1_score: 0.5985 - val_accuracy: 0.7590\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 156s 277ms/step - loss: 0.0920 - f1_score: 0.5919 - accuracy: 0.9690 - val_loss: 0.9781 - val_f1_score: 0.5985 - val_accuracy: 0.7350\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 161s 275ms/step - loss: 0.5246 - f1_score: 0.5925 - accuracy: 0.7368 - val_loss: 0.5750 - val_f1_score: 0.5985 - val_accuracy: 0.6830\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 155s 275ms/step - loss: 0.3751 - f1_score: 0.5919 - accuracy: 0.8323 - val_loss: 0.6332 - val_f1_score: 0.5985 - val_accuracy: 0.7430\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 155s 275ms/step - loss: 0.2531 - f1_score: 0.5919 - accuracy: 0.8993 - val_loss: 0.8399 - val_f1_score: 0.5985 - val_accuracy: 0.7330\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 155s 275ms/step - loss: 0.1737 - f1_score: 0.5919 - accuracy: 0.9377 - val_loss: 0.7183 - val_f1_score: 0.5985 - val_accuracy: 0.7470\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 160s 274ms/step - loss: 0.5028 - f1_score: 0.5925 - accuracy: 0.7544 - val_loss: 0.4650 - val_f1_score: 0.5985 - val_accuracy: 0.7510\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 154s 274ms/step - loss: 0.3173 - f1_score: 0.5919 - accuracy: 0.8606 - val_loss: 0.4871 - val_f1_score: 0.5985 - val_accuracy: 0.7700\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 154s 274ms/step - loss: 0.1677 - f1_score: 0.5919 - accuracy: 0.9343 - val_loss: 0.6172 - val_f1_score: 0.5985 - val_accuracy: 0.7560\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 154s 274ms/step - loss: 0.0824 - f1_score: 0.5919 - accuracy: 0.9707 - val_loss: 0.7109 - val_f1_score: 0.5985 - val_accuracy: 0.7660\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 169s 290ms/step - loss: 0.4971 - f1_score: 0.5925 - accuracy: 0.7468 - val_loss: 0.4815 - val_f1_score: 0.5985 - val_accuracy: 0.7680\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 163s 290ms/step - loss: 0.3202 - f1_score: 0.5919 - accuracy: 0.8637 - val_loss: 0.4968 - val_f1_score: 0.5985 - val_accuracy: 0.7650\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 164s 291ms/step - loss: 0.1601 - f1_score: 0.5919 - accuracy: 0.9409 - val_loss: 0.6379 - val_f1_score: 0.5985 - val_accuracy: 0.7440\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 164s 291ms/step - loss: 0.0932 - f1_score: 0.5919 - accuracy: 0.9666 - val_loss: 0.8538 - val_f1_score: 0.5985 - val_accuracy: 0.7570\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 191s 164ms/step - loss: 0.5270 - f1_score: 0.5925 - accuracy: 0.7388 - val_loss: 0.4697 - val_f1_score: 0.5985 - val_accuracy: 0.7730\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 186s 166ms/step - loss: 0.3525 - f1_score: 0.5919 - accuracy: 0.8433 - val_loss: 0.5311 - val_f1_score: 0.5985 - val_accuracy: 0.7480\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 185s 165ms/step - loss: 0.2054 - f1_score: 0.5919 - accuracy: 0.9240 - val_loss: 0.8105 - val_f1_score: 0.5985 - val_accuracy: 0.7500\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 180s 160ms/step - loss: 0.1058 - f1_score: 0.5919 - accuracy: 0.9653 - val_loss: 0.8217 - val_f1_score: 0.5985 - val_accuracy: 0.7670\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 196s 168ms/step - loss: 0.8193 - f1_score: 0.5925 - accuracy: 0.5388 - val_loss: 0.6841 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 189s 168ms/step - loss: 0.7076 - f1_score: 0.5919 - accuracy: 0.5400 - val_loss: 0.6825 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 182s 162ms/step - loss: 0.7004 - f1_score: 0.5919 - accuracy: 0.5509 - val_loss: 0.6825 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 186s 165ms/step - loss: 0.7008 - f1_score: 0.5919 - accuracy: 0.5440 - val_loss: 0.6840 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 193s 166ms/step - loss: 0.5334 - f1_score: 0.5925 - accuracy: 0.7253 - val_loss: 0.4547 - val_f1_score: 0.5985 - val_accuracy: 0.7750\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 188s 167ms/step - loss: 0.3441 - f1_score: 0.5919 - accuracy: 0.8526 - val_loss: 0.4770 - val_f1_score: 0.5985 - val_accuracy: 0.7600\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 185s 165ms/step - loss: 0.1858 - f1_score: 0.5919 - accuracy: 0.9297 - val_loss: 0.6244 - val_f1_score: 0.5985 - val_accuracy: 0.7660\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 185s 164ms/step - loss: 0.0964 - f1_score: 0.5919 - accuracy: 0.9672 - val_loss: 0.7339 - val_f1_score: 0.5985 - val_accuracy: 0.7630\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 189s 163ms/step - loss: 0.5290 - f1_score: 0.5925 - accuracy: 0.7310 - val_loss: 0.5220 - val_f1_score: 0.5985 - val_accuracy: 0.7270\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 182s 162ms/step - loss: 0.3340 - f1_score: 0.5919 - accuracy: 0.8594 - val_loss: 0.5120 - val_f1_score: 0.5985 - val_accuracy: 0.7850\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 182s 162ms/step - loss: 0.1810 - f1_score: 0.5919 - accuracy: 0.9322 - val_loss: 0.7641 - val_f1_score: 0.5985 - val_accuracy: 0.7690\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 176s 157ms/step - loss: 0.0788 - f1_score: 0.5919 - accuracy: 0.9748 - val_loss: 0.6834 - val_f1_score: 0.5985 - val_accuracy: 0.7690\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 168s 288ms/step - loss: 0.5379 - f1_score: 0.5925 - accuracy: 0.7268 - val_loss: 0.5348 - val_f1_score: 0.5985 - val_accuracy: 0.7500\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 160s 285ms/step - loss: 0.3458 - f1_score: 0.5919 - accuracy: 0.8488 - val_loss: 0.5066 - val_f1_score: 0.5985 - val_accuracy: 0.7540\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 159s 282ms/step - loss: 0.1924 - f1_score: 0.5919 - accuracy: 0.9281 - val_loss: 0.7148 - val_f1_score: 0.5985 - val_accuracy: 0.7630\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 158s 281ms/step - loss: 0.0920 - f1_score: 0.5919 - accuracy: 0.9686 - val_loss: 0.8351 - val_f1_score: 0.5985 - val_accuracy: 0.7630\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 164s 280ms/step - loss: 0.7476 - f1_score: 0.5925 - accuracy: 0.6038 - val_loss: 0.6955 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 158s 281ms/step - loss: 0.7479 - f1_score: 0.5919 - accuracy: 0.5354 - val_loss: 0.6842 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.7184 - f1_score: 0.5919 - accuracy: 0.5456 - val_loss: 0.6825 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 157s 280ms/step - loss: 0.7164 - f1_score: 0.5919 - accuracy: 0.5353 - val_loss: 0.6843 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 164s 281ms/step - loss: 0.5370 - f1_score: 0.5925 - accuracy: 0.7277 - val_loss: 0.4468 - val_f1_score: 0.5985 - val_accuracy: 0.7780\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 158s 281ms/step - loss: 0.3411 - f1_score: 0.5919 - accuracy: 0.8498 - val_loss: 0.4930 - val_f1_score: 0.5985 - val_accuracy: 0.7710\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.1818 - f1_score: 0.5919 - accuracy: 0.9304 - val_loss: 0.5485 - val_f1_score: 0.5985 - val_accuracy: 0.7750\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 158s 281ms/step - loss: 0.0846 - f1_score: 0.5919 - accuracy: 0.9729 - val_loss: 0.7463 - val_f1_score: 0.5985 - val_accuracy: 0.7580\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 164s 281ms/step - loss: 0.5624 - f1_score: 0.5925 - accuracy: 0.7073 - val_loss: 0.4813 - val_f1_score: 0.5985 - val_accuracy: 0.7540\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 158s 281ms/step - loss: 0.3650 - f1_score: 0.5919 - accuracy: 0.8397 - val_loss: 0.4606 - val_f1_score: 0.5985 - val_accuracy: 0.7720\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 158s 281ms/step - loss: 0.2080 - f1_score: 0.5919 - accuracy: 0.9192 - val_loss: 0.6622 - val_f1_score: 0.5985 - val_accuracy: 0.7250\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 158s 281ms/step - loss: 0.1044 - f1_score: 0.5919 - accuracy: 0.9623 - val_loss: 0.7475 - val_f1_score: 0.5985 - val_accuracy: 0.7580\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 179s 154ms/step - loss: 0.7160 - f1_score: 0.5925 - accuracy: 0.5497 - val_loss: 0.6832 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 173s 154ms/step - loss: 0.6876 - f1_score: 0.5919 - accuracy: 0.5677 - val_loss: 0.6825 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 173s 154ms/step - loss: 0.6890 - f1_score: 0.5919 - accuracy: 0.5647 - val_loss: 0.6891 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 173s 154ms/step - loss: 0.6883 - f1_score: 0.5919 - accuracy: 0.5667 - val_loss: 0.6825 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 180s 154ms/step - loss: 0.6388 - f1_score: 0.5925 - accuracy: 0.6402 - val_loss: 0.7398 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 174s 154ms/step - loss: 0.7201 - f1_score: 0.5919 - accuracy: 0.5368 - val_loss: 0.6858 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 173s 154ms/step - loss: 0.7043 - f1_score: 0.5919 - accuracy: 0.5439 - val_loss: 0.6877 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 174s 154ms/step - loss: 0.6959 - f1_score: 0.5919 - accuracy: 0.5553 - val_loss: 0.6885 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 179s 154ms/step - loss: 0.4810 - f1_score: 0.5925 - accuracy: 0.7628 - val_loss: 0.4471 - val_f1_score: 0.5985 - val_accuracy: 0.7760\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 174s 154ms/step - loss: 0.3055 - f1_score: 0.5919 - accuracy: 0.8692 - val_loss: 0.5424 - val_f1_score: 0.5985 - val_accuracy: 0.7700\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 174s 154ms/step - loss: 0.1456 - f1_score: 0.5919 - accuracy: 0.9460 - val_loss: 0.6562 - val_f1_score: 0.5985 - val_accuracy: 0.7430\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 174s 154ms/step - loss: 0.0775 - f1_score: 0.5919 - accuracy: 0.9730 - val_loss: 0.8812 - val_f1_score: 0.5985 - val_accuracy: 0.7580\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 180s 154ms/step - loss: 0.4747 - f1_score: 0.5925 - accuracy: 0.7706 - val_loss: 0.4675 - val_f1_score: 0.5985 - val_accuracy: 0.7670\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 173s 154ms/step - loss: 0.3027 - f1_score: 0.5919 - accuracy: 0.8676 - val_loss: 0.5783 - val_f1_score: 0.5985 - val_accuracy: 0.7730\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 173s 154ms/step - loss: 0.1510 - f1_score: 0.5919 - accuracy: 0.9426 - val_loss: 0.6326 - val_f1_score: 0.5985 - val_accuracy: 0.7720\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 173s 154ms/step - loss: 0.0702 - f1_score: 0.5919 - accuracy: 0.9757 - val_loss: 0.8734 - val_f1_score: 0.5985 - val_accuracy: 0.7600\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 165s 281ms/step - loss: 0.4741 - f1_score: 0.5925 - accuracy: 0.7696 - val_loss: 0.5080 - val_f1_score: 0.5985 - val_accuracy: 0.7290\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 158s 281ms/step - loss: 0.3070 - f1_score: 0.5919 - accuracy: 0.8740 - val_loss: 0.5370 - val_f1_score: 0.5985 - val_accuracy: 0.7640\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 158s 281ms/step - loss: 0.1663 - f1_score: 0.5919 - accuracy: 0.9406 - val_loss: 0.7025 - val_f1_score: 0.5985 - val_accuracy: 0.7620\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 158s 281ms/step - loss: 0.0920 - f1_score: 0.5919 - accuracy: 0.9692 - val_loss: 0.9722 - val_f1_score: 0.5985 - val_accuracy: 0.7630\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 163s 279ms/step - loss: 0.5031 - f1_score: 0.5925 - accuracy: 0.7531 - val_loss: 0.6122 - val_f1_score: 0.5985 - val_accuracy: 0.7440\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.3529 - f1_score: 0.5919 - accuracy: 0.8548 - val_loss: 0.5451 - val_f1_score: 0.5985 - val_accuracy: 0.7390\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 158s 281ms/step - loss: 0.2304 - f1_score: 0.5919 - accuracy: 0.9124 - val_loss: 0.7162 - val_f1_score: 0.5985 - val_accuracy: 0.7210\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.1418 - f1_score: 0.5919 - accuracy: 0.9522 - val_loss: 1.0644 - val_f1_score: 0.5985 - val_accuracy: 0.7280\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 164s 280ms/step - loss: 0.4691 - f1_score: 0.5925 - accuracy: 0.7698 - val_loss: 0.4622 - val_f1_score: 0.5985 - val_accuracy: 0.7710\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.3077 - f1_score: 0.5919 - accuracy: 0.8682 - val_loss: 0.4685 - val_f1_score: 0.5985 - val_accuracy: 0.7770\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 158s 281ms/step - loss: 0.1544 - f1_score: 0.5919 - accuracy: 0.9431 - val_loss: 0.7377 - val_f1_score: 0.5985 - val_accuracy: 0.7560\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.0723 - f1_score: 0.5919 - accuracy: 0.9751 - val_loss: 1.0836 - val_f1_score: 0.5985 - val_accuracy: 0.7590\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 164s 280ms/step - loss: 0.4816 - f1_score: 0.5925 - accuracy: 0.7633 - val_loss: 0.4834 - val_f1_score: 0.5985 - val_accuracy: 0.7600\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 158s 281ms/step - loss: 0.3085 - f1_score: 0.5919 - accuracy: 0.8680 - val_loss: 0.5303 - val_f1_score: 0.5985 - val_accuracy: 0.7670\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.1622 - f1_score: 0.5919 - accuracy: 0.9344 - val_loss: 0.7454 - val_f1_score: 0.5985 - val_accuracy: 0.7740\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 158s 281ms/step - loss: 0.0714 - f1_score: 0.5919 - accuracy: 0.9757 - val_loss: 0.8786 - val_f1_score: 0.5985 - val_accuracy: 0.7760\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 179s 154ms/step - loss: 0.4755 - f1_score: 0.5925 - accuracy: 0.7641 - val_loss: 0.5209 - val_f1_score: 0.5985 - val_accuracy: 0.7490\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 174s 155ms/step - loss: 0.3270 - f1_score: 0.5919 - accuracy: 0.8568 - val_loss: 0.4470 - val_f1_score: 0.5985 - val_accuracy: 0.7800\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 173s 154ms/step - loss: 0.1988 - f1_score: 0.5919 - accuracy: 0.9218 - val_loss: 0.6953 - val_f1_score: 0.5985 - val_accuracy: 0.7670\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 174s 154ms/step - loss: 0.1124 - f1_score: 0.5919 - accuracy: 0.9622 - val_loss: 0.6965 - val_f1_score: 0.5985 - val_accuracy: 0.7710\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 180s 154ms/step - loss: 0.6816 - f1_score: 0.5925 - accuracy: 0.5798 - val_loss: 0.6858 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 174s 155ms/step - loss: 0.6846 - f1_score: 0.5919 - accuracy: 0.5724 - val_loss: 0.6831 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 173s 154ms/step - loss: 0.6837 - f1_score: 0.5919 - accuracy: 0.5706 - val_loss: 0.6836 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 174s 154ms/step - loss: 0.6837 - f1_score: 0.5919 - accuracy: 0.5758 - val_loss: 0.6939 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 180s 154ms/step - loss: 0.4670 - f1_score: 0.5925 - accuracy: 0.7736 - val_loss: 0.4651 - val_f1_score: 0.5985 - val_accuracy: 0.7720\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 174s 154ms/step - loss: 0.2942 - f1_score: 0.5919 - accuracy: 0.8761 - val_loss: 0.4973 - val_f1_score: 0.5985 - val_accuracy: 0.7610\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 173s 154ms/step - loss: 0.1504 - f1_score: 0.5919 - accuracy: 0.9461 - val_loss: 0.6349 - val_f1_score: 0.5985 - val_accuracy: 0.7820\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 174s 154ms/step - loss: 0.0791 - f1_score: 0.5919 - accuracy: 0.9710 - val_loss: 0.6950 - val_f1_score: 0.5985 - val_accuracy: 0.7820\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 180s 154ms/step - loss: 0.4672 - f1_score: 0.5925 - accuracy: 0.7707 - val_loss: 0.4738 - val_f1_score: 0.5985 - val_accuracy: 0.7700\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 174s 155ms/step - loss: 0.2960 - f1_score: 0.5919 - accuracy: 0.8737 - val_loss: 0.5420 - val_f1_score: 0.5985 - val_accuracy: 0.7360\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 174s 155ms/step - loss: 0.1385 - f1_score: 0.5919 - accuracy: 0.9467 - val_loss: 0.8032 - val_f1_score: 0.5985 - val_accuracy: 0.7520\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 174s 154ms/step - loss: 0.0673 - f1_score: 0.5919 - accuracy: 0.9769 - val_loss: 1.3108 - val_f1_score: 0.5985 - val_accuracy: 0.6640\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 164s 280ms/step - loss: 0.4778 - f1_score: 0.5925 - accuracy: 0.7663 - val_loss: 0.5178 - val_f1_score: 0.5985 - val_accuracy: 0.7260\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.3118 - f1_score: 0.5919 - accuracy: 0.8707 - val_loss: 0.5309 - val_f1_score: 0.5985 - val_accuracy: 0.7700\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 158s 281ms/step - loss: 0.1739 - f1_score: 0.5919 - accuracy: 0.9351 - val_loss: 0.6052 - val_f1_score: 0.5985 - val_accuracy: 0.7590\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.0920 - f1_score: 0.5919 - accuracy: 0.9689 - val_loss: 0.6535 - val_f1_score: 0.5985 - val_accuracy: 0.7390\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 164s 280ms/step - loss: 0.5234 - f1_score: 0.5925 - accuracy: 0.7393 - val_loss: 0.6187 - val_f1_score: 0.5985 - val_accuracy: 0.7230\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 157s 280ms/step - loss: 0.3930 - f1_score: 0.5919 - accuracy: 0.8282 - val_loss: 0.5362 - val_f1_score: 0.5985 - val_accuracy: 0.7540\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 157s 279ms/step - loss: 0.5390 - f1_score: 0.5919 - accuracy: 0.7117 - val_loss: 0.6912 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.6825 - f1_score: 0.5919 - accuracy: 0.5797 - val_loss: 0.6846 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 163s 279ms/step - loss: 0.4734 - f1_score: 0.5925 - accuracy: 0.7682 - val_loss: 0.4837 - val_f1_score: 0.5985 - val_accuracy: 0.7590\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 157s 280ms/step - loss: 0.3170 - f1_score: 0.5919 - accuracy: 0.8668 - val_loss: 0.4812 - val_f1_score: 0.5985 - val_accuracy: 0.7620\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.1811 - f1_score: 0.5919 - accuracy: 0.9326 - val_loss: 0.6632 - val_f1_score: 0.5985 - val_accuracy: 0.7880\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 157s 280ms/step - loss: 0.0852 - f1_score: 0.5919 - accuracy: 0.9711 - val_loss: 0.8071 - val_f1_score: 0.5985 - val_accuracy: 0.7790\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 163s 278ms/step - loss: 0.4591 - f1_score: 0.5925 - accuracy: 0.7777 - val_loss: 0.4784 - val_f1_score: 0.5985 - val_accuracy: 0.7680\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 157s 279ms/step - loss: 0.2856 - f1_score: 0.5919 - accuracy: 0.8814 - val_loss: 0.4698 - val_f1_score: 0.5985 - val_accuracy: 0.7830\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 157s 280ms/step - loss: 0.1388 - f1_score: 0.5919 - accuracy: 0.9509 - val_loss: 0.6885 - val_f1_score: 0.5985 - val_accuracy: 0.7650\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.0780 - f1_score: 0.5919 - accuracy: 0.9746 - val_loss: 0.9351 - val_f1_score: 0.5985 - val_accuracy: 0.7570\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 181s 155ms/step - loss: 0.4873 - f1_score: 0.5925 - accuracy: 0.7623 - val_loss: 0.4895 - val_f1_score: 0.5985 - val_accuracy: 0.7430\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 174s 155ms/step - loss: 0.3415 - f1_score: 0.5919 - accuracy: 0.8569 - val_loss: 0.5812 - val_f1_score: 0.5985 - val_accuracy: 0.7720\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 174s 154ms/step - loss: 0.1987 - f1_score: 0.5919 - accuracy: 0.9237 - val_loss: 0.6751 - val_f1_score: 0.5985 - val_accuracy: 0.7570\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 174s 155ms/step - loss: 0.1039 - f1_score: 0.5919 - accuracy: 0.9669 - val_loss: 1.0099 - val_f1_score: 0.5985 - val_accuracy: 0.7560\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 181s 155ms/step - loss: 0.7088 - f1_score: 0.5925 - accuracy: 0.5472 - val_loss: 0.6903 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 174s 155ms/step - loss: 0.7062 - f1_score: 0.5919 - accuracy: 0.5416 - val_loss: 0.6980 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 174s 155ms/step - loss: 0.7007 - f1_score: 0.5919 - accuracy: 0.5513 - val_loss: 0.7310 - val_f1_score: 0.5985 - val_accuracy: 0.4270\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 174s 154ms/step - loss: 0.6969 - f1_score: 0.5919 - accuracy: 0.5516 - val_loss: 0.6830 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 181s 155ms/step - loss: 0.4800 - f1_score: 0.5925 - accuracy: 0.7680 - val_loss: 0.4745 - val_f1_score: 0.5985 - val_accuracy: 0.7810\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 174s 155ms/step - loss: 0.3053 - f1_score: 0.5919 - accuracy: 0.8736 - val_loss: 0.6015 - val_f1_score: 0.5985 - val_accuracy: 0.7050\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 174s 155ms/step - loss: 0.1456 - f1_score: 0.5919 - accuracy: 0.9474 - val_loss: 0.6492 - val_f1_score: 0.5985 - val_accuracy: 0.7730\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 174s 155ms/step - loss: 0.0740 - f1_score: 0.5919 - accuracy: 0.9740 - val_loss: 0.7714 - val_f1_score: 0.5985 - val_accuracy: 0.7750\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 181s 155ms/step - loss: 0.4724 - f1_score: 0.5925 - accuracy: 0.7642 - val_loss: 0.4872 - val_f1_score: 0.5985 - val_accuracy: 0.7750\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 175s 155ms/step - loss: 0.3091 - f1_score: 0.5919 - accuracy: 0.8687 - val_loss: 0.5107 - val_f1_score: 0.5985 - val_accuracy: 0.7660\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 174s 155ms/step - loss: 0.1407 - f1_score: 0.5919 - accuracy: 0.9471 - val_loss: 0.7322 - val_f1_score: 0.5985 - val_accuracy: 0.7760\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 174s 155ms/step - loss: 0.0666 - f1_score: 0.5919 - accuracy: 0.9779 - val_loss: 1.0718 - val_f1_score: 0.5985 - val_accuracy: 0.7450\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 164s 280ms/step - loss: 0.4781 - f1_score: 0.5925 - accuracy: 0.7639 - val_loss: 0.4724 - val_f1_score: 0.5985 - val_accuracy: 0.7780\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.3222 - f1_score: 0.5919 - accuracy: 0.8618 - val_loss: 0.5180 - val_f1_score: 0.5985 - val_accuracy: 0.7640\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.1787 - f1_score: 0.5919 - accuracy: 0.9308 - val_loss: 0.6159 - val_f1_score: 0.5985 - val_accuracy: 0.7820\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.0906 - f1_score: 0.5919 - accuracy: 0.9690 - val_loss: 0.8627 - val_f1_score: 0.5985 - val_accuracy: 0.7420\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 163s 279ms/step - loss: 0.4998 - f1_score: 0.5925 - accuracy: 0.7538 - val_loss: 0.5118 - val_f1_score: 0.5985 - val_accuracy: 0.7410\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.3671 - f1_score: 0.5919 - accuracy: 0.8448 - val_loss: 0.5319 - val_f1_score: 0.5985 - val_accuracy: 0.7350\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.2492 - f1_score: 0.5919 - accuracy: 0.8996 - val_loss: 0.7664 - val_f1_score: 0.5985 - val_accuracy: 0.7250\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.1542 - f1_score: 0.5919 - accuracy: 0.9447 - val_loss: 1.0969 - val_f1_score: 0.5985 - val_accuracy: 0.7210\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 164s 280ms/step - loss: 0.4774 - f1_score: 0.5925 - accuracy: 0.7663 - val_loss: 0.5443 - val_f1_score: 0.5985 - val_accuracy: 0.7170\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.2968 - f1_score: 0.5919 - accuracy: 0.8711 - val_loss: 0.6021 - val_f1_score: 0.5985 - val_accuracy: 0.7400\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 157s 279ms/step - loss: 0.1483 - f1_score: 0.5919 - accuracy: 0.9456 - val_loss: 0.6150 - val_f1_score: 0.5985 - val_accuracy: 0.7780\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 157s 279ms/step - loss: 0.0658 - f1_score: 0.5919 - accuracy: 0.9793 - val_loss: 0.9615 - val_f1_score: 0.5985 - val_accuracy: 0.7460\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 165s 280ms/step - loss: 0.4734 - f1_score: 0.5925 - accuracy: 0.7678 - val_loss: 0.5320 - val_f1_score: 0.5985 - val_accuracy: 0.7140\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.3074 - f1_score: 0.5919 - accuracy: 0.8693 - val_loss: 0.4466 - val_f1_score: 0.5985 - val_accuracy: 0.8020\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.1598 - f1_score: 0.5919 - accuracy: 0.9416 - val_loss: 0.6646 - val_f1_score: 0.5985 - val_accuracy: 0.7680\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 158s 280ms/step - loss: 0.0800 - f1_score: 0.5919 - accuracy: 0.9724 - val_loss: 0.7540 - val_f1_score: 0.5985 - val_accuracy: 0.7570\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "learning_rates = [5e-5, 1e-4, 3e-5, 3e-5]\n",
    "learning_rates_text = ['5e-5', '1e-4', '3e-5', '3e-5']\n",
    "batch_sizes = [8, 16]\n",
    "dropout = [.5,.75,.25,0.0,.1]\n",
    "results = {}\n",
    "results_acc = {}\n",
    "for do in dropout:\n",
    "    for bs in batch_sizes:\n",
    "        for lr in range(len(learning_rates)):\n",
    "            string = 'lr{lr}_bs{bs}_do{do}'.format(lr=learning_rates_text[lr],bs=bs,do=do)\n",
    "            #filepath = 'checkpoints/bert_finetuned/lr{lr}_bs{bs}.hdf5'.format(lr=learning_rates_text[lr],bs=bs)\n",
    "            #checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
    "                                                 #    monitor='val_f1_score',\n",
    "                                                  #  save_best_only=True,\n",
    "                                                   #  verbose=1,)\n",
    "            #callbacks = [checkpoint]\n",
    "\n",
    "            bert = build_classifier_model(do,trainable=True)\n",
    "            bert.compile(loss = loss, optimizer = Adam(learning_rate=learning_rates[lr]), metrics = [f1,'accuracy'])\n",
    "            history = bert.fit(x=x_train,\n",
    "                                y=y_train,batch_size=bs,\n",
    "                                validation_data=(x_val,y_val),\n",
    "                                epochs=4)\n",
    "\n",
    "            max_f1 = max(history.history['val_f1_score'])\n",
    "            max_acc = max(history.history['val_accuracy'])\n",
    "            results[string] = max_f1\n",
    "            results_acc[string] = max_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "{'lr5e-5_bs8_do0.5': 0.5984582901000977,\n 'lr1e-4_bs8_do0.5': 0.5984582901000977,\n 'lr3e-5_bs8_do0.5': 0.5984582901000977,\n 'lr5e-5_bs16_do0.5': 0.5984582901000977,\n 'lr1e-4_bs16_do0.5': 0.5984582901000977,\n 'lr3e-5_bs16_do0.5': 0.5984582901000977,\n 'lr5e-5_bs8_do0.75': 0.5984582901000977,\n 'lr1e-4_bs8_do0.75': 0.5984582901000977,\n 'lr3e-5_bs8_do0.75': 0.5984582901000977,\n 'lr5e-5_bs16_do0.75': 0.5984582901000977,\n 'lr1e-4_bs16_do0.75': 0.5984582901000977,\n 'lr3e-5_bs16_do0.75': 0.5984582901000977,\n 'lr5e-5_bs8_do0.25': 0.5984582901000977,\n 'lr1e-4_bs8_do0.25': 0.5984582901000977,\n 'lr3e-5_bs8_do0.25': 0.5984582901000977,\n 'lr5e-5_bs16_do0.25': 0.5984582901000977,\n 'lr1e-4_bs16_do0.25': 0.5984582901000977,\n 'lr3e-5_bs16_do0.25': 0.5984582901000977,\n 'lr5e-5_bs8_do0.0': 0.5984582901000977,\n 'lr1e-4_bs8_do0.0': 0.5984582901000977,\n 'lr3e-5_bs8_do0.0': 0.5984582901000977,\n 'lr5e-5_bs16_do0.0': 0.5984582901000977,\n 'lr1e-4_bs16_do0.0': 0.5984582901000977,\n 'lr3e-5_bs16_do0.0': 0.5984582901000977,\n 'lr5e-5_bs8_do0.1': 0.5984582901000977,\n 'lr1e-4_bs8_do0.1': 0.5984582901000977,\n 'lr3e-5_bs8_do0.1': 0.5984582901000977,\n 'lr5e-5_bs16_do0.1': 0.5984582901000977,\n 'lr1e-4_bs16_do0.1': 0.5984582901000977,\n 'lr3e-5_bs16_do0.1': 0.5984582901000977}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "results2 = {}\n",
    "results2_acc = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 64s 54ms/step - loss: 0.7664 - f1_score: 0.5925 - accuracy: 0.5293 - val_loss: 0.6778 - val_f1_score: 0.5985 - val_accuracy: 0.5690\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 61s 54ms/step - loss: 0.7499 - f1_score: 0.5919 - accuracy: 0.5382 - val_loss: 0.6674 - val_f1_score: 0.5985 - val_accuracy: 0.5900\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 63s 56ms/step - loss: 0.7402 - f1_score: 0.5919 - accuracy: 0.5396 - val_loss: 0.6601 - val_f1_score: 0.5985 - val_accuracy: 0.5920\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 60s 54ms/step - loss: 0.7188 - f1_score: 0.5919 - accuracy: 0.5608 - val_loss: 0.6564 - val_f1_score: 0.5985 - val_accuracy: 0.5850\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 65s 53ms/step - loss: 0.7571 - f1_score: 0.5925 - accuracy: 0.5282 - val_loss: 0.6776 - val_f1_score: 0.5985 - val_accuracy: 0.5770\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 61s 54ms/step - loss: 0.7434 - f1_score: 0.5919 - accuracy: 0.5336 - val_loss: 0.6578 - val_f1_score: 0.5985 - val_accuracy: 0.5790\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 61s 54ms/step - loss: 0.7161 - f1_score: 0.5919 - accuracy: 0.5580 - val_loss: 0.6519 - val_f1_score: 0.5985 - val_accuracy: 0.5830\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 61s 54ms/step - loss: 0.7056 - f1_score: 0.5919 - accuracy: 0.5667 - val_loss: 0.6472 - val_f1_score: 0.5985 - val_accuracy: 0.6190\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 64s 53ms/step - loss: 0.7802 - f1_score: 0.5925 - accuracy: 0.5128 - val_loss: 0.6853 - val_f1_score: 0.5985 - val_accuracy: 0.5670\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.7531 - f1_score: 0.5919 - accuracy: 0.5373 - val_loss: 0.6768 - val_f1_score: 0.5985 - val_accuracy: 0.5550\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 60s 53ms/step - loss: 0.7532 - f1_score: 0.5919 - accuracy: 0.5393 - val_loss: 0.6723 - val_f1_score: 0.5985 - val_accuracy: 0.5590\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 64s 57ms/step - loss: 0.7448 - f1_score: 0.5919 - accuracy: 0.5400 - val_loss: 0.6691 - val_f1_score: 0.5985 - val_accuracy: 0.5680\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 70s 58ms/step - loss: 0.7757 - f1_score: 0.5925 - accuracy: 0.5126 - val_loss: 0.6678 - val_f1_score: 0.5985 - val_accuracy: 0.5810\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 68s 60ms/step - loss: 0.7437 - f1_score: 0.5919 - accuracy: 0.5387 - val_loss: 0.6643 - val_f1_score: 0.5985 - val_accuracy: 0.5830\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 69s 61ms/step - loss: 0.7385 - f1_score: 0.5919 - accuracy: 0.5409 - val_loss: 0.6608 - val_f1_score: 0.5985 - val_accuracy: 0.5840\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 65s 58ms/step - loss: 0.7396 - f1_score: 0.5919 - accuracy: 0.5364 - val_loss: 0.6584 - val_f1_score: 0.5985 - val_accuracy: 0.5820\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 67s 112ms/step - loss: 0.7496 - f1_score: 0.5925 - accuracy: 0.5412 - val_loss: 0.6693 - val_f1_score: 0.5985 - val_accuracy: 0.5700\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 61s 109ms/step - loss: 0.7356 - f1_score: 0.5919 - accuracy: 0.5462 - val_loss: 0.6662 - val_f1_score: 0.5985 - val_accuracy: 0.5680\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 62s 111ms/step - loss: 0.7315 - f1_score: 0.5919 - accuracy: 0.5453 - val_loss: 0.6631 - val_f1_score: 0.5985 - val_accuracy: 0.5640\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 62s 110ms/step - loss: 0.7223 - f1_score: 0.5919 - accuracy: 0.5583 - val_loss: 0.6625 - val_f1_score: 0.5985 - val_accuracy: 0.5710\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 67s 112ms/step - loss: 0.7699 - f1_score: 0.5925 - accuracy: 0.5260 - val_loss: 0.6747 - val_f1_score: 0.5985 - val_accuracy: 0.5820\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 61s 109ms/step - loss: 0.7472 - f1_score: 0.5919 - accuracy: 0.5338 - val_loss: 0.6658 - val_f1_score: 0.5985 - val_accuracy: 0.5810\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.7324 - f1_score: 0.5919 - accuracy: 0.5489 - val_loss: 0.6597 - val_f1_score: 0.5985 - val_accuracy: 0.5850\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.7227 - f1_score: 0.5919 - accuracy: 0.5544 - val_loss: 0.6557 - val_f1_score: 0.5985 - val_accuracy: 0.6120\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 67s 112ms/step - loss: 0.7482 - f1_score: 0.5925 - accuracy: 0.5508 - val_loss: 0.6770 - val_f1_score: 0.5985 - val_accuracy: 0.5770\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 62s 111ms/step - loss: 0.7386 - f1_score: 0.5919 - accuracy: 0.5469 - val_loss: 0.6775 - val_f1_score: 0.5985 - val_accuracy: 0.5760\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 63s 111ms/step - loss: 0.7316 - f1_score: 0.5919 - accuracy: 0.5531 - val_loss: 0.6711 - val_f1_score: 0.5985 - val_accuracy: 0.5860\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 63s 112ms/step - loss: 0.7293 - f1_score: 0.5919 - accuracy: 0.5524 - val_loss: 0.6686 - val_f1_score: 0.5985 - val_accuracy: 0.5840\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 64s 107ms/step - loss: 0.7860 - f1_score: 0.5925 - accuracy: 0.5137 - val_loss: 0.6745 - val_f1_score: 0.5985 - val_accuracy: 0.5810\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 62s 111ms/step - loss: 0.7556 - f1_score: 0.5919 - accuracy: 0.5297 - val_loss: 0.6710 - val_f1_score: 0.5985 - val_accuracy: 0.5780\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 63s 113ms/step - loss: 0.7426 - f1_score: 0.5919 - accuracy: 0.5474 - val_loss: 0.6679 - val_f1_score: 0.5985 - val_accuracy: 0.5830\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 60s 107ms/step - loss: 0.7429 - f1_score: 0.5919 - accuracy: 0.5401 - val_loss: 0.6655 - val_f1_score: 0.5985 - val_accuracy: 0.5790\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 64s 53ms/step - loss: 0.9297 - f1_score: 0.5925 - accuracy: 0.5104 - val_loss: 0.6855 - val_f1_score: 0.5985 - val_accuracy: 0.5690\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 61s 54ms/step - loss: 0.8878 - f1_score: 0.5919 - accuracy: 0.5192 - val_loss: 0.6821 - val_f1_score: 0.5985 - val_accuracy: 0.5750\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 59s 53ms/step - loss: 0.8642 - f1_score: 0.5919 - accuracy: 0.5248 - val_loss: 0.6748 - val_f1_score: 0.5985 - val_accuracy: 0.5740\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 60s 54ms/step - loss: 0.8270 - f1_score: 0.5919 - accuracy: 0.5398 - val_loss: 0.6729 - val_f1_score: 0.5985 - val_accuracy: 0.5770\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 64s 53ms/step - loss: 0.8622 - f1_score: 0.5925 - accuracy: 0.5248 - val_loss: 0.6807 - val_f1_score: 0.5985 - val_accuracy: 0.5710\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 63s 56ms/step - loss: 0.8279 - f1_score: 0.5919 - accuracy: 0.5320 - val_loss: 0.6717 - val_f1_score: 0.5985 - val_accuracy: 0.5740\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 64s 57ms/step - loss: 0.7900 - f1_score: 0.5919 - accuracy: 0.5429 - val_loss: 0.6600 - val_f1_score: 0.5985 - val_accuracy: 0.5940\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 63s 56ms/step - loss: 0.7626 - f1_score: 0.5919 - accuracy: 0.5460 - val_loss: 0.6544 - val_f1_score: 0.5985 - val_accuracy: 0.6090\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 65s 55ms/step - loss: 0.8914 - f1_score: 0.5925 - accuracy: 0.5251 - val_loss: 0.6848 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 63s 56ms/step - loss: 0.8745 - f1_score: 0.5919 - accuracy: 0.5363 - val_loss: 0.6795 - val_f1_score: 0.5985 - val_accuracy: 0.5740\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 63s 56ms/step - loss: 0.8698 - f1_score: 0.5919 - accuracy: 0.5251 - val_loss: 0.6758 - val_f1_score: 0.5985 - val_accuracy: 0.5740\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 64s 57ms/step - loss: 0.8512 - f1_score: 0.5919 - accuracy: 0.5286 - val_loss: 0.6705 - val_f1_score: 0.5985 - val_accuracy: 0.5820\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 66s 55ms/step - loss: 0.8859 - f1_score: 0.5925 - accuracy: 0.5219 - val_loss: 0.6841 - val_f1_score: 0.5985 - val_accuracy: 0.5710\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 63s 56ms/step - loss: 0.8583 - f1_score: 0.5919 - accuracy: 0.5300 - val_loss: 0.6743 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 63s 56ms/step - loss: 0.8362 - f1_score: 0.5919 - accuracy: 0.5319 - val_loss: 0.6668 - val_f1_score: 0.5985 - val_accuracy: 0.5780\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 62s 56ms/step - loss: 0.8166 - f1_score: 0.5919 - accuracy: 0.5432 - val_loss: 0.6631 - val_f1_score: 0.5985 - val_accuracy: 0.5850\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 65s 108ms/step - loss: 0.9013 - f1_score: 0.5925 - accuracy: 0.5262 - val_loss: 0.6801 - val_f1_score: 0.5985 - val_accuracy: 0.5680\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.8677 - f1_score: 0.5919 - accuracy: 0.5259 - val_loss: 0.6739 - val_f1_score: 0.5985 - val_accuracy: 0.5660\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.8598 - f1_score: 0.5919 - accuracy: 0.5248 - val_loss: 0.6707 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 63s 112ms/step - loss: 0.8317 - f1_score: 0.5919 - accuracy: 0.5301 - val_loss: 0.6672 - val_f1_score: 0.5985 - val_accuracy: 0.5770\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 66s 110ms/step - loss: 0.8816 - f1_score: 0.5925 - accuracy: 0.5300 - val_loss: 0.6608 - val_f1_score: 0.5985 - val_accuracy: 0.5720\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 63s 111ms/step - loss: 0.8526 - f1_score: 0.5919 - accuracy: 0.5247 - val_loss: 0.6566 - val_f1_score: 0.5985 - val_accuracy: 0.5760\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.8157 - f1_score: 0.5919 - accuracy: 0.5416 - val_loss: 0.6540 - val_f1_score: 0.5985 - val_accuracy: 0.5790\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 61s 109ms/step - loss: 0.8015 - f1_score: 0.5919 - accuracy: 0.5407 - val_loss: 0.6509 - val_f1_score: 0.5985 - val_accuracy: 0.5800\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 64s 106ms/step - loss: 0.9069 - f1_score: 0.5925 - accuracy: 0.5123 - val_loss: 0.6828 - val_f1_score: 0.5985 - val_accuracy: 0.5690\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 62s 111ms/step - loss: 0.8938 - f1_score: 0.5919 - accuracy: 0.5184 - val_loss: 0.6810 - val_f1_score: 0.5985 - val_accuracy: 0.5700\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 63s 112ms/step - loss: 0.8850 - f1_score: 0.5919 - accuracy: 0.5217 - val_loss: 0.6770 - val_f1_score: 0.5985 - val_accuracy: 0.5670\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 63s 112ms/step - loss: 0.8630 - f1_score: 0.5919 - accuracy: 0.5291 - val_loss: 0.6756 - val_f1_score: 0.5985 - val_accuracy: 0.5680\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 67s 112ms/step - loss: 0.9491 - f1_score: 0.5925 - accuracy: 0.4919 - val_loss: 0.6886 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 63s 113ms/step - loss: 0.8876 - f1_score: 0.5919 - accuracy: 0.5142 - val_loss: 0.6881 - val_f1_score: 0.5985 - val_accuracy: 0.5800\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 64s 113ms/step - loss: 0.8742 - f1_score: 0.5919 - accuracy: 0.5269 - val_loss: 0.6833 - val_f1_score: 0.5985 - val_accuracy: 0.5800\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 64s 113ms/step - loss: 0.8623 - f1_score: 0.5919 - accuracy: 0.5178 - val_loss: 0.6811 - val_f1_score: 0.5985 - val_accuracy: 0.5720\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 70s 59ms/step - loss: 0.7042 - f1_score: 0.5925 - accuracy: 0.5528 - val_loss: 0.6696 - val_f1_score: 0.5985 - val_accuracy: 0.5880\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 67s 59ms/step - loss: 0.6913 - f1_score: 0.5919 - accuracy: 0.5681 - val_loss: 0.6621 - val_f1_score: 0.5985 - val_accuracy: 0.5900\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 66s 58ms/step - loss: 0.6813 - f1_score: 0.5919 - accuracy: 0.5791 - val_loss: 0.6535 - val_f1_score: 0.5985 - val_accuracy: 0.6020\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 66s 59ms/step - loss: 0.6721 - f1_score: 0.5919 - accuracy: 0.5868 - val_loss: 0.6490 - val_f1_score: 0.5985 - val_accuracy: 0.6040\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 70s 58ms/step - loss: 0.7065 - f1_score: 0.5925 - accuracy: 0.5470 - val_loss: 0.6637 - val_f1_score: 0.5985 - val_accuracy: 0.5780\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 67s 60ms/step - loss: 0.6833 - f1_score: 0.5919 - accuracy: 0.5803 - val_loss: 0.6527 - val_f1_score: 0.5985 - val_accuracy: 0.5850\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 66s 59ms/step - loss: 0.6759 - f1_score: 0.5919 - accuracy: 0.5794 - val_loss: 0.6449 - val_f1_score: 0.5985 - val_accuracy: 0.6340\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 65s 58ms/step - loss: 0.6634 - f1_score: 0.5919 - accuracy: 0.5914 - val_loss: 0.6386 - val_f1_score: 0.5985 - val_accuracy: 0.6340\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 68s 57ms/step - loss: 0.7209 - f1_score: 0.5925 - accuracy: 0.5236 - val_loss: 0.6892 - val_f1_score: 0.5985 - val_accuracy: 0.5700\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 65s 58ms/step - loss: 0.7073 - f1_score: 0.5919 - accuracy: 0.5432 - val_loss: 0.6827 - val_f1_score: 0.5985 - val_accuracy: 0.5680\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 66s 59ms/step - loss: 0.7064 - f1_score: 0.5919 - accuracy: 0.5484 - val_loss: 0.6785 - val_f1_score: 0.5985 - val_accuracy: 0.5660\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 63s 56ms/step - loss: 0.6970 - f1_score: 0.5919 - accuracy: 0.5487 - val_loss: 0.6720 - val_f1_score: 0.5985 - val_accuracy: 0.5660\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 66s 55ms/step - loss: 0.7063 - f1_score: 0.5925 - accuracy: 0.5520 - val_loss: 0.6633 - val_f1_score: 0.5985 - val_accuracy: 0.5740\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 63s 56ms/step - loss: 0.6976 - f1_score: 0.5919 - accuracy: 0.5560 - val_loss: 0.6612 - val_f1_score: 0.5985 - val_accuracy: 0.5760\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 63s 56ms/step - loss: 0.6922 - f1_score: 0.5919 - accuracy: 0.5682 - val_loss: 0.6559 - val_f1_score: 0.5985 - val_accuracy: 0.5880\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 62s 55ms/step - loss: 0.6859 - f1_score: 0.5919 - accuracy: 0.5730 - val_loss: 0.6534 - val_f1_score: 0.5985 - val_accuracy: 0.5970\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 65s 109ms/step - loss: 0.7022 - f1_score: 0.5925 - accuracy: 0.5431 - val_loss: 0.6711 - val_f1_score: 0.5985 - val_accuracy: 0.5650\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 61s 109ms/step - loss: 0.6978 - f1_score: 0.5919 - accuracy: 0.5538 - val_loss: 0.6670 - val_f1_score: 0.5985 - val_accuracy: 0.5610\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6921 - f1_score: 0.5919 - accuracy: 0.5612 - val_loss: 0.6629 - val_f1_score: 0.5985 - val_accuracy: 0.5620\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 61s 109ms/step - loss: 0.6876 - f1_score: 0.5919 - accuracy: 0.5676 - val_loss: 0.6600 - val_f1_score: 0.5985 - val_accuracy: 0.5640\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 65s 108ms/step - loss: 0.7090 - f1_score: 0.5925 - accuracy: 0.5446 - val_loss: 0.6774 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6887 - f1_score: 0.5919 - accuracy: 0.5673 - val_loss: 0.6631 - val_f1_score: 0.5985 - val_accuracy: 0.5830\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 61s 109ms/step - loss: 0.6827 - f1_score: 0.5919 - accuracy: 0.5740 - val_loss: 0.6534 - val_f1_score: 0.5985 - val_accuracy: 0.6070\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6721 - f1_score: 0.5919 - accuracy: 0.5856 - val_loss: 0.6474 - val_f1_score: 0.5985 - val_accuracy: 0.5930\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 65s 108ms/step - loss: 0.7192 - f1_score: 0.5925 - accuracy: 0.5287 - val_loss: 0.6644 - val_f1_score: 0.5985 - val_accuracy: 0.5840\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 61s 109ms/step - loss: 0.7009 - f1_score: 0.5919 - accuracy: 0.5541 - val_loss: 0.6617 - val_f1_score: 0.5985 - val_accuracy: 0.5820\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6955 - f1_score: 0.5919 - accuracy: 0.5541 - val_loss: 0.6599 - val_f1_score: 0.5985 - val_accuracy: 0.5850\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6949 - f1_score: 0.5919 - accuracy: 0.5604 - val_loss: 0.6583 - val_f1_score: 0.5985 - val_accuracy: 0.5960\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 65s 108ms/step - loss: 0.7309 - f1_score: 0.5925 - accuracy: 0.5507 - val_loss: 0.6846 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.7084 - f1_score: 0.5919 - accuracy: 0.5459 - val_loss: 0.6751 - val_f1_score: 0.5985 - val_accuracy: 0.5730\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.7004 - f1_score: 0.5919 - accuracy: 0.5576 - val_loss: 0.6696 - val_f1_score: 0.5985 - val_accuracy: 0.5760\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6980 - f1_score: 0.5919 - accuracy: 0.5533 - val_loss: 0.6653 - val_f1_score: 0.5985 - val_accuracy: 0.5760\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 65s 54ms/step - loss: 0.6942 - f1_score: 0.5925 - accuracy: 0.5654 - val_loss: 0.6709 - val_f1_score: 0.5985 - val_accuracy: 0.5950\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 61s 55ms/step - loss: 0.6669 - f1_score: 0.5919 - accuracy: 0.5917 - val_loss: 0.6628 - val_f1_score: 0.5985 - val_accuracy: 0.5930\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 62s 55ms/step - loss: 0.6596 - f1_score: 0.5919 - accuracy: 0.6032 - val_loss: 0.6549 - val_f1_score: 0.5985 - val_accuracy: 0.6030\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 62s 55ms/step - loss: 0.6533 - f1_score: 0.5919 - accuracy: 0.6093 - val_loss: 0.6493 - val_f1_score: 0.5985 - val_accuracy: 0.6020\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 65s 54ms/step - loss: 0.6724 - f1_score: 0.5925 - accuracy: 0.5843 - val_loss: 0.6534 - val_f1_score: 0.5985 - val_accuracy: 0.6030\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 62s 55ms/step - loss: 0.6565 - f1_score: 0.5919 - accuracy: 0.6083 - val_loss: 0.6428 - val_f1_score: 0.5985 - val_accuracy: 0.6490\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 61s 55ms/step - loss: 0.6457 - f1_score: 0.5919 - accuracy: 0.6270 - val_loss: 0.6383 - val_f1_score: 0.5985 - val_accuracy: 0.6400\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 62s 55ms/step - loss: 0.6379 - f1_score: 0.5919 - accuracy: 0.6414 - val_loss: 0.6338 - val_f1_score: 0.5985 - val_accuracy: 0.6210\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 66s 55ms/step - loss: 0.7192 - f1_score: 0.5925 - accuracy: 0.5417 - val_loss: 0.6761 - val_f1_score: 0.5985 - val_accuracy: 0.5750\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 62s 55ms/step - loss: 0.6710 - f1_score: 0.5919 - accuracy: 0.5873 - val_loss: 0.6707 - val_f1_score: 0.5985 - val_accuracy: 0.5760\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 62s 55ms/step - loss: 0.6659 - f1_score: 0.5919 - accuracy: 0.5971 - val_loss: 0.6656 - val_f1_score: 0.5985 - val_accuracy: 0.5840\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 62s 55ms/step - loss: 0.6618 - f1_score: 0.5919 - accuracy: 0.6008 - val_loss: 0.6615 - val_f1_score: 0.5985 - val_accuracy: 0.5870\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 65s 54ms/step - loss: 0.6714 - f1_score: 0.5925 - accuracy: 0.5771 - val_loss: 0.6674 - val_f1_score: 0.5985 - val_accuracy: 0.5760\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 61s 55ms/step - loss: 0.6632 - f1_score: 0.5919 - accuracy: 0.5894 - val_loss: 0.6617 - val_f1_score: 0.5985 - val_accuracy: 0.5760\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 61s 55ms/step - loss: 0.6584 - f1_score: 0.5919 - accuracy: 0.5924 - val_loss: 0.6563 - val_f1_score: 0.5985 - val_accuracy: 0.5870\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 62s 55ms/step - loss: 0.6543 - f1_score: 0.5919 - accuracy: 0.6040 - val_loss: 0.6535 - val_f1_score: 0.5985 - val_accuracy: 0.6060\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 65s 107ms/step - loss: 0.6799 - f1_score: 0.5925 - accuracy: 0.5744 - val_loss: 0.6679 - val_f1_score: 0.5985 - val_accuracy: 0.5750\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 60s 107ms/step - loss: 0.6699 - f1_score: 0.5919 - accuracy: 0.5833 - val_loss: 0.6620 - val_f1_score: 0.5985 - val_accuracy: 0.5780\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6642 - f1_score: 0.5919 - accuracy: 0.5904 - val_loss: 0.6573 - val_f1_score: 0.5985 - val_accuracy: 0.6160\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6599 - f1_score: 0.5919 - accuracy: 0.6046 - val_loss: 0.6548 - val_f1_score: 0.5985 - val_accuracy: 0.5750\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 65s 108ms/step - loss: 0.6705 - f1_score: 0.5925 - accuracy: 0.5814 - val_loss: 0.6684 - val_f1_score: 0.5985 - val_accuracy: 0.5720\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 61s 109ms/step - loss: 0.6593 - f1_score: 0.5919 - accuracy: 0.5904 - val_loss: 0.6656 - val_f1_score: 0.5985 - val_accuracy: 0.5970\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 61s 109ms/step - loss: 0.6523 - f1_score: 0.5919 - accuracy: 0.6071 - val_loss: 0.6512 - val_f1_score: 0.5985 - val_accuracy: 0.5770\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 61s 109ms/step - loss: 0.6453 - f1_score: 0.5919 - accuracy: 0.6181 - val_loss: 0.6475 - val_f1_score: 0.5985 - val_accuracy: 0.5890\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 65s 108ms/step - loss: 0.7023 - f1_score: 0.5925 - accuracy: 0.5449 - val_loss: 0.6838 - val_f1_score: 0.5985 - val_accuracy: 0.5720\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6806 - f1_score: 0.5919 - accuracy: 0.5784 - val_loss: 0.6737 - val_f1_score: 0.5985 - val_accuracy: 0.5780\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6751 - f1_score: 0.5919 - accuracy: 0.5832 - val_loss: 0.6677 - val_f1_score: 0.5985 - val_accuracy: 0.5840\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6710 - f1_score: 0.5919 - accuracy: 0.5900 - val_loss: 0.6637 - val_f1_score: 0.5985 - val_accuracy: 0.5920\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 64s 108ms/step - loss: 0.7025 - f1_score: 0.5925 - accuracy: 0.5409 - val_loss: 0.6830 - val_f1_score: 0.5985 - val_accuracy: 0.5710\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 60s 107ms/step - loss: 0.6840 - f1_score: 0.5919 - accuracy: 0.5739 - val_loss: 0.6781 - val_f1_score: 0.5985 - val_accuracy: 0.5690\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6800 - f1_score: 0.5919 - accuracy: 0.5741 - val_loss: 0.6737 - val_f1_score: 0.5985 - val_accuracy: 0.5700\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 60s 107ms/step - loss: 0.6762 - f1_score: 0.5919 - accuracy: 0.5734 - val_loss: 0.6699 - val_f1_score: 0.5985 - val_accuracy: 0.5740\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 65s 54ms/step - loss: 0.6759 - f1_score: 0.5925 - accuracy: 0.5761 - val_loss: 0.6633 - val_f1_score: 0.5985 - val_accuracy: 0.5760\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 61s 55ms/step - loss: 0.6672 - f1_score: 0.5919 - accuracy: 0.5891 - val_loss: 0.6551 - val_f1_score: 0.5985 - val_accuracy: 0.5940\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 61s 55ms/step - loss: 0.6629 - f1_score: 0.5919 - accuracy: 0.5946 - val_loss: 0.6565 - val_f1_score: 0.5985 - val_accuracy: 0.6200\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 62s 55ms/step - loss: 0.6559 - f1_score: 0.5919 - accuracy: 0.6050 - val_loss: 0.6464 - val_f1_score: 0.5985 - val_accuracy: 0.6020\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 65s 54ms/step - loss: 0.6878 - f1_score: 0.5925 - accuracy: 0.5571 - val_loss: 0.6632 - val_f1_score: 0.5985 - val_accuracy: 0.5770\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 61s 55ms/step - loss: 0.6712 - f1_score: 0.5919 - accuracy: 0.5774 - val_loss: 0.6610 - val_f1_score: 0.5985 - val_accuracy: 0.6060\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 61s 54ms/step - loss: 0.6634 - f1_score: 0.5919 - accuracy: 0.5919 - val_loss: 0.6481 - val_f1_score: 0.5985 - val_accuracy: 0.6110\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 61s 55ms/step - loss: 0.6523 - f1_score: 0.5919 - accuracy: 0.6103 - val_loss: 0.6412 - val_f1_score: 0.5985 - val_accuracy: 0.6110\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 65s 54ms/step - loss: 0.6833 - f1_score: 0.5925 - accuracy: 0.5587 - val_loss: 0.6692 - val_f1_score: 0.5985 - val_accuracy: 0.5810\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 61s 54ms/step - loss: 0.6747 - f1_score: 0.5919 - accuracy: 0.5839 - val_loss: 0.6631 - val_f1_score: 0.5985 - val_accuracy: 0.6050\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 61s 55ms/step - loss: 0.6717 - f1_score: 0.5919 - accuracy: 0.5883 - val_loss: 0.6587 - val_f1_score: 0.5985 - val_accuracy: 0.6020\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 61s 55ms/step - loss: 0.6679 - f1_score: 0.5919 - accuracy: 0.5936 - val_loss: 0.6553 - val_f1_score: 0.5985 - val_accuracy: 0.6140\n",
      "Epoch 1/4\n",
      "1125/1125 [==============================] - 66s 54ms/step - loss: 0.6949 - f1_score: 0.5925 - accuracy: 0.5586 - val_loss: 0.6841 - val_f1_score: 0.5985 - val_accuracy: 0.5660\n",
      "Epoch 2/4\n",
      "1125/1125 [==============================] - 61s 54ms/step - loss: 0.6879 - f1_score: 0.5919 - accuracy: 0.5637 - val_loss: 0.6771 - val_f1_score: 0.5985 - val_accuracy: 0.5630\n",
      "Epoch 3/4\n",
      "1125/1125 [==============================] - 61s 54ms/step - loss: 0.6817 - f1_score: 0.5919 - accuracy: 0.5696 - val_loss: 0.6725 - val_f1_score: 0.5985 - val_accuracy: 0.5700\n",
      "Epoch 4/4\n",
      "1125/1125 [==============================] - 61s 54ms/step - loss: 0.6761 - f1_score: 0.5919 - accuracy: 0.5800 - val_loss: 0.6670 - val_f1_score: 0.5985 - val_accuracy: 0.5710\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 65s 108ms/step - loss: 0.7038 - f1_score: 0.5925 - accuracy: 0.5389 - val_loss: 0.6809 - val_f1_score: 0.5985 - val_accuracy: 0.5710\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6806 - f1_score: 0.5919 - accuracy: 0.5687 - val_loss: 0.6711 - val_f1_score: 0.5985 - val_accuracy: 0.5720\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6737 - f1_score: 0.5919 - accuracy: 0.5793 - val_loss: 0.6662 - val_f1_score: 0.5985 - val_accuracy: 0.5690\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6685 - f1_score: 0.5919 - accuracy: 0.5901 - val_loss: 0.6619 - val_f1_score: 0.5985 - val_accuracy: 0.5820\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 64s 108ms/step - loss: 0.7013 - f1_score: 0.5925 - accuracy: 0.5472 - val_loss: 0.6723 - val_f1_score: 0.5985 - val_accuracy: 0.5650\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6839 - f1_score: 0.5919 - accuracy: 0.5613 - val_loss: 0.6648 - val_f1_score: 0.5985 - val_accuracy: 0.5680\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 61s 109ms/step - loss: 0.6716 - f1_score: 0.5919 - accuracy: 0.5828 - val_loss: 0.6547 - val_f1_score: 0.5985 - val_accuracy: 0.5790\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6640 - f1_score: 0.5919 - accuracy: 0.5863 - val_loss: 0.6505 - val_f1_score: 0.5985 - val_accuracy: 0.5840\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 65s 107ms/step - loss: 0.7091 - f1_score: 0.5925 - accuracy: 0.5460 - val_loss: 0.6880 - val_f1_score: 0.5985 - val_accuracy: 0.5640\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6892 - f1_score: 0.5919 - accuracy: 0.5632 - val_loss: 0.6749 - val_f1_score: 0.5985 - val_accuracy: 0.5470\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6832 - f1_score: 0.5919 - accuracy: 0.5594 - val_loss: 0.6696 - val_f1_score: 0.5985 - val_accuracy: 0.5580\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6814 - f1_score: 0.5919 - accuracy: 0.5660 - val_loss: 0.6670 - val_f1_score: 0.5985 - val_accuracy: 0.5630\n",
      "Epoch 1/4\n",
      "563/563 [==============================] - 64s 107ms/step - loss: 0.6863 - f1_score: 0.5925 - accuracy: 0.5580 - val_loss: 0.6700 - val_f1_score: 0.5985 - val_accuracy: 0.5750\n",
      "Epoch 2/4\n",
      "563/563 [==============================] - 60s 107ms/step - loss: 0.6780 - f1_score: 0.5919 - accuracy: 0.5772 - val_loss: 0.6656 - val_f1_score: 0.5985 - val_accuracy: 0.5770\n",
      "Epoch 3/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6752 - f1_score: 0.5919 - accuracy: 0.5788 - val_loss: 0.6622 - val_f1_score: 0.5985 - val_accuracy: 0.5880\n",
      "Epoch 4/4\n",
      "563/563 [==============================] - 61s 108ms/step - loss: 0.6728 - f1_score: 0.5919 - accuracy: 0.5810 - val_loss: 0.6602 - val_f1_score: 0.5985 - val_accuracy: 0.6060\n"
     ]
    }
   ],
   "source": [
    "for do in dropout:\n",
    "    for bs in batch_sizes:\n",
    "        for lr in range(len(learning_rates)):\n",
    "            string = 'lr{lr}_bs{bs}_do{do}'.format(lr=learning_rates_text[lr],bs=bs,do=do)\n",
    "            #filepath = 'checkpoints/bert_finetuned/lr{lr}_bs{bs}.hdf5'.format(lr=learning_rates_text[lr],bs=bs)\n",
    "            #checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=filepath,\n",
    "                                                 #    monitor='val_f1_score',\n",
    "                                                  #  save_best_only=True,\n",
    "                                                   #  verbose=1,)\n",
    "            #callbacks = [checkpoint]\n",
    "\n",
    "            bert = build_classifier_model(do,trainable=False)\n",
    "            bert.compile(loss = loss, optimizer = Adam(learning_rate=learning_rates[lr]), metrics = [f1,'accuracy'])\n",
    "            history = bert.fit(x=x_train,\n",
    "                                y=y_train,batch_size=bs,\n",
    "                                validation_data=(x_val,y_val),\n",
    "                                epochs=4)\n",
    "\n",
    "            max_f1 = max(history.history['val_f1_score'])\n",
    "            max_acc = max(history.history['val_accuracy'])\n",
    "            results2[string] = max_f1\n",
    "            results2_acc[string] = max_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "{'lr5e-5_bs8_do0.5': 0.5984582901000977,\n 'lr1e-4_bs8_do0.5': 0.5984582901000977,\n 'lr3e-5_bs8_do0.5': 0.5984582901000977,\n 'lr5e-5_bs16_do0.5': 0.5984582901000977,\n 'lr1e-4_bs16_do0.5': 0.5984582901000977,\n 'lr3e-5_bs16_do0.5': 0.5984582901000977,\n 'lr5e-5_bs8_do0.75': 0.5984582901000977,\n 'lr1e-4_bs8_do0.75': 0.5984582901000977,\n 'lr3e-5_bs8_do0.75': 0.5984582901000977,\n 'lr5e-5_bs16_do0.75': 0.5984582901000977,\n 'lr1e-4_bs16_do0.75': 0.5984582901000977,\n 'lr3e-5_bs16_do0.75': 0.5984582901000977,\n 'lr5e-5_bs8_do0.25': 0.5984582901000977,\n 'lr1e-4_bs8_do0.25': 0.5984582901000977,\n 'lr3e-5_bs8_do0.25': 0.5984582901000977,\n 'lr5e-5_bs16_do0.25': 0.5984582901000977,\n 'lr1e-4_bs16_do0.25': 0.5984582901000977,\n 'lr3e-5_bs16_do0.25': 0.5984582901000977,\n 'lr5e-5_bs8_do0.0': 0.5984582901000977,\n 'lr1e-4_bs8_do0.0': 0.5984582901000977,\n 'lr3e-5_bs8_do0.0': 0.5984582901000977,\n 'lr5e-5_bs16_do0.0': 0.5984582901000977,\n 'lr1e-4_bs16_do0.0': 0.5984582901000977,\n 'lr3e-5_bs16_do0.0': 0.5984582901000977,\n 'lr5e-5_bs8_do0.1': 0.5984582901000977,\n 'lr1e-4_bs8_do0.1': 0.5984582901000977,\n 'lr3e-5_bs8_do0.1': 0.5984582901000977,\n 'lr5e-5_bs16_do0.1': 0.5984582901000977,\n 'lr1e-4_bs16_do0.1': 0.5984582901000977,\n 'lr3e-5_bs16_do0.1': 0.5984582901000977}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{'lr5e-5_bs8_do0.5': 0.7689999938011169,\n 'lr1e-4_bs8_do0.5': 0.5730000138282776,\n 'lr3e-5_bs8_do0.5': 0.7910000085830688,\n 'lr5e-5_bs16_do0.5': 0.7590000033378601,\n 'lr1e-4_bs16_do0.5': 0.746999979019165,\n 'lr3e-5_bs16_do0.5': 0.7680000066757202,\n 'lr5e-5_bs8_do0.75': 0.7730000019073486,\n 'lr1e-4_bs8_do0.75': 0.5730000138282776,\n 'lr3e-5_bs8_do0.75': 0.7850000262260437,\n 'lr5e-5_bs16_do0.75': 0.7630000114440918,\n 'lr1e-4_bs16_do0.75': 0.5730000138282776,\n 'lr3e-5_bs16_do0.75': 0.7720000147819519,\n 'lr5e-5_bs8_do0.25': 0.5730000138282776,\n 'lr1e-4_bs8_do0.25': 0.5730000138282776,\n 'lr3e-5_bs8_do0.25': 0.7730000019073486,\n 'lr5e-5_bs16_do0.25': 0.7639999985694885,\n 'lr1e-4_bs16_do0.25': 0.7440000176429749,\n 'lr3e-5_bs16_do0.25': 0.7760000228881836,\n 'lr5e-5_bs8_do0.0': 0.7799999713897705,\n 'lr1e-4_bs8_do0.0': 0.5730000138282776,\n 'lr3e-5_bs8_do0.0': 0.7699999809265137,\n 'lr5e-5_bs16_do0.0': 0.7699999809265137,\n 'lr1e-4_bs16_do0.0': 0.7540000081062317,\n 'lr3e-5_bs16_do0.0': 0.7829999923706055,\n 'lr5e-5_bs8_do0.1': 0.7720000147819519,\n 'lr1e-4_bs8_do0.1': 0.5730000138282776,\n 'lr3e-5_bs8_do0.1': 0.7760000228881836,\n 'lr5e-5_bs16_do0.1': 0.7820000052452087,\n 'lr1e-4_bs16_do0.1': 0.7409999966621399,\n 'lr3e-5_bs16_do0.1': 0.8019999861717224}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_acc\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "{'lr5e-5_bs8_do0.5': 0.5920000076293945,\n 'lr1e-4_bs8_do0.5': 0.6190000176429749,\n 'lr3e-5_bs8_do0.5': 0.5839999914169312,\n 'lr5e-5_bs16_do0.5': 0.5709999799728394,\n 'lr1e-4_bs16_do0.5': 0.6119999885559082,\n 'lr3e-5_bs16_do0.5': 0.5830000042915344,\n 'lr5e-5_bs8_do0.75': 0.5770000219345093,\n 'lr1e-4_bs8_do0.75': 0.609000027179718,\n 'lr3e-5_bs8_do0.75': 0.5849999785423279,\n 'lr5e-5_bs16_do0.75': 0.5770000219345093,\n 'lr1e-4_bs16_do0.75': 0.5799999833106995,\n 'lr3e-5_bs16_do0.75': 0.5799999833106995,\n 'lr5e-5_bs8_do0.25': 0.6039999723434448,\n 'lr1e-4_bs8_do0.25': 0.6340000033378601,\n 'lr3e-5_bs8_do0.25': 0.597000002861023,\n 'lr5e-5_bs16_do0.25': 0.5649999976158142,\n 'lr1e-4_bs16_do0.25': 0.6069999933242798,\n 'lr3e-5_bs16_do0.25': 0.5759999752044678,\n 'lr5e-5_bs8_do0.0': 0.6029999852180481,\n 'lr1e-4_bs8_do0.0': 0.6489999890327454,\n 'lr3e-5_bs8_do0.0': 0.6060000061988831,\n 'lr5e-5_bs16_do0.0': 0.6159999966621399,\n 'lr1e-4_bs16_do0.0': 0.597000002861023,\n 'lr3e-5_bs16_do0.0': 0.5740000009536743,\n 'lr5e-5_bs8_do0.1': 0.6200000047683716,\n 'lr1e-4_bs8_do0.1': 0.6110000014305115,\n 'lr3e-5_bs8_do0.1': 0.5709999799728394,\n 'lr5e-5_bs16_do0.1': 0.5820000171661377,\n 'lr1e-4_bs16_do0.1': 0.5839999914169312,\n 'lr3e-5_bs16_do0.1': 0.6060000061988831}"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 6s 185ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.91      0.73       573\n",
      "           1       0.63      0.19      0.29       427\n",
      "\n",
      "    accuracy                           0.61      1000\n",
      "   macro avg       0.61      0.55      0.51      1000\n",
      "weighted avg       0.61      0.61      0.54      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#model = tf.keras.models.load_model('checkpoints/fast_text_model.hdf5')\n",
    "#print(val)\n",
    "pred = bert.predict(x_val)\n",
    "pred = np.round(pred)\n",
    "#print(pred)\n",
    "print(classification_report(y_val,pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}