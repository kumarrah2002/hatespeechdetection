{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LD_LIBRARY_PATH=/home/zach/anaconda3/envs/research/lib/\n"
     ]
    }
   ],
   "source": [
    "#Need to remove hardcoding but needed for now\n",
    "%env LD_LIBRARY_PATH=/home/zach/anaconda3/envs/research/lib/\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0433822-9d89-4b16-bb3c-faf4becb2f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 14:24:24.963476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 14:24:25.458863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 14:24:25.459253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/zach/anaconda3/envs/research/lib/'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['LD_LIBRARY_PATH']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Import and Cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bc2ed28-b317-4e93-879b-174809fe1592",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3713/675437588.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  train = train.drop(['TR','AG'],1)\n",
      "/tmp/ipykernel_3713/675437588.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  test = test.drop(['TR','AG'],1)\n",
      "/tmp/ipykernel_3713/675437588.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  val = val.drop(['TR','AG'],1)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/hateval2019_en_train.csv')\n",
    "test = pd.read_csv('data/hateval2019_en_test.csv')\n",
    "val = pd.read_csv('data/hateval2019_en_dev.csv')\n",
    "\n",
    "train = train.drop(['TR','AG'],1)\n",
    "test = test.drop(['TR','AG'],1)\n",
    "val = val.drop(['TR','AG'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38ad4e4f-bb0a-4320-abb5-70975afcf27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "    id                                               text  HS\n0  201  Hurray, saving us $$$ in so many ways @potus @...   1\n1  202  Why would young fighting age men be the vast m...   1\n2  203  @KamalaHarris Illegals Dump their Kids at the ...   1\n3  204  NY Times: 'Nearly All White' States Pose 'an A...   0\n4  205  Orban in Brussels: European leaders are ignori...   0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>HS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>201</td>\n      <td>Hurray, saving us $$$ in so many ways @potus @...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>202</td>\n      <td>Why would young fighting age men be the vast m...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>203</td>\n      <td>@KamalaHarris Illegals Dump their Kids at the ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>204</td>\n      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>205</td>\n      <td>Orban in Brussels: European leaders are ignori...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19c65889-3f31-48d8-9b24-4761dead01fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.regularizers import L1,L2, l1_l2\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a577312-e144-4c17-8f0d-3c01dfb99194",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_tweet(text):\n",
    "    \"\"\"\n",
    "    Removes hashtags, @s, links, and punctuation\n",
    "    :param text:Text to be cleaned\n",
    "    :return: text with mentions, hashtages, and urls removes\n",
    "    \"\"\"\n",
    "    processed_text = text.lower()\n",
    "    processed_text = re.sub(r\"(?:\\@|http?\\://|https?\\://|www|t\\.)\\S+\", \"\", processed_text)\n",
    "    processed_text = re.sub(r\"(?:\\.|,|\\?|-)\", \" \", processed_text)\n",
    "    processed_text = re.sub(r\"(?:\\@|http?\\://|https?\\://|www|\\.com)\", \"\", processed_text)\n",
    "    processed_text = re.sub(r'[^\\w\\s]', '', processed_text)\n",
    "    processed_text = \" \".join(processed_text.split())\n",
    "    return processed_text\n",
    "\n",
    "def x_y_split(data):\n",
    "    \"\"\"splits and X and y from dataframe\n",
    "\n",
    "    Args:\n",
    "        data:dataframe to split from\n",
    "\n",
    "    Returns:\n",
    "        tuple:X data, y data\n",
    "    \"\"\"\n",
    "    X = data['text']\n",
    "    X = X.apply(normalize_tweet)\n",
    "    y = data['HS']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486671d4-0ebf-4dca-b222-f9874edcffd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split sequences into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "892e5b37-65e1-4490-8f21-4c86f55a3252",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       hurray saving us in so many ways lockthemup bu...\n",
      "1       why would young fighting age men be the vast m...\n",
      "2       illegals dump their kids at the border like ro...\n",
      "3       ny times nearly all white states pose an array...\n",
      "4       orban in brussels european leaders are ignorin...\n",
      "                              ...                        \n",
      "8995                  i am proud to be a hysterical woman\n",
      "8996    hollywood is complicit in the rape and sexual ...\n",
      "8997    what a fucking cunt i hate seeing kids getting...\n",
      "8998                                hysterical woman like\n",
      "8999    nearly every woman i know has metoo in their f...\n",
      "Name: text, Length: 9000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Split x and ys\n",
    "x_train, y_train = x_y_split(train)\n",
    "print(x_train)\n",
    "#x_train.to_csv('data/x_train.csv')\n",
    "#y_train.to_csv('data/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d051068c-d8f7-4ae2-953f-cab47e9d6aa6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       oh i could have gone on about taxes since the ...\n",
      "1       several of the wild fires in california and co...\n",
      "2       my question is how do you resettle a refugee a...\n",
      "3       europe youve got a problem we must hurry and b...\n",
      "4       this is outrageous stopillegalimmigration meri...\n",
      "                              ...                        \n",
      "2995    you can never take a l off a real bitch im hot...\n",
      "2996    likes to call me a cunt a bitch but i tell him...\n",
      "2997    1 never said you were taught 2 you called me b...\n",
      "2998    if i see and know you a hoe why would i hit yo...\n",
      "2999     you be chasing them hoes fuck what a bitch think\n",
      "Name: text, Length: 3000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Split x and ys\n",
    "x_test, y_test = x_y_split(test)\n",
    "print(x_test)\n",
    "#x_test.to_csv('data/x_test.csv')\n",
    "#y_test.to_csv('data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01de8fa7-03ed-4d50-9ca6-296865282e6f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      i swear im getting to places just in the nick ...\n",
      "1      im an immigrant and trump is right on immigrat...\n",
      "2      illegalimmigrants illegalaliens electoralsyste...\n",
      "3      we have our own invasion issues with mexicans ...\n",
      "4      worker charged with sexually molesting eight c...\n",
      "                             ...                        \n",
      "995                     you unfollowed me fuck you pussy\n",
      "996    stfu bitch and you go make some satanic music ...\n",
      "997    honey as a fellow white chick let me tell you ...\n",
      "998    i hate bitches who talk about niggaz with kids...\n",
      "999    you won the life time recipient for hysterical...\n",
      "Name: text, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Split x and ys\n",
    "x_val, y_val = x_y_split(val)\n",
    "print(x_val)\n",
    "#x_val.to_csv('data/x_val.csv')\n",
    "#y_val.to_csv('data/y_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text  # A dependency of the preprocessing model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#bert_model_name = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n",
    "#tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#x_train = tf.convert_to_tensor(x_train)\n",
    "#y_train = tf.convert_to_tensor(y_train)\n",
    "\n",
    "#x_val = tf.convert_to_tensor(x_val)\n",
    "#y_val = tf.convert_to_tensor(y_val)\n",
    "\n",
    "#y_val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3713/493614395.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  train = train.drop(['id'],1)\n",
      "/tmp/ipykernel_3713/493614395.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  val = val.drop(['id'],1)\n",
      "/tmp/ipykernel_3713/493614395.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  test = test.drop(['id'],1)\n"
     ]
    }
   ],
   "source": [
    "train = train.drop(['id'],1)\n",
    "val = val.drop(['id'],1)\n",
    "test = test.drop(['id'],1)\n",
    "#train_dataset = tf.data.Dataset.from_tensors()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "train['text'] = train['text'].apply(normalize_tweet)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "0       hurray saving us in so many ways lockthemup bu...\n1       why would young fighting age men be the vast m...\n2       illegals dump their kids at the border like ro...\n3       ny times nearly all white states pose an array...\n4       orban in brussels european leaders are ignorin...\n                              ...                        \n8995                  i am proud to be a hysterical woman\n8996    hollywood is complicit in the rape and sexual ...\n8997    what a fucking cunt i hate seeing kids getting...\n8998                                hysterical woman like\n8999    nearly every woman i know has metoo in their f...\nName: text, Length: 9000, dtype: object"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "x_train_data = tf.convert_to_tensor(x_train.values)\n",
    "y_train_data = tf.convert_to_tensor(y_train.values)\n",
    "train_data = tf.data.Dataset.from_tensor_slices(dict(train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(9000,), dtype=int64, numpy=array([1, 1, 1, ..., 1, 0, 0])>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_data\n",
    "y_train_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [38]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_data \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_tensor_slices\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43my_train_data\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/research/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:809\u001B[0m, in \u001B[0;36mDatasetV2.from_tensor_slices\u001B[0;34m(tensors, name)\u001B[0m\n\u001B[1;32m    731\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    732\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_tensor_slices\u001B[39m(tensors, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    733\u001B[0m   \u001B[38;5;124;03m\"\"\"Creates a `Dataset` whose elements are slices of the given tensors.\u001B[39;00m\n\u001B[1;32m    734\u001B[0m \n\u001B[1;32m    735\u001B[0m \u001B[38;5;124;03m  The given tensors are sliced along their first dimension. This operation\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    807\u001B[0m \u001B[38;5;124;03m    Dataset: A `Dataset`.\u001B[39;00m\n\u001B[1;32m    808\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[0;32m--> 809\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mTensorSliceDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/research/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:4571\u001B[0m, in \u001B[0;36mTensorSliceDataset.__init__\u001B[0;34m(self, element, is_files, name)\u001B[0m\n\u001B[1;32m   4562\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tensors[\u001B[38;5;241m1\u001B[39m:]:\n\u001B[1;32m   4563\u001B[0m   batch_dim\u001B[38;5;241m.\u001B[39massert_is_compatible_with(\n\u001B[1;32m   4564\u001B[0m       tensor_shape\u001B[38;5;241m.\u001B[39mDimension(\n\u001B[1;32m   4565\u001B[0m           tensor_shape\u001B[38;5;241m.\u001B[39mdimension_value(t\u001B[38;5;241m.\u001B[39mget_shape()[\u001B[38;5;241m0\u001B[39m])))\n\u001B[1;32m   4567\u001B[0m variant_tensor \u001B[38;5;241m=\u001B[39m gen_dataset_ops\u001B[38;5;241m.\u001B[39mtensor_slice_dataset(\n\u001B[1;32m   4568\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tensors,\n\u001B[1;32m   4569\u001B[0m     output_shapes\u001B[38;5;241m=\u001B[39mstructure\u001B[38;5;241m.\u001B[39mget_flat_tensor_shapes(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_structure),\n\u001B[1;32m   4570\u001B[0m     is_files\u001B[38;5;241m=\u001B[39mis_files,\n\u001B[0;32m-> 4571\u001B[0m     metadata\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_metadata\u001B[49m\u001B[38;5;241m.\u001B[39mSerializeToString())\n\u001B[1;32m   4572\u001B[0m \u001B[38;5;28msuper\u001B[39m(TensorSliceDataset, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(variant_tensor)\n",
      "File \u001B[0;32m~/anaconda3/envs/research/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:663\u001B[0m, in \u001B[0;36mDatasetV2._metadata\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    661\u001B[0m \u001B[38;5;124;03m\"\"\"Helper for generating dataset metadata.\"\"\"\u001B[39;00m\n\u001B[1;32m    662\u001B[0m metadata \u001B[38;5;241m=\u001B[39m dataset_metadata_pb2\u001B[38;5;241m.\u001B[39mMetadata()\n\u001B[0;32m--> 663\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name:\n\u001B[1;32m    664\u001B[0m   metadata\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m=\u001B[39m _validate_and_encode(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name)\n\u001B[1;32m    665\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m metadata\n",
      "File \u001B[0;32m~/anaconda3/envs/research/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1070\u001B[0m, in \u001B[0;36m_EagerTensorBase.__bool__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1069\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__bool__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m-> 1070\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mbool\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_numpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValueError\u001B[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices(x_train_data,y_train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "<TakeDataset element_spec={'text': TensorSpec(shape=(), dtype=tf.string, name=None), 'HS': TensorSpec(shape=(), dtype=tf.int64, name=None)}>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.take(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}