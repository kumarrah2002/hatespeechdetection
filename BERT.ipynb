{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LD_LIBRARY_PATH=/home/zach/anaconda3/envs/research/lib/\n",
      "env: TF_GPU_ALLOCATOR=cuda_malloc_async\n"
     ]
    }
   ],
   "source": [
    "#Need to remove hardcoding but needed for now\n",
    "%env LD_LIBRARY_PATH=/home/zach/anaconda3/envs/research/lib/\n",
    "%env TF_GPU_ALLOCATOR=cuda_malloc_async"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0433822-9d89-4b16-bb3c-faf4becb2f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 16:26:19.279397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 16:26:19.282962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 16:26:19.283290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/zach/anaconda3/envs/research/lib/'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['LD_LIBRARY_PATH']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Import and Cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bc2ed28-b317-4e93-879b-174809fe1592",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19047/675437588.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  train = train.drop(['TR','AG'],1)\n",
      "/tmp/ipykernel_19047/675437588.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  test = test.drop(['TR','AG'],1)\n",
      "/tmp/ipykernel_19047/675437588.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  val = val.drop(['TR','AG'],1)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/hateval2019_en_train.csv')\n",
    "test = pd.read_csv('data/hateval2019_en_test.csv')\n",
    "val = pd.read_csv('data/hateval2019_en_dev.csv')\n",
    "\n",
    "train = train.drop(['TR','AG'],1)\n",
    "test = test.drop(['TR','AG'],1)\n",
    "val = val.drop(['TR','AG'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38ad4e4f-bb0a-4320-abb5-70975afcf27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "    id                                               text  HS\n0  201  Hurray, saving us $$$ in so many ways @potus @...   1\n1  202  Why would young fighting age men be the vast m...   1\n2  203  @KamalaHarris Illegals Dump their Kids at the ...   1\n3  204  NY Times: 'Nearly All White' States Pose 'an A...   0\n4  205  Orban in Brussels: European leaders are ignori...   0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>HS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>201</td>\n      <td>Hurray, saving us $$$ in so many ways @potus @...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>202</td>\n      <td>Why would young fighting age men be the vast m...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>203</td>\n      <td>@KamalaHarris Illegals Dump their Kids at the ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>204</td>\n      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>205</td>\n      <td>Orban in Brussels: European leaders are ignori...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19c65889-3f31-48d8-9b24-4761dead01fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.regularizers import L1,L2, l1_l2\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a577312-e144-4c17-8f0d-3c01dfb99194",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_tweet(text):\n",
    "    \"\"\"\n",
    "    Removes hashtags, @s, links, and punctuation\n",
    "    :param text:Text to be cleaned\n",
    "    :return: text with mentions, hashtages, and urls removes\n",
    "    \"\"\"\n",
    "    processed_text = text.lower()\n",
    "    processed_text = re.sub(r\"(?:\\@|http?\\://|https?\\://|www|t\\.)\\S+\", \"\", processed_text)\n",
    "    processed_text = re.sub(r\"(?:\\.|,|\\?|-)\", \" \", processed_text)\n",
    "    processed_text = re.sub(r\"(?:\\@|http?\\://|https?\\://|www|\\.com)\", \"\", processed_text)\n",
    "    processed_text = re.sub(r'[^\\w\\s]', '', processed_text)\n",
    "    processed_text = \" \".join(processed_text.split())\n",
    "    return processed_text\n",
    "\n",
    "def x_y_split(data):\n",
    "    \"\"\"splits and X and y from dataframe\n",
    "\n",
    "    Args:\n",
    "        data:dataframe to split from\n",
    "\n",
    "    Returns:\n",
    "        tuple:X data, y data\n",
    "    \"\"\"\n",
    "    X = data['text']\n",
    "    X = X.apply(normalize_tweet)\n",
    "    y = data['HS']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486671d4-0ebf-4dca-b222-f9874edcffd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split sequences into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "892e5b37-65e1-4490-8f21-4c86f55a3252",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       hurray saving us in so many ways lockthemup bu...\n",
      "1       why would young fighting age men be the vast m...\n",
      "2       illegals dump their kids at the border like ro...\n",
      "3       ny times nearly all white states pose an array...\n",
      "4       orban in brussels european leaders are ignorin...\n",
      "                              ...                        \n",
      "8995                  i am proud to be a hysterical woman\n",
      "8996    hollywood is complicit in the rape and sexual ...\n",
      "8997    what a fucking cunt i hate seeing kids getting...\n",
      "8998                                hysterical woman like\n",
      "8999    nearly every woman i know has metoo in their f...\n",
      "Name: text, Length: 9000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Split x and ys\n",
    "x_train, y_train = x_y_split(train)\n",
    "print(x_train)\n",
    "#x_train.to_csv('data/x_train.csv')\n",
    "#y_train.to_csv('data/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d051068c-d8f7-4ae2-953f-cab47e9d6aa6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       oh i could have gone on about taxes since the ...\n",
      "1       several of the wild fires in california and co...\n",
      "2       my question is how do you resettle a refugee a...\n",
      "3       europe youve got a problem we must hurry and b...\n",
      "4       this is outrageous stopillegalimmigration meri...\n",
      "                              ...                        \n",
      "2995    you can never take a l off a real bitch im hot...\n",
      "2996    likes to call me a cunt a bitch but i tell him...\n",
      "2997    1 never said you were taught 2 you called me b...\n",
      "2998    if i see and know you a hoe why would i hit yo...\n",
      "2999     you be chasing them hoes fuck what a bitch think\n",
      "Name: text, Length: 3000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Split x and ys\n",
    "x_test, y_test = x_y_split(test)\n",
    "print(x_test)\n",
    "#x_test.to_csv('data/x_test.csv')\n",
    "#y_test.to_csv('data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01de8fa7-03ed-4d50-9ca6-296865282e6f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      i swear im getting to places just in the nick ...\n",
      "1      im an immigrant and trump is right on immigrat...\n",
      "2      illegalimmigrants illegalaliens electoralsyste...\n",
      "3      we have our own invasion issues with mexicans ...\n",
      "4      worker charged with sexually molesting eight c...\n",
      "                             ...                        \n",
      "995                     you unfollowed me fuck you pussy\n",
      "996    stfu bitch and you go make some satanic music ...\n",
      "997    honey as a fellow white chick let me tell you ...\n",
      "998    i hate bitches who talk about niggaz with kids...\n",
      "999    you won the life time recipient for hysterical...\n",
      "Name: text, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Split x and ys\n",
    "x_val, y_val = x_y_split(val)\n",
    "print(x_val)\n",
    "#x_val.to_csv('data/x_val.csv')\n",
    "#y_val.to_csv('data/y_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text  # A dependency of the preprocessing model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#bert_model_name = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n",
    "#tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#x_train = tf.convert_to_tensor(x_train)\n",
    "#y_train = tf.convert_to_tensor(y_train)\n",
    "\n",
    "#x_val = tf.convert_to_tensor(x_val)\n",
    "#y_val = tf.convert_to_tensor(y_val)\n",
    "\n",
    "#y_val"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19047/493614395.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  train = train.drop(['id'],1)\n",
      "/tmp/ipykernel_19047/493614395.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  val = val.drop(['id'],1)\n",
      "/tmp/ipykernel_19047/493614395.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  test = test.drop(['id'],1)\n"
     ]
    }
   ],
   "source": [
    "train = train.drop(['id'],1)\n",
    "val = val.drop(['id'],1)\n",
    "test = test.drop(['id'],1)\n",
    "#train_dataset = tf.data.Dataset.from_tensors()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "train['text'] = train['text'].apply(normalize_tweet)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "0       hurray saving us in so many ways lockthemup bu...\n1       why would young fighting age men be the vast m...\n2       illegals dump their kids at the border like ro...\n3       ny times nearly all white states pose an array...\n4       orban in brussels european leaders are ignorin...\n                              ...                        \n8995                  i am proud to be a hysterical woman\n8996    hollywood is complicit in the rape and sexual ...\n8997    what a fucking cunt i hate seeing kids getting...\n8998                                hysterical woman like\n8999    nearly every woman i know has metoo in their f...\nName: text, Length: 9000, dtype: object"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 16:26:19.824243: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-23 16:26:19.825384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 16:26:19.825747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 16:26:19.826041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 16:26:20.155660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 16:26:20.155985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 16:26:20.156271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-23 16:26:20.156528: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-05-23 16:26:20.156735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6329 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "tfhub_handle_encoder = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n",
    "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
    "\n",
    "\n",
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)\n",
    "\n",
    "\n",
    "bert = build_classifier_model()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 16:26:44.242882: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:288] gpu_async_0 cuMemAllocAsync failed to allocate 50331648 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)\n",
      " Reported by CUDA: Free memory/Total memory: 81199104/8366784512\n",
      "2022-05-23 16:26:44.242910: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:293] Stats: Limit:                      6636765184\n",
      "InUse:                      7429657257\n",
      "MaxInUse:                   7429657257\n",
      "NumAllocs:                       24531\n",
      "MaxAllocSize:                 93763584\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-05-23 16:26:44.242943: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:56] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n",
      "2022-05-23 16:26:44.242948: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1, 1\n",
      "2022-05-23 16:26:44.242952: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 4, 150\n",
      "2022-05-23 16:26:44.242954: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 8, 27\n",
      "2022-05-23 16:26:44.242957: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 16, 2\n",
      "2022-05-23 16:26:44.242960: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 128, 1\n",
      "2022-05-23 16:26:44.242963: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1028, 1\n",
      "2022-05-23 16:26:44.242966: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1900, 1\n",
      "2022-05-23 16:26:44.242968: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 3072, 563\n",
      "2022-05-23 16:26:44.242971: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 6144, 5\n",
      "2022-05-23 16:26:44.242974: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 12288, 60\n",
      "2022-05-23 16:26:44.242977: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 16384, 45\n",
      "2022-05-23 16:26:44.242980: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 32768, 1\n",
      "2022-05-23 16:26:44.242982: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 72000, 2\n",
      "2022-05-23 16:26:44.242985: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 122088, 1\n",
      "2022-05-23 16:26:44.242988: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1572864, 5\n",
      "2022-05-23 16:26:44.242991: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 2097152, 1\n",
      "2022-05-23 16:26:44.242993: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 2359296, 246\n",
      "2022-05-23 16:26:44.242996: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 9437184, 120\n",
      "2022-05-23 16:26:44.242999: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 12582912, 142\n",
      "2022-05-23 16:26:44.243002: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 25165824, 33\n",
      "2022-05-23 16:26:44.243005: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 50331648, 52\n",
      "2022-05-23 16:26:44.243007: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 93763584, 5\n",
      "2022-05-23 16:26:44.243032: W tensorflow/core/framework/op_kernel.cc:1733] RESOURCE_EXHAUSTED: failed to allocate memory\n",
      "2022-05-23 16:26:44.243223: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:288] gpu_async_0 cuMemAllocAsync failed to allocate 50331648 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)\n",
      " Reported by CUDA: Free memory/Total memory: 81199104/8366784512\n",
      "2022-05-23 16:26:44.243232: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:293] Stats: Limit:                      6636765184\n",
      "InUse:                      7429657257\n",
      "MaxInUse:                   7429657257\n",
      "NumAllocs:                       24531\n",
      "MaxAllocSize:                 93763584\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-05-23 16:26:44.243256: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:56] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n",
      "2022-05-23 16:26:44.243259: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1, 1\n",
      "2022-05-23 16:26:44.243262: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 4, 150\n",
      "2022-05-23 16:26:44.243265: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 8, 27\n",
      "2022-05-23 16:26:44.243268: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 16, 2\n",
      "2022-05-23 16:26:44.243272: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 128, 1\n",
      "2022-05-23 16:26:44.243274: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1028, 1\n",
      "2022-05-23 16:26:44.243277: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1900, 1\n",
      "2022-05-23 16:26:44.243280: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 3072, 563\n",
      "2022-05-23 16:26:44.243283: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 6144, 5\n",
      "2022-05-23 16:26:44.243285: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 12288, 60\n",
      "2022-05-23 16:26:44.243288: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 16384, 45\n",
      "2022-05-23 16:26:44.243291: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 32768, 1\n",
      "2022-05-23 16:26:44.243294: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 72000, 2\n",
      "2022-05-23 16:26:44.243297: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 122088, 1\n",
      "2022-05-23 16:26:44.243299: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 1572864, 5\n",
      "2022-05-23 16:26:44.243302: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 2097152, 1\n",
      "2022-05-23 16:26:44.243305: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 2359296, 246\n",
      "2022-05-23 16:26:44.243308: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 9437184, 120\n",
      "2022-05-23 16:26:44.243311: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 12582912, 142\n",
      "2022-05-23 16:26:44.243314: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 25165824, 33\n",
      "2022-05-23 16:26:44.243317: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 50331648, 52\n",
      "2022-05-23 16:26:44.243319: E tensorflow/core/common_runtime/gpu/gpu_cudamallocasync_allocator.cc:59] 93763584, 5\n",
      "2022-05-23 16:26:44.243324: W tensorflow/core/framework/op_kernel.cc:1733] RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nfailed to allocate memory\n\t [[{{node transformer/layer_10/activation/Gelu/Pow}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_89307]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "Input \u001B[0;32mIn [23]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m metrics \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mBinaryAccuracy()\n\u001B[1;32m      4\u001B[0m bert\u001B[38;5;241m.\u001B[39mcompile(loss \u001B[38;5;241m=\u001B[39m loss, optimizer \u001B[38;5;241m=\u001B[39m Adam(), metrics \u001B[38;5;241m=\u001B[39m metrics)\n\u001B[0;32m----> 5\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mbert\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/research/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/anaconda3/envs/research/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mResourceExhaustedError\u001B[0m: Graph execution error:\n\nfailed to allocate memory\n\t [[{{node transformer/layer_10/activation/Gelu/Pow}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_89307]"
     ]
    }
   ],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "metrics = tf.metrics.BinaryAccuracy()\n",
    "\n",
    "bert.compile(loss = loss, optimizer = Adam(), metrics = metrics)\n",
    "history = bert.fit(x=x_train,y=y_train,epochs=1,batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}